[
  {
    "objectID": "otros.html",
    "href": "otros.html",
    "title": "Otras cosas",
    "section": "",
    "text": "secuencia&lt;-5:15\nsecuencia\n\n [1]  5  6  7  8  9 10 11 12 13 14 15\n\nseq(5.5, 10, by = 0.5) #la secuencia irá de 5,5 hasta 10, de 0,5 en 0,5\n\n [1]  5.5  6.0  6.5  7.0  7.5  8.0  8.5  9.0  9.5 10.0\n\nseq(5, 10, length.out = 5) #entre el 5 y el 10, sacará una secuencia formada por 5 números\n\n[1]  5.00  6.25  7.50  8.75 10.00\n\n\nTambién se pueden repetir valores:\n\nvalores &lt;- c(\"yes\", \"no\")\n\nrep(valores, times=3) #Repite la secuencia completa tres veces\n\n[1] \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n\nrep(valores, each=3) #Repite cada uno de los valores del vector 3 veces\n\n[1] \"yes\" \"yes\" \"yes\" \"no\"  \"no\"  \"no\"",
    "crumbs": [
      "Otros",
      "Otras cosas"
    ]
  },
  {
    "objectID": "otros.html#secuencia",
    "href": "otros.html#secuencia",
    "title": "Otras cosas",
    "section": "",
    "text": "secuencia&lt;-5:15\nsecuencia\n\n [1]  5  6  7  8  9 10 11 12 13 14 15\n\nseq(5.5, 10, by = 0.5) #la secuencia irá de 5,5 hasta 10, de 0,5 en 0,5\n\n [1]  5.5  6.0  6.5  7.0  7.5  8.0  8.5  9.0  9.5 10.0\n\nseq(5, 10, length.out = 5) #entre el 5 y el 10, sacará una secuencia formada por 5 números\n\n[1]  5.00  6.25  7.50  8.75 10.00\n\n\nTambién se pueden repetir valores:\n\nvalores &lt;- c(\"yes\", \"no\")\n\nrep(valores, times=3) #Repite la secuencia completa tres veces\n\n[1] \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n\nrep(valores, each=3) #Repite cada uno de los valores del vector 3 veces\n\n[1] \"yes\" \"yes\" \"yes\" \"no\"  \"no\"  \"no\"",
    "crumbs": [
      "Otros",
      "Otras cosas"
    ]
  },
  {
    "objectID": "otros.html#NA",
    "href": "otros.html#NA",
    "title": "Otras cosas",
    "section": "Valores perdidos",
    "text": "Valores perdidos\n\nComprobar si hay valores perdidos: is.na() o anyNA(). En la consola dirá True o False.\nConocer el número de valores perdidos dentro de una variable: table(datos$var, useNA=\"always\").\nEliminar todas las observaciones de una base de datos que tengan casos perdidos en alguna de sus variables: datos &lt;- na.omit(datos)",
    "crumbs": [
      "Otros",
      "Otras cosas"
    ]
  },
  {
    "objectID": "otros.html#funciones",
    "href": "otros.html#funciones",
    "title": "Otras cosas",
    "section": "Crear funciones",
    "text": "Crear funciones\nPermiten concentrar varios comandos en uno solo.\nnombre_función &lt;- function (x){\n  argumentos de la función\n}\n\n\nEjemplos:\n\nFunción que devuelve el valor de la mitad de un número:\n\nfuncionmitad &lt;- function(x){\n  y &lt;- x/2\n  return(y)\n}\n\nFunción que hace una potencia y añade texto:\n\nfuncionpotencia &lt;- function(x,y){\n  potencia &lt;- x^y\n  z &lt;- \"El resultado de la potencia es: \"\n  texto &lt;- paste0(z,potencia)\n  return(texto)\n}\n\nFunción para crear tablas de frecuencia (como %) automáticas (función table de stata):\n\ntabla &lt;- function(x,y){\n  tabla_decimal &lt;- table(x,y) %&gt;% prop.table %&gt;% round(4)\n  tabla_porcentaje &lt;- tabla_decimal*100\n  return(tabla_porcentaje)\n}\nSi algunas de las funciones creadas se quiere reutilizar habitualmente, existen dos formas fáciles de volver a instalarlas:\n\nEscribiendo estas funciones en un script a parte y usando source.\nCrear un paquete propio.",
    "crumbs": [
      "Otros",
      "Otras cosas"
    ]
  },
  {
    "objectID": "otros.html#recomendaciones_dicotomicas",
    "href": "otros.html#recomendaciones_dicotomicas",
    "title": "Otras cosas",
    "section": "Recomendaciones para las variables dicotómicas",
    "text": "Recomendaciones para las variables dicotómicas\nEs recomendable nombrar a la variable como la categoría de referencia. Por ejemplo, en el siguente ejemplo la variable se llama hombre en lugar de sexo porque el 1 se corresponde con los hombres. Es mejor hacerlo de este modo porque facilita la interpretación de los análisis. Por ejemplo, al hacer un summary de la nueva variable, se puede ver fácilmente que el 0.51 indica que la proporción de hombres en la muestra es del 51%.\ndatos &lt;- datos %&gt;% \n  mutate(hombre=ifelse(SEXO==1, 1, 0))",
    "crumbs": [
      "Otros",
      "Otras cosas"
    ]
  },
  {
    "objectID": "intro/introduccion.html",
    "href": "intro/introduccion.html",
    "title": "R Studio",
    "section": "",
    "text": "Ventanas de R Studio\n\n\n\n\nEditor de código: ficheros donde se escribe el código. Elemento clave para la reproducibilidad.\nConsola: muestra los resultados del código ejecutado y permite ejecutar código de forma rápida (poco recomendable excepto para pruebas y mirar cosas muy concretas y rápidas)\nVentana de ambiente: muestra los objetos almacenados\nVentana de ficheros/gráficos…\n\nPermite visualizar resultados del trabajo: gráficos, html…\nEncontrar ficheros\nVer detalles de los paquetes empleados, etc.\n\n\nExisten diversos formatos para escribir código en R, siendo los más destacados los siguientes:\n\nScript: útil si solo se quiere escribir código.\nRMarkdown: más útil si se quieren añadir anotaciones de texto frecuentes. Además, cuenta con numerosas opciones extra, como añadir imágenes, tablas o guardar los documentos en formato pdf o html, entre otras funciones.\nQuarto: muy similar a RMarkdown, pero más moderno y con más opciones.",
    "crumbs": [
      "Introducción a R",
      "R Studio"
    ]
  },
  {
    "objectID": "intro/introduccion.html#qué-es-r-studio",
    "href": "intro/introduccion.html#qué-es-r-studio",
    "title": "R Studio",
    "section": "",
    "text": "Ventanas de R Studio\n\n\n\n\nEditor de código: ficheros donde se escribe el código. Elemento clave para la reproducibilidad.\nConsola: muestra los resultados del código ejecutado y permite ejecutar código de forma rápida (poco recomendable excepto para pruebas y mirar cosas muy concretas y rápidas)\nVentana de ambiente: muestra los objetos almacenados\nVentana de ficheros/gráficos…\n\nPermite visualizar resultados del trabajo: gráficos, html…\nEncontrar ficheros\nVer detalles de los paquetes empleados, etc.\n\n\nExisten diversos formatos para escribir código en R, siendo los más destacados los siguientes:\n\nScript: útil si solo se quiere escribir código.\nRMarkdown: más útil si se quieren añadir anotaciones de texto frecuentes. Además, cuenta con numerosas opciones extra, como añadir imágenes, tablas o guardar los documentos en formato pdf o html, entre otras funciones.\nQuarto: muy similar a RMarkdown, pero más moderno y con más opciones.",
    "crumbs": [
      "Introducción a R",
      "R Studio"
    ]
  },
  {
    "objectID": "intro/introduccion.html#instalar-paquetes",
    "href": "intro/introduccion.html#instalar-paquetes",
    "title": "R Studio",
    "section": "Instalar paquetes",
    "text": "Instalar paquetes\nLos paquetes son un conjunto de código, datos y documentación que permiten implementar funciones predefinidas extra.\nR básico:\nPara instalar un paquete, se puede hacer buscándola en la pestañaInstall dentro de la pestaña Packages (esquina inferior derecha de la pantalla).\nTambién se puede instalar usando el siguiente comando: install.packages(\"nombre_librería\")\nUna vez instalada, se abre usando el comando: library(\"nombre_librería\")\nIMPORTANTE: las librerías deben abrirse siempre que se usen (no con cada comando que se use, sino con cada sesión de R que se abra), pero solo se instalan una vez.\nLibrería pacman:\n\nInstalar la librería pacman.\nAbrir la librería.\nCuando se vaya a abrir una nueva librería, en lugar de usar el comando library(nombre_librería) se usa p_load(nombre_librería)\n\nLa ventaja de este comando es que, en caso de que no esté instalada la librería, se descargará y abrirá directamente.\nAdemás, con el comando p_load se pueden abrir en un único comando varias librerías, lo que reduce la cantidad de espacio necesario para abrir las librerías: p_load(librería_1, librería_2, librería_3...)\n\n\nPaquetes de GitHub:\nTanto install.packages como p_load sirven únicamente para paquetes que estén dentro de CRAN. Para instalar los que estén en GitHub se debe usar el comando devtools::install_github(\"libraría\"), que pertenece a la librería devtools.",
    "crumbs": [
      "Introducción a R",
      "R Studio"
    ]
  },
  {
    "objectID": "intro/introduccion.html#recomendaciones",
    "href": "intro/introduccion.html#recomendaciones",
    "title": "R Studio",
    "section": "Recomendaciones",
    "text": "Recomendaciones\nAl comenzar un nuevo trabajo en R, conviene crear un proyecto nuevo en el que se quiera trabajara, y mantener este ordenado. También es recomendable guardar todos los códigos de forma estructurada, de modo que tanto otras personas como tu yo del futuro puedan saber para qué sirven cada una de las cosas que se han añadido.",
    "crumbs": [
      "Introducción a R",
      "R Studio"
    ]
  },
  {
    "objectID": "intro/introduccion.html#atajos",
    "href": "intro/introduccion.html#atajos",
    "title": "R Studio",
    "section": "Atajos",
    "text": "Atajos\n\nAñadir un pipe (%&gt;%): ctrl + shift + m\nAñadir una almohadilla a la línea de código sobre la que se esté: ctrl + shift + c\nAñadir la &lt;- con sus espacios: alt + -\n\nEn RMarkdown / Quarto\n\nAñadir un nuevo chunk de R: ctrl + alt + i\n\nEn un script\n\nCrear nuevas secciones dentro del documento: ctrl + shift + r",
    "crumbs": [
      "Introducción a R",
      "R Studio"
    ]
  },
  {
    "objectID": "intro/documentos-r.html",
    "href": "intro/documentos-r.html",
    "title": "Documentos de R",
    "section": "",
    "text": "Para escribir código en R se pueden usar tres tipos de documentos: Script, RMarkdown y Quarto.",
    "crumbs": [
      "Introducción a R",
      "Documentos de R"
    ]
  },
  {
    "objectID": "intro/documentos-r.html#script",
    "href": "intro/documentos-r.html#script",
    "title": "Documentos de R",
    "section": "Script",
    "text": "Script\nSirve solo para escribir código. No tiene otras opciones como poner imágenes, texto, títulos o guardar en otros formatos como pdf o html.",
    "crumbs": [
      "Introducción a R",
      "Documentos de R"
    ]
  },
  {
    "objectID": "intro/documentos-r.html#rmarkdown",
    "href": "intro/documentos-r.html#rmarkdown",
    "title": "Documentos de R",
    "section": "RMarkdown",
    "text": "RMarkdown\n\n1. Elementos básicos\nYalm\nSe escribe al comienzo del documento, y establece las características básicas de este y como se va a guardar.\n---\n title: \"El título del documento\"\n subtitle: \"El subtítulo\"\n date: \"Fecha\"\n author: \"Autor\"\n output:\n  html_document: #también se puede guardar como pdf o word, así saca una página web\n    theme: united #es el tema del documento, hay diferentes\n    toc: true #para crear una tabla de contenido\n ---\nMuchos de estos elementos son opcionales, y se pueden añadir más.\nEjemplos de temas que se pueden utilizar para el documento: https://rpubs.com/ranydc/rmarkdown_themes\nChunks\nPara escribir los códigos de R y que estos se puedan ejecutar, se debe añadir un chunk. Se puede hacer manualmente o mediante el atajo Ctrl + Alt + I.\nPara ejecutar el códico que se escriba, se puede pulsar el triángulo verde de la esquina superior derecha (del chunk), la opción Run de la esquina de la pestaña del rmd, o usando Ctrl+Enter.\nDentro de los chunks, se pueden establecer diferentes opciones para que no se muestre el código en el documento final pero se ejecute igualmente, no se muestren los errores… Estos ajustes se puedes escribir como comandos dentro de {r} o en la rueda de opciones que aparece a la derecha de cada chunk. Algunas de estas opciones son:\n\ninclude: incluir los contenidos del chunk en el output\nmessage: mensajes de la consola\nwarning: avisos de la consola\necho: muestra el código\neval: muestra el resultado del código (tabla, gráfico, etc.)\n…\n\nSi se quiere que alguna de estas opciones se aplique a todos los chunks del documento, en lugar de tener que especificarlas en cada nuevo bloque de código se pueden escribir una única vez al princicipio del documento del siguiente modo:\nknitr::opts_chunk$set(warning = FALSE, # En caso de mensajes de alerta\n                      message = FALSE, # Otro tipo de mensajes\n                      echo = TRUE, # Mostrar el código\n                      results = TRUE) # Mostrar los resultados del código\nAsimismo, los diferentes chunks del documento se les pueden dar nombres del siguiente modo: {r nombre chunk}\nLos chunks de R además permiten ejecutar todo el contenido de los chunks empleados con anterioridad, lo que puede resultar muy útil en el casdo de cometer errores que nedesitar resetear todo el trabajo realizado hasta el momento. Para ello, se debe seleccrionar la segunda opción que aparece en la esquina superior derecha del chunk (entre la rueda y el triángulo verde).\nEncabezados\nSirven para delimitar los diferentes apartados y subapartados de los documentos. Se crean con las # (en una nueva línea se escribiría: # Encabezado de nivel 1. El espacio entre la almohadilla y el texto es imprescindible. Si en lugar de escribir una única # se ponen 2, 3… o 6, se van creando subniveles de encabezados (un mayor número de almohadillas indica un nivel inferior de encabezado).\nEspacio entre líneas\nSi se quiere añadir un salto de línea, se debe dejar una línea de código vacía entre los dos textos que se pretenden separar. Si simplemente se escribe en la siguiente línea, se compliará todo como parte del mismo párrafo.\nCompilar el documento\nSe selecciona la opción Knit, lo que genrará un documento HTML/PDF con todo el contenido y los resultados.\n\n\n\n2. Opciones de texto y otros elementos\nSi no se conocen estas opciones, es mejor usar el apartado de edición de texto Visual y no Source, ya que en el primero se puede editar el texto de forma parecida a un Word.\nFormatos de texto:\n\n**Texto en negrita** = Texto en negrita (los asteriscos se pueden sustituir por _)\n*Texto en cursiva* = Texto en cursiva\n***Texto en negrita y cursiva*** = Texto en negrita y cursiva\n`Código subrayado` = Código subrayado\nSubíndice: 3~2~ = 32\nSuperíndice: 3^2^ = 32\n\nListas:\nPara las listas de puntos, se escriben al comienzo de la línea de código y seguido de un espacio antes del texto un asterisco (*) o un guión (-). Además, si en la siguiente línea se añade espacio también antes del símbolo, se creará una sublista:\n\nElemento 1\n\nElemento 2\n\n\nTambién se pueden hacer listas con números y letras: 1. 1) A. i. etc.\nCitas\nSe escribe el texto con un &gt; al principio de la línea:\n\nEjemplo de una cita\n\nEcuaciones\nSe escribe el texto de la ecuación entre dos símbolos del dolar. Ej.: $E=mc^{2}$ = \\(E=mc^{2}\\)\nSi se quiere que la ecuación esté en un bloque a parte en lugar de dentro del texto, se añaden dos símbolos del dolar para abrir y cerrar la ecuación: \\[E=mc^{2}\\]\nHipervínculos\nEl texto para el que se quiere el hipervínculo se escribe entre corchetes, y a continuación (sin dejar espacios) se escribe entre paréntesis el enlace a la página para la que se quiere el hipervínculo. Ej.: [Texto del hipervínculo](paginaweb.com)\nAñadir imágenes\nHay varias opciones para insertar una imagen en el texto. Por ejemplo, puedes guardarla previamente en el directorio de trabajo (o en el proyecto que hayas creado). Una vez la tienes en tu directorio, puedes usar esta línea de código para introducirla en el documento final: ![título de la imagen](path-to-image-here). Además, se puede combinar con center para centrar la imagen en el output, y con width para ajustar el tamaño.\n&lt;center&gt;\n![Título de la imagen](mi_imagen.png){width=350px}\n&lt;/center&gt;\nOtra manera sencilla de controlar el tamaño es usando porcentajes: {width=10%}\nUna alternativa bastante usada, por ejemplo, es usar include_graphics para controlar el ancho y alto de la imagen añadiendo como opción dentro de {r} lo siguiente: out.width = \"100px\", out.height=\"300px\"\nknitr::include_graphics(\"mi_imagen.png\")\nTambién tenemos la opción de introducir una imagen directamente desde la web (es decir, sin descargarla previamente). Primero, creamos una variable con la dirección url. Una vez creada la variable, se añade igual que una imágen guardada en el directorio:\nnombre_imagen&lt;-\"https://ejemplo_imagen.jpg\" \nLíneas horizontales\nSe añaden escribiendo en una línea vacía *** o —. El resultado es:\n\nExisten muchas otras opciones dentro del RMarkdown, como incluir tablas, citas, referencias… En el enlace se puede encontrar información extra, aunque es solo un ejemplo de página sobre RMarkdown.\n\n\n\n3. Índices y tablas de contenido\n\n2.1. Índice como lista al comienzo del documento\nLos índices se crean a partir de los títulos (#). Se puede especificar el número de niveles que se quieren incluir gracias a la opciontoc_depth:\n ---\ntitle: \"El título del documento\"\noutput:\n  html_document:\n    toc: true\n    toc_depth: 3 #En este caso se incluirían los tres primeros niveles del títulos (hasta ###)\n--- \n\n\n\n2.2. Índice a la izquierda del documento\nTabla de contenido despegable\nPara poder hacer una tabla de contenido despegable, se debe crear un css personalizado:\nÍndice personalizable en RMarkdown\nPara crear un índice (TOC - Table of Contents) personalizable en RMarkdown que sea flotante y se pueda ocultar/mostrar, necesitamos añadir código CSS y JavaScript. Aquí te explico paso a paso cómo hacerlo.\n1. Código CSS necesario\nPrimero, necesitas añadir este bloque de código CSS al inicio de tu documento. Este código dará estilo al índice y creará la funcionalidad de mostrar/ocultar:\n```{css, echo=FALSE}\nhr {\n  border: none;\n  border-top: 3px solid #bbb;\n  margin: 1em 0;\n}\n #TOC {\n  position: fixed;\n  left: 0;\n  top: 0;\n  width: 300px;\n  height: 100%;\n  overflow-y: auto;\n  background: #f8f8f8;\n  border-right: 1px solid #e7e7e7;\n  padding: 20px;\n  transition: left 0.3s ease;\n}\n #TOC.hidden {\n  left: -300px;\n}\n #toggle-toc {\n  position: fixed;\n  top: 5px;\n  left: 5px;\n  z-index: 1000;\n  background: #f8f8f8;\n  border: 1px solid #e7e7e7;\n  padding: 5px 10px;\n  cursor: pointer;\n}\n.main-content {\n  transition: margin-left 0.3s ease;\n  margin-left: 200px;\n}\n.main-content.toc-hidden {\n  margin-left: 150px;\n}\n@media (max-width: 767px) {\n  .main-content {\n    margin-left: 0;\n  }\n}\n```\n2. Código JavaScript necesario\nLuego, necesitas añadir este bloque de código JavaScript que proporcionará la funcionalidad interactiva:\n```{js, echo=FALSE}\n$(document).ready(function() {\n  var toc = $('#TOC');\n  var toggle = $('☰');\n  var mainContent = $('body &gt; .main-container');\n  $('body').prepend(toggle);\n  mainContent.addClass('main-content');\n  toggle.click(function() {\n    toc.toggleClass('hidden');\n    mainContent.toggleClass('toc-hidden');\n  });\n  // Inicializar el estado en pantallas pequeñas\n  if ($(window).width() &lt;= 767) {\n    toc.addClass('hidden');\n    mainContent.addClass('toc-hidden');\n  }\n});\n```\n3. Configuración del YAML\nAdemás, asegúrate de que tu encabezado YAML incluya la opción de tabla de contenidos:\n---\ntitle: \"Tu título\"\noutput: \n  html_document:\n    toc: true\n    toc_float: true\n ---\n4. Cómo funciona\nEste código creará:\n\nUn índice flotante en el lado izquierdo de la página\nUn botón (☰) en la esquina superior izquierda para mostrar/ocultar el índice\nEl índice se ocultará automáticamente en dispositivos móviles\nTransiciones suaves al mostrar/ocultar el índice\n\nNota: El código CSS y JavaScript debe colocarse al principio del documento, después del encabezado YAML.\nPersonalización\nPuedes personalizar el aspecto modificando los valores en el código CSS:\n\nCambia width: 300px en #TOC para ajustar el ancho del índice\nModifica background: #f8f8f8 para cambiar el color de fondo\nAjusta margin-left en .main-content para cambiar el espaciado del contenido principal\n\n\n\n\n2.3. Índice por pestañas\n\nEn el yalm no se escribe el toc: true\nTras el primer título (que se puede dejar en blanco escribiendo únicamente la #) se escribe el siguiente comando {.tabset .tabset-fade .tabset-pills}.\nEsta opción se puede repetir para los sucesivos subniveles de títulos, creando nuevas pestañas dentro de cada pestaña (como en este archivo).\n\n\n\n\n2.4. Números de sección\nEn lugar de añadir a mano los números delante de cada título (1.2. Subtitulo), estos se pueden añadir automáticamente gracias a la siguiente opción:\n---\ntitle: \"El título del documento\"\noutput:\n  html_document:\n    toc: true\n    number_sections: true\n---\nSi se utiliza esta opción, hay que comenzar los títulos por el primer nivel, porque si no en el segundo apareceran como 0.1 0.2 …\n\n\n\n\n4. Otras cosas RMarkdown\n\nPara escribir código de R sin que se ejecute (pero mostrándolo en el html), se borran las llaves que rodean la r del chunk:\n\nCódigo que se ejecuta:\n\n\n```{r}\nAquí iría el código\n```\n\nCódigo que no se ejecuta:\n\n```r\nAquí iría el código\n```\n\nCrear índices a mano (lista con hipervínculos)\n\nJunto a un título (para cualquier nivel de #), se escribe: {#nombre-sección}\nDonde se quiera crear el índice se pone el siguiente texto: [Nombre de la sección] (#nombre-sección) Importante: no se debe dejar ningún espacio entre el corchete y el paréntesis.",
    "crumbs": [
      "Introducción a R",
      "Documentos de R"
    ]
  },
  {
    "objectID": "intro/documentos-r.html#quarto",
    "href": "intro/documentos-r.html#quarto",
    "title": "Documentos de R",
    "section": "Quarto",
    "text": "Quarto\nLas mismas opciones que en RMarkdown (menos lo del tabstat, que se hace de un modo distinto).",
    "crumbs": [
      "Introducción a R",
      "Documentos de R"
    ]
  },
  {
    "objectID": "graficos/g-otros.html",
    "href": "graficos/g-otros.html",
    "title": "Otros gráficos",
    "section": "",
    "text": "GráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(ideol_psoe_j, aes(x = ideol)) +\n  facet_wrap(~ mes, ncol = 1, strip.position = \"top\", labeller = label_value) +\n  geom_bar(aes(y = porcentaje), stat = \"identity\", fill = \"red\", alpha = 0.1) +\n  geom_point(data = pref_j, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color = Var1), size = 3, alpha = 0.7) +\n  geom_text_repel(data = pref_j, \n                  aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), \n                      label = round(Freq, 0)), \n                  size = 2.7, show.legend = FALSE) +\n  theme_classic() +\n  labs(\n    x = \"Posición ideológica (1-10)\",\n    caption = \"Evolución de preferencias por cada candidato para los votantes del PSOE según su ideología\\n Los valores 7 a 10 de las escala se han omitido debido a la baja frecuencia de votantes socialistas\",\n    color = \"Preferencia por:\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 9),\n    axis.title = element_text(size = 14),\n    strip.background = element_blank()) +\n  scale_y_continuous(\n    name = \"Porcentaje de votantes\", # Eje izquierdo\n    sec.axis = sec_axis(~ . * max(pref_j$Freq) / max(ideol_psoe$porcentaje), name = \"Preferencia de candidatos\")) +\n  scale_color_manual(\n    values = c(\"Sánchez\" = \"red\", \"Casado/Feijoo\" = \"blue\", \"Indiferente\" = \"grey\")) +\n  scale_x_continuous(breaks = seq(1, 6, by = 1))\n\n\nggplot(ideol_psoe_j, aes(x = ideol)) +\n\n## Juntar los tres graficos\n  facet_wrap(~ mes, ncol = 1, strip.position = \"top\", labeller = label_value) +\n  \n## Barras (eje primario)\n  geom_bar(aes(y = porcentaje), stat = \"identity\", fill = \"red\", alpha = 0.1) +\n  \n## Puntos (eje secundario)\n  geom_point(data = pref_j, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color = Var1), size = 3, alpha = 0.7) +\n  \n## Etiquetas en los puntos que evitan la superposición\n  geom_text_repel(data = pref_j, \n                  aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), \n                      label = round(Freq, 0)), \n                  size = 2.7, show.legend = FALSE) +\n  \n## Tema y etiquetas\n  theme_classic() +\n  labs(\n    x = \"Posición ideológica (1-10)\",\n    caption = \"Evolución de preferencias por cada candidato para los votantes del PSOE según su ideología\\n Los valores 7 a 10 de las escala se han omitido debido a la baja frecuencia de votantes socialistas\",\n    color = \"Preferencia por:\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 9),\n    axis.title = element_text(size = 14),\n    strip.background = element_blank()) +\n  \n## Ejes con escalas independientes\n  scale_y_continuous(\n    name = \"Porcentaje de votantes\", # Eje izquierdo\n    sec.axis = sec_axis(~ . * max(pref_j$Freq) / max(ideol_psoe$porcentaje), name = \"Preferencia de candidatos\")) + # Eje derecho\n\n## Colores personalizado\n  scale_color_manual(\n    values = c(\"Sánchez\" = \"red\", \"Casado/Feijoo\" = \"blue\", \"Indiferente\" = \"grey\")) +\n\n## Establecer valores del eje x\n  scale_x_continuous(breaks = seq(1, 6, by = 1))\n\n\n\n\n\n\n\n\n\n\n\nideol_psoe_j\n\n\n\n\n\n\n\npref_j",
    "crumbs": [
      "Gráficos",
      "Otros gráficos"
    ]
  },
  {
    "objectID": "graficos/g-otros.html#puntos-barras",
    "href": "graficos/g-otros.html#puntos-barras",
    "title": "Otros gráficos",
    "section": "",
    "text": "GráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(ideol_psoe_j, aes(x = ideol)) +\n  facet_wrap(~ mes, ncol = 1, strip.position = \"top\", labeller = label_value) +\n  geom_bar(aes(y = porcentaje), stat = \"identity\", fill = \"red\", alpha = 0.1) +\n  geom_point(data = pref_j, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color = Var1), size = 3, alpha = 0.7) +\n  geom_text_repel(data = pref_j, \n                  aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), \n                      label = round(Freq, 0)), \n                  size = 2.7, show.legend = FALSE) +\n  theme_classic() +\n  labs(\n    x = \"Posición ideológica (1-10)\",\n    caption = \"Evolución de preferencias por cada candidato para los votantes del PSOE según su ideología\\n Los valores 7 a 10 de las escala se han omitido debido a la baja frecuencia de votantes socialistas\",\n    color = \"Preferencia por:\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 9),\n    axis.title = element_text(size = 14),\n    strip.background = element_blank()) +\n  scale_y_continuous(\n    name = \"Porcentaje de votantes\", # Eje izquierdo\n    sec.axis = sec_axis(~ . * max(pref_j$Freq) / max(ideol_psoe$porcentaje), name = \"Preferencia de candidatos\")) +\n  scale_color_manual(\n    values = c(\"Sánchez\" = \"red\", \"Casado/Feijoo\" = \"blue\", \"Indiferente\" = \"grey\")) +\n  scale_x_continuous(breaks = seq(1, 6, by = 1))\n\n\nggplot(ideol_psoe_j, aes(x = ideol)) +\n\n## Juntar los tres graficos\n  facet_wrap(~ mes, ncol = 1, strip.position = \"top\", labeller = label_value) +\n  \n## Barras (eje primario)\n  geom_bar(aes(y = porcentaje), stat = \"identity\", fill = \"red\", alpha = 0.1) +\n  \n## Puntos (eje secundario)\n  geom_point(data = pref_j, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color = Var1), size = 3, alpha = 0.7) +\n  \n## Etiquetas en los puntos que evitan la superposición\n  geom_text_repel(data = pref_j, \n                  aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), \n                      label = round(Freq, 0)), \n                  size = 2.7, show.legend = FALSE) +\n  \n## Tema y etiquetas\n  theme_classic() +\n  labs(\n    x = \"Posición ideológica (1-10)\",\n    caption = \"Evolución de preferencias por cada candidato para los votantes del PSOE según su ideología\\n Los valores 7 a 10 de las escala se han omitido debido a la baja frecuencia de votantes socialistas\",\n    color = \"Preferencia por:\") +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10),\n    legend.text = element_text(size = 9),\n    axis.title = element_text(size = 14),\n    strip.background = element_blank()) +\n  \n## Ejes con escalas independientes\n  scale_y_continuous(\n    name = \"Porcentaje de votantes\", # Eje izquierdo\n    sec.axis = sec_axis(~ . * max(pref_j$Freq) / max(ideol_psoe$porcentaje), name = \"Preferencia de candidatos\")) + # Eje derecho\n\n## Colores personalizado\n  scale_color_manual(\n    values = c(\"Sánchez\" = \"red\", \"Casado/Feijoo\" = \"blue\", \"Indiferente\" = \"grey\")) +\n\n## Establecer valores del eje x\n  scale_x_continuous(breaks = seq(1, 6, by = 1))\n\n\n\n\n\n\n\n\n\n\n\nideol_psoe_j\n\n\n\n\n\n\n\npref_j",
    "crumbs": [
      "Gráficos",
      "Otros gráficos"
    ]
  },
  {
    "objectID": "graficos/g-otros.html#líneas-barras",
    "href": "graficos/g-otros.html#líneas-barras",
    "title": "Otros gráficos",
    "section": "Líneas + barras",
    "text": "Líneas + barras\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(ideol_psoe, aes(x = ideol)) +\n  geom_bar(aes(y = porcentaje), stat = \"identity\", fill=\"red\", alpha = 0.1)+\n  geom_line(data = pref, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color=Var1), size = 0.8)+\n  geom_point(data = pref, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color=Var1))+\n    geom_text(data=pref, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje),label = round(Freq, 0)), vjust = -0.7, hjust = 0.3, size = 2.7,show.legend = F)+  \n  theme_classic() +\n  labs(\n    x = \"Posición ideológica (1-10)\",\n    caption = \"Evolución de las preferencias por los candidatos para los votantes del PSOE según su ideología\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    legend.text = element_text(size = 9),\n    axis.title = element_text(size = 10)\n  ) +\n  scale_y_continuous(\n    name = \"Porcentaje de votantes\", # Eje izquierdo\n    sec.axis = sec_axis(~ . * max(pref$Freq) / max(ideol_psoe$porcentaje), name = \"Preferencia de candidatos\") # Eje derecho\n  )+\n  scale_color_manual(values=c(\"Sánchez\"=\"red\",\"Casado\"=\"blue\",\"Indiferente\"=\"grey\"))+\n  scale_x_continuous(breaks = seq(1,10,by=2))\n\n\nggplot(ideol_psoe, aes(x = ideol)) +\n\n## Barras (eje primario)\n  geom_bar(aes(y = porcentaje), \n           stat = \"identity\", # Hay que añadirlo porque los datos ya están en formato un % por cada valor del eje x\n           fill=\"red\", # Color de las barras\n           alpha = 0.1)+ # Nivel de transparencia de las barras\n\n## Línea (eje secundario)\n  geom_line(data = pref, aes(x = ideol, # Datos nuevos para las líneas\n                             y = Freq / max(Freq) * max(ideol_psoe$porcentaje), # Es neesaria esta transformación para que haya dos ejes independientes\n                             group = Var1, color=Var1), # Variables de agrupación para que haya varias líneas\n            size = 0.8)+ # El tamaño de las líneas\n\n## Puntos de las líneas\n  geom_point(data = pref, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje), group = Var1, color=Var1))+\n\n## Texto de los % sobre cada punto de las líneas\n    geom_text(data=pref, aes(x = ideol, y = Freq / max(Freq) * max(ideol_psoe$porcentaje),label = round(Freq, 0)), vjust = -0.7, hjust = 0.3, size = 2.7,show.legend = F)+\n\n## Tema y etiquetas\n  theme_classic() + # Tema con el fondo en blanco\n  labs(\n    x = \"Posición ideológica (1-10)\", # Etiqueta del eje x\n    caption = \"Evolución de las preferencias por los candidatos para los votantes del PSOE según su ideología\" \n    # El caption es el texto en el pie del gráfico\n  ) +\n  theme(\n    legend.position = \"bottom\", # Posición de la leyenda (abajo en lugar de en el lado)\n    legend.title = element_blank(), # Para eliminar el título del gráfico\n    legend.text = element_text(size = 9), # Tamaño de la leyenda\n    axis.title = element_text(size = 10) # Tamaño de los títulos de los ejes\n  ) +\n\n## Dos ejes con escalas independientes\n  scale_y_continuous(\n    name = \"Porcentaje de votantes\", # Eje izquierdo\n    sec.axis = sec_axis(~ . * max(pref$Freq) / max(ideol_psoe$porcentaje), name = \"Preferencia de candidatos\"))+ # Eje derecho\n  scale_color_manual(values=c(\"Sánchez\"=\"red\",\"Casado\"=\"blue\",\"Indiferente\"=\"grey\"))+ # Cambiar el color de las líneas\n\n## Personalizar el eje x\n  scale_x_continuous(breaks = seq(1,10,by=2))\n\n\n\n\n\n\n\n\n\n\n\nideol_psoe\n\n\n\n\n\n\n\npref",
    "crumbs": [
      "Gráficos",
      "Otros gráficos"
    ]
  },
  {
    "objectID": "graficos/g-otros.html#gráficos-de-cajas-y-violines",
    "href": "graficos/g-otros.html#gráficos-de-cajas-y-violines",
    "title": "Otros gráficos",
    "section": "Gráficos de cajas y violines",
    "text": "Gráficos de cajas y violines\n\nGráfico de cajas\n\nGráficoCódigoCódigo anotado\n\n\n\n\n\n\n\n\n\nggplot(data = desempleo_juvenil, aes(x = Country, y = Value, fill=Country)) +\n  geom_boxplot(color=\"black\",\n               alpha=0.3) +\n  geom_jitter(color=\"black\", size=0.4, alpha=0.3)+\n  ggtitle(\"Diagrama de cajas y evolución temporal del paro juvenil\")+\n  theme_classic()+\n  labs(\n    x = \"País\",\n    y = \"Desempleo juvenil (%)\") +\n  stat_boxplot(geom = \"errorbar\",\n               width = 0.25) +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5, size = 11))+\n  scale_x_discrete(labels = c(Spain = \"España\", Italy = \"Italia\", Netherlands = \"Paises Bajos\")) +\n  scale_fill_manual(\n    values = c(Spain = \"blue\", Italy = \"red\", Austria = \"purple\", Netherlands = \"green\"))\n\n\nggplot(data = desempleo_juvenil, aes(x = Country, y = Value, fill=Country)) +\n\n## Comando del gráfico de cajas\n    geom_boxplot(color=\"black\", # Bordes de color negro\n               alpha=0.3) + # Transparencia del relleno\n\n## Añadir los puntos de distribución\n    geom_jitter(color=\"black\", size=0.4, alpha=0.3)+\n\n## Personalización del gráfico\n  ggtitle(\"Diagrama de cajas y evolución temporal del paro juvenil\")+ # Añadirle un título\n  theme_classic()+ #Tema con el fondo blanco\n  labs( # Etiquetas de los ejes\n    x = \"País\",\n    y = \"Desempleo juvenil (%)\") +\n  stat_boxplot(geom = \"errorbar\",width = 0.25)+ # Añade las líneas horizontales que indican los datos extremos (si no lo pones solo aparecen las verticales)\n  theme(legend.position = \"none\", # Elimina la leyenda\n        plot.title = element_text(hjust = 0.5, size = 11))+ # Ajustes del título\n  scale_x_discrete(labels = c(Spain = \"España\", Italy = \"Italia\", Netherlands = \"Paises Bajos\")) + # Cambiar el nombre de las etiquetas del eje x\n  scale_fill_manual(values = c(Spain = \"blue\", Italy = \"red\", Austria = \"purple\", Netherlands = \"green\")) # Cambiar los colores\n\n\n\n\n\nGráfico de violines\n\nGráficoCódigoCódigo anotado\n\n\n\n\n\n\n\n\n\nggplot(datos,aes(x=intención, y=ideol, fill=intención))+\n  theme_classic()+\n  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 2))+\n  geom_hline(yintercept = c(0,2,4,6,8,10), color = \"lightgrey\", alpha = 0.5)+\n  geom_violin(width=1, alpha=0.5, adjust = 1.6)+ #width es para hacer más ancho cada violin, y adjust para lo suaves que son las curvas\n  geom_boxplot(width=0.1, color=\"grey\", alpha=0.4) +\n  scale_fill_manual(values = c(PP = \"#458CFF\", PSOE = \"red\", Podemos = \"purple\", Vox = \"green\", Sumar=\"pink\",SALF=\"darkgrey\"))+\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position=\"none\")+\n  labs(title=\"Media ideología de los votantes de cada partido\",\n       x=\"Votantes de cada partido\\n(intención)\", \n       y=\"Ideología\\n(0-10)\",\n       caption=\"Fuente: elaboración propia. Datos de 40dB\")\n\n\nggplot(datos,aes(x=intención, y=ideol, fill=intención))+\n\n## Líneas horizontales de fondo\n  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, by = 2))+ # Los límites del eje y\n  geom_hline(yintercept = c(0,2,4,6,8,10), color = \"lightgrey\", alpha = 0.5)+ # Las líneas grises de fondo\n\n## Gráfico de violines\n  geom_violin(width=1, alpha=0.5, adjust = 1.6)+ #width es para hacer más ancho cada violin, y adjust para lo suaves que son las curvas\n\n## Gráfico de cajas dentro de los violines\n  geom_boxplot(width=0.1, color=\"grey\", alpha=0.4) +\n\n## Personalización del gráfico\n  scale_fill_manual(values = c(PP = \"#458CFF\", PSOE = \"red\", Podemos = \"purple\", Vox = \"green\", Sumar=\"pink\",SALF=\"darkgrey\"))+ # Cambiar los colores\n  theme_classic()+ # El tema del fondo\n  theme(plot.title = element_text(hjust = 0.5), # Centrar el título\n        legend.position=\"none\")+ # Eliminar la leyenda\n  labs(title=\"Media ideología de los votantes de cada partido\",\n       x=\"Votantes de cada partido\\n(intención)\", \n       y=\"Ideología\\n(0-10)\", \n       caption=\"Fuente: elaboración propia. Datos de 40dB\")",
    "crumbs": [
      "Gráficos",
      "Otros gráficos"
    ]
  },
  {
    "objectID": "graficos/g-lineas.html",
    "href": "graficos/g-lineas.html",
    "title": "Gráficos de líneas",
    "section": "",
    "text": "GráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(cis_pop_recu, aes(x=mes, y=Feijoo, color=recuerdo, group=recuerdo)) +\n  geom_hline(yintercept = seq(1, 10, by = 1), color = \"lightgrey\", alpha = 0.5)+\n  geom_line(linewidth=0.9, linetype=1)+\n  geom_point()+\n  theme_classic()+\n  labs(x=\"Mes de la encuesta\",\n       y=\"Valoración media (1 al 10)\",\n       caption = \"Evolución de la valoración de Alberto Nuñez Feijoo según el recuerdo de voto\\nFuente: elaboración propia a partir de los datos del CIS\")+\n  theme(\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 10))+\n  scale_color_manual(values=colores_cis)+\n    geom_text(aes(label = round(Feijoo, 1)), vjust = -0.5, size = 2.5,show.legend = F)+\n  scale_y_continuous(limits = c(1,10), breaks = seq(0,10, by=2))\n\n\nggplot(cis_pop_recu, aes(x=mes, y=Feijoo, color=recuerdo, group=recuerdo)) +\n\n## Líneas grises de fondo\n  geom_hline(yintercept = seq(1, 10, by = 1), color = \"lightgrey\", alpha = 0.5)+\n  \n## Líneas, puntos y anotaciones\n  geom_line(linewidth=0.9, linetype=1)+\n  geom_point()+\n  geom_text(aes(label = round(Feijoo, 1)), vjust = -0.5, size = 2.5,show.legend = F)+\n  \n## Otros ajustes\n  scale_y_continuous(limits = c(1,10), breaks = seq(0,10, by=2))+ # Personalizar el eje x\n  theme_classic()+ # El tema del fondo (en blanco)\n  labs(x=\"Mes de la encuesta\", # Etiqueta del eje x\n       y=\"Valoración media (1 al 10)\", #La etiqueta del eje y\n       caption = \"Evolución de la valoración de Alberto Nuñez Feijoo según el recuerdo de voto\\nFuente: elaboración propia a partir de los datos del CIS\")+ # El texto del pio\n  theme(\n        legend.position = \"bottom\", # Posición de la leyenda\n        legend.title = element_blank(), # Leyenda sin título\n        legend.text = element_text(size = 9), # Tamaño de la leyenda\n        axis.title = element_text(size = 10))+\n  scale_color_manual(values=colores_cis) # Colores personalizados para cada partido (se establece antes la equivalencia en un vector)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(data = gasto_desempleo, aes(x = TIME, y = Value, color = Country, group = Country)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    x = \"Año\",\n    y = \"% PIB\",\n    color = \"Países\",\n    caption = \"Fuente: elaboración propia a partir de datos de Eurostat\") +\n  ggtitle(\"Gasto gubernamental en prestaciones por desempleo\") +\n  theme(plot.title = element_text(hjust = 0.5))+\n  scale_color_manual(values = c(Spain = \"blue\", Italy = \"red\", Netherlands = \"green\", Austria = \"purple\")) +\n  theme_minimal() +\n  scale_x_continuous(\n    limits = c(2000, 2019),\n    breaks = c(2000, 2004, 2008, 2012, 2016, 2019),\n    labels = scales::number_format(accuracy = 1)) +\n  geom_vline(xintercept = 2008, linetype = \"dashed\", color = \"black\")\n\n\nggplot(data = gasto_desempleo, aes(x = TIME, y = Value, color = Country, group = Country)) +\n\n## Líneas + puntos\n  geom_line() +\n  geom_point() +\n  \n## Etiquetas\n  labs(\n    x = \"Año\",\n    y = \"% PIB\",\n    color = \"Países\",\n    caption = \"Fuente: elaboración propia a partir de datos de Eurostat\") +\n  ggtitle(\"Gasto gubernamental en prestaciones por desempleo\")+\n  theme(plot.title = element_text(hjust = 0.5))+ # Para centrar el título del gráfico\n  \n## Colores personalizados para las líneas\n  scale_color_manual(values = c(Spain = \"blue\", Italy = \"red\", Netherlands = \"green\", Austria = \"purple\")) +\n  \n## Tema del gráfico\n  theme_minimal() +\n## Ajuste de las cifras mostradas en el eje x\n  scale_x_continuous(\n    limits = c(2000, 2019),\n    breaks = c(2000, 2004, 2008, 2012, 2016, 2019),\n    labels = scales::number_format(accuracy = 1)) +\n    \n## Añadir línea de puntos vertical para el año 2008\n  geom_vline(xintercept = 2008, linetype = \"dashed\", color = \"black\")",
    "crumbs": [
      "Gráficos",
      "Gráficos de líneas"
    ]
  },
  {
    "objectID": "graficos/g-lineas.html#evolución-temporal",
    "href": "graficos/g-lineas.html#evolución-temporal",
    "title": "Gráficos de líneas",
    "section": "",
    "text": "GráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(cis_pop_recu, aes(x=mes, y=Feijoo, color=recuerdo, group=recuerdo)) +\n  geom_hline(yintercept = seq(1, 10, by = 1), color = \"lightgrey\", alpha = 0.5)+\n  geom_line(linewidth=0.9, linetype=1)+\n  geom_point()+\n  theme_classic()+\n  labs(x=\"Mes de la encuesta\",\n       y=\"Valoración media (1 al 10)\",\n       caption = \"Evolución de la valoración de Alberto Nuñez Feijoo según el recuerdo de voto\\nFuente: elaboración propia a partir de los datos del CIS\")+\n  theme(\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 10))+\n  scale_color_manual(values=colores_cis)+\n    geom_text(aes(label = round(Feijoo, 1)), vjust = -0.5, size = 2.5,show.legend = F)+\n  scale_y_continuous(limits = c(1,10), breaks = seq(0,10, by=2))\n\n\nggplot(cis_pop_recu, aes(x=mes, y=Feijoo, color=recuerdo, group=recuerdo)) +\n\n## Líneas grises de fondo\n  geom_hline(yintercept = seq(1, 10, by = 1), color = \"lightgrey\", alpha = 0.5)+\n  \n## Líneas, puntos y anotaciones\n  geom_line(linewidth=0.9, linetype=1)+\n  geom_point()+\n  geom_text(aes(label = round(Feijoo, 1)), vjust = -0.5, size = 2.5,show.legend = F)+\n  \n## Otros ajustes\n  scale_y_continuous(limits = c(1,10), breaks = seq(0,10, by=2))+ # Personalizar el eje x\n  theme_classic()+ # El tema del fondo (en blanco)\n  labs(x=\"Mes de la encuesta\", # Etiqueta del eje x\n       y=\"Valoración media (1 al 10)\", #La etiqueta del eje y\n       caption = \"Evolución de la valoración de Alberto Nuñez Feijoo según el recuerdo de voto\\nFuente: elaboración propia a partir de los datos del CIS\")+ # El texto del pio\n  theme(\n        legend.position = \"bottom\", # Posición de la leyenda\n        legend.title = element_blank(), # Leyenda sin título\n        legend.text = element_text(size = 9), # Tamaño de la leyenda\n        axis.title = element_text(size = 10))+\n  scale_color_manual(values=colores_cis) # Colores personalizados para cada partido (se establece antes la equivalencia en un vector)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(data = gasto_desempleo, aes(x = TIME, y = Value, color = Country, group = Country)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    x = \"Año\",\n    y = \"% PIB\",\n    color = \"Países\",\n    caption = \"Fuente: elaboración propia a partir de datos de Eurostat\") +\n  ggtitle(\"Gasto gubernamental en prestaciones por desempleo\") +\n  theme(plot.title = element_text(hjust = 0.5))+\n  scale_color_manual(values = c(Spain = \"blue\", Italy = \"red\", Netherlands = \"green\", Austria = \"purple\")) +\n  theme_minimal() +\n  scale_x_continuous(\n    limits = c(2000, 2019),\n    breaks = c(2000, 2004, 2008, 2012, 2016, 2019),\n    labels = scales::number_format(accuracy = 1)) +\n  geom_vline(xintercept = 2008, linetype = \"dashed\", color = \"black\")\n\n\nggplot(data = gasto_desempleo, aes(x = TIME, y = Value, color = Country, group = Country)) +\n\n## Líneas + puntos\n  geom_line() +\n  geom_point() +\n  \n## Etiquetas\n  labs(\n    x = \"Año\",\n    y = \"% PIB\",\n    color = \"Países\",\n    caption = \"Fuente: elaboración propia a partir de datos de Eurostat\") +\n  ggtitle(\"Gasto gubernamental en prestaciones por desempleo\")+\n  theme(plot.title = element_text(hjust = 0.5))+ # Para centrar el título del gráfico\n  \n## Colores personalizados para las líneas\n  scale_color_manual(values = c(Spain = \"blue\", Italy = \"red\", Netherlands = \"green\", Austria = \"purple\")) +\n  \n## Tema del gráfico\n  theme_minimal() +\n## Ajuste de las cifras mostradas en el eje x\n  scale_x_continuous(\n    limits = c(2000, 2019),\n    breaks = c(2000, 2004, 2008, 2012, 2016, 2019),\n    labels = scales::number_format(accuracy = 1)) +\n    \n## Añadir línea de puntos vertical para el año 2008\n  geom_vline(xintercept = 2008, linetype = \"dashed\", color = \"black\")",
    "crumbs": [
      "Gráficos",
      "Gráficos de líneas"
    ]
  },
  {
    "objectID": "graficos/g-lineas.html#líneas-rellenas",
    "href": "graficos/g-lineas.html#líneas-rellenas",
    "title": "Gráficos de líneas",
    "section": "Líneas rellenas",
    "text": "Líneas rellenas\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nlibrary(ggh4x)\n\ng&lt;-ggplot(data = brecha_edad, aes(x=edad)) + #y=porcentaje, color=genero, group=genero\n  scale_x_continuous(limits=c(15,90),breaks=c(10,20,30,40,50,60,70,80,90))+\n  scale_y_continuous(limits=c(0,40),breaks=c(0,10,20,30,40))+\n  geom_hline(yintercept = c(0, 10, 20,30,40), color = \"lightgrey\", alpha = 0.5)+\n  geom_vline(xintercept=c(35,65), color=\"black\", linetype=\"dashed\")+\n  theme_classic()+\n  labs(x=\"Edad\",y=\"Porcentaje de manifestantes\",caption = \"Figura 2: Porcentaje de manifestantes para cada edad según su género\" )+\n  theme(plot.caption = element_text(hjust=0,family=\"Times New Roman\",size=15), #Ajustes del caption\n        text = element_text(size = 11),\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 10),\n        axis.title = element_text(size = 12)) +\n  geom_line(aes(y=Mujer),color=\"#51DA2C\",size=1.15)+\n  geom_line(aes(y=Hombre),color=\"#130081\",size=1.15)+\n  stat_difference(aes(ymin = Hombre, ymax = Mujer), alpha = 0.5,) +\n  scale_fill_manual(values = c(\"#51DA2C\", \"#130081\"), labels=c(\"Mujer\",\"Hombre\"))\ng+annotate(\"text\",x=c(23,50,80), y=c(39,39,39),label=c(\"Jóvenes\", \"Adultos\", \"Ancianos\"),size=3.6)\n\n\nlibrary(ggh4x)\n\ng&lt;-ggplot(data = brecha_edad, aes(x=edad)) +\n\n## Personalizar los ejes\n  scale_x_continuous(limits=c(15,90),breaks=c(10,20,30,40,50,60,70,80,90))+\n  scale_y_continuous(limits=c(0,40),breaks=c(0,10,20,30,40))+\n  geom_hline(yintercept = c(0, 10, 20,30,40), color = \"lightgrey\", alpha = 0.5)+\n  geom_vline(xintercept=c(35,65), color=\"black\", linetype=\"dashed\")+\n  \n## Ajustes estéticos del gráfico\n  theme_classic()+\n  labs(x=\"Edad\",y=\"Porcentaje de manifestantes\",caption = \"Figura 2: Porcentaje de manifestantes para cada edad según su género\" )+\n  theme(plot.caption = element_text(hjust=0,family=\"Times New Roman\",size=15), \n        text = element_text(size = 11),\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 10),\n        axis.title = element_text(size = 12)) +\n        \n## Lineas y relleno\n  geom_line(aes(y=Mujer),color=\"#51DA2C\",size=1.15)+ # Línea para las mujeres\n  geom_line(aes(y=Hombre),color=\"#130081\",size=1.15)+ # Línea para los hombres\n  stat_difference(aes(ymin = Hombre, ymax = Mujer), alpha = 0.5,) + # El relleno entre las líneas\n  scale_fill_manual(values = c(\"#51DA2C\", \"#130081\"), labels=c(\"Mujer\",\"Hombre\")) # Personalizar el relleno \n\n## Añadir las etiquetas de la edad\ng+annotate(\"text\",x=c(23,50,80), y=c(39,39,39),label=c(\"Jóvenes\", \"Adultos\", \"Ancianos\"),size=3.6)\n\n\nEl mismo que en los casos anteriores (tres columnas, datos alargados)",
    "crumbs": [
      "Gráficos",
      "Gráficos de líneas"
    ]
  },
  {
    "objectID": "graficos/g-barras.html",
    "href": "graficos/g-barras.html",
    "title": "Gráficos de barras",
    "section": "",
    "text": "GráficoCódigoCódigo anotado\n\n\n\n\n\n\n\n\n\nggplot(datos, aes(x = ideol, y = freq, fill = partido)) +\n  geom_hline(yintercept = c(0, 5, 10, 15, 20, 25), color = \"lightgrey\", alpha = 0.5) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha=0.8) +\n  theme_classic() +\n  labs(x = \"Posición ideológica (0-10)\",\n       y = \"Porcentaje de votantes\",\n       caption = \"Distribución en la escala ideológica de los votantes del PP y PSOE\\nFuente: elaboración propia a partir de los datos de 40db\") +\n  geom_text(aes(label = paste0(round(freq, 1), \"%\")), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+\n  scale_fill_manual(values=c(\"PP\"=\"#17589d\", \"PSOE\"=\"#FF1C1C\"))+\n  theme(\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 10))\n\n\nggplot(datos, aes(x = ideol, y = freq, fill = partido)) +\n\n## Línes de fondo para indicar los valores del eje y\n  geom_hline(yintercept = c(0, 5, 10, 15, 20, 25), color = \"lightgrey\", alpha = 0.5) +\n  \n## Las barras\n  geom_bar(stat = \"identity\", position = \"dodge\",\n           alpha=0.8) + # Alpha indica la transparencia de las barras (cuanto menor es el número, más transparentes)\n\n## Ajustes estéticos\n  theme_classic() + # Tema del fondo (en blanco)\n  labs(x = \"Posición ideológica (0-10)\", # Etiqueta eje x\n       y = \"Porcentaje de votantes\", # Etiqueta eje y\n       caption = \"Distribución en la escala ideológica de los votantes del PP y PSOE\\nFuente: elaboración propia a partir de los datos de 40db\") + # Texto a pie de gráfico. El \\n indica que se pasa a otra línea.\n  geom_text(aes(label = paste0(round(freq, 1), \"%\")), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+ # Los números del % encima de las barras\n  scale_fill_manual(values=c(\"PP\"=\"#17589d\", \"PSOE\"=\"#FF1C1C\"))+ # Color del relleno\n  theme( #Ajustes del tamaño y posición de los títulos\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 10))\n\n\n\n\n\n\n\nGráficoCódigoCódigo anotado\n\n\n\n\n\n\n\n\n\nggplot(brecha_gen, aes(x = gen, y = porcentaje, fill = genero)) +\n  scale_y_continuous(limits=c(0,30))+\n  geom_hline(yintercept = c(0, 10, 20,30), color = \"lightgrey\", alpha = 0.5) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.94), width = 0.87, colour=\"black\") +\n  labs(x = \"Generación\", y = \"Porcentaje de manifestantes\", fill = \"Género\", caption = \"Figura 3: Porcentaje de manifestantes en cada generación según su género\") +\n  theme_classic() +\n  geom_text(aes(label = porcentaje, y = porcentaje + 1),\n            position = position_dodge(width = 1), vjust = 1.1, size = 3) +\n  theme(plot.caption = element_text(hjust=0,family=\"Times New Roman\",size=15), #Ajustes del caption\n        text = element_text(size = 11),  # Tamaño del texto del gráfico\n        legend.position = \"bottom\",      # Posición de la leyenda\n        legend.title = element_blank(),   # Elimina el título de la leyenda\n        legend.text = element_text(size = 9),  # Tamaño del texto de la leyenda\n        axis.title = element_text(size = 12)) +  # Tamaño del texto de los títulos de los ejes\n  scale_fill_manual(values=c(\"Hombre\"=\"#d8d8d8\", \"Mujer\"=\"#777777\"))\n\n\nggplot(brecha_gen, aes(x = gen, y = porcentaje, fill = genero)) +\n\n## Ajustes del eje y: limites y líneas grises del fondo\n  scale_y_continuous(limits=c(0,30))+\n  geom_hline(yintercept = c(0, 10, 20,30), color = \"lightgrey\", alpha = 0.5) +\n\n## El gráfico de barras\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.94), width = 0.87, colour=\"black\") +\n\n## Otros ajustes estéticos (iguales que en el gráfico anterior)\n  labs(x = \"Generación\", y = \"Porcentaje de manifestantes\", fill = \"Género\", caption = \"Figura 3: Porcentaje de manifestantes en cada generación según su género\") +\n  theme_classic() +\n  geom_text(aes(label = porcentaje, y = porcentaje + 1),\n            position = position_dodge(width = 1), vjust = 1.1, size = 3) +\n  theme(plot.caption = element_text(hjust=0,family=\"Times New Roman\",size=15), #Ajustes del caption\n        text = element_text(size = 11),  # Tamaño del texto del gráfico\n        legend.position = \"bottom\",      # Posición de la leyenda\n        legend.title = element_blank(),   # Elimina el título de la leyenda\n        legend.text = element_text(size = 9),  # Tamaño del texto de la leyenda\n        axis.title = element_text(size = 12)) +  # Tamaño del texto de los títulos de los ejes\n  scale_fill_manual(values=c(\"Hombre\"=\"#d8d8d8\", \"Mujer\"=\"#777777\"))\n\n\n\n\n\n\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(diferencias_dcha, aes(x = Tema, y = diferencias, fill = Partido)) +\n  geom_hline(yintercept = seq(0,5,by=0.5), color = \"lightgrey\", alpha = 0.3) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha=0.8) +\n  theme_classic() +\n  labs(x = NULL,\n       y = \"Diferencia (0-10)\",\n       caption = \"Distancia entre el Vox y PP y los votantes de derechas y centro.\\nLa distancia se ha medido como la resta de la media del partido menos la del grupo ideológico (términos absolutos).\",\n       fill=\"Partido-ideología:\") +\n  geom_text(aes(label = round(diferencias, 2)), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 12))+\n  scale_fill_manual(\n    values = c(\"PP_c\"=\"#85B9ED\",\"PP_d\"=\"#17589d\",\"Vox_c\"=\"#B3E384\",\"Vox_d\"=\"#63ac33\"),\n    labels = c(\"PP_c\" = \"PP (centro)\",\"PP_d\" = \"PP (derecha)\",\"Vox_c\" = \"Vox (centro)\",\"Vox_d\" = \"Vox (derecha)\"))+\n  scale_x_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))\n\n\nggplot(diferencias_dcha, aes(x = Tema, y = diferencias, fill = Partido)) +\n\n## Ajustes del eje y: líneas grises del fondo\n  geom_hline(yintercept = seq(0,5,by=0.5), color = \"lightgrey\", alpha = 0.3) +\n\n## El gráfico de barras\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha=0.8) +\n\n## Otros ajustes estéticos (iguales que en el primer gráfico)\n  theme_classic() +\n  labs(x = NULL,\n       y = \"Diferencia (0-10)\",\n       caption = \"Distancia entre el Vox y PP y los votantes de derechas y centro.\\nLa distancia se ha medido como la resta de la media del partido menos la del grupo ideológico (términos absolutos).\",\n       fill=\"Partido-ideología:\") +\n  geom_text(aes(label = round(diferencias, 2)), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 12))+\n  scale_fill_manual(\n    values = c(\"PP_c\"=\"#85B9ED\",\"PP_d\"=\"#17589d\",\"Vox_c\"=\"#B3E384\",\"Vox_d\"=\"#63ac33\"),\n    labels = c(\"PP_c\" = \"PP (centro)\",\"PP_d\" = \"PP (derecha)\",\"Vox_c\" = \"Vox (centro)\",\"Vox_d\" = \"Vox (derecha)\"))+\n\n## Para cambiar las etiquetas del eje x\n  scale_x_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))",
    "crumbs": [
      "Gráficos",
      "Gráficos de barras"
    ]
  },
  {
    "objectID": "graficos/g-barras.html#barras-divididas-según-una-tercera-variable",
    "href": "graficos/g-barras.html#barras-divididas-según-una-tercera-variable",
    "title": "Gráficos de barras",
    "section": "",
    "text": "GráficoCódigoCódigo anotado\n\n\n\n\n\n\n\n\n\nggplot(datos, aes(x = ideol, y = freq, fill = partido)) +\n  geom_hline(yintercept = c(0, 5, 10, 15, 20, 25), color = \"lightgrey\", alpha = 0.5) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha=0.8) +\n  theme_classic() +\n  labs(x = \"Posición ideológica (0-10)\",\n       y = \"Porcentaje de votantes\",\n       caption = \"Distribución en la escala ideológica de los votantes del PP y PSOE\\nFuente: elaboración propia a partir de los datos de 40db\") +\n  geom_text(aes(label = paste0(round(freq, 1), \"%\")), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+\n  scale_fill_manual(values=c(\"PP\"=\"#17589d\", \"PSOE\"=\"#FF1C1C\"))+\n  theme(\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 10))\n\n\nggplot(datos, aes(x = ideol, y = freq, fill = partido)) +\n\n## Línes de fondo para indicar los valores del eje y\n  geom_hline(yintercept = c(0, 5, 10, 15, 20, 25), color = \"lightgrey\", alpha = 0.5) +\n  \n## Las barras\n  geom_bar(stat = \"identity\", position = \"dodge\",\n           alpha=0.8) + # Alpha indica la transparencia de las barras (cuanto menor es el número, más transparentes)\n\n## Ajustes estéticos\n  theme_classic() + # Tema del fondo (en blanco)\n  labs(x = \"Posición ideológica (0-10)\", # Etiqueta eje x\n       y = \"Porcentaje de votantes\", # Etiqueta eje y\n       caption = \"Distribución en la escala ideológica de los votantes del PP y PSOE\\nFuente: elaboración propia a partir de los datos de 40db\") + # Texto a pie de gráfico. El \\n indica que se pasa a otra línea.\n  geom_text(aes(label = paste0(round(freq, 1), \"%\")), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+ # Los números del % encima de las barras\n  scale_fill_manual(values=c(\"PP\"=\"#17589d\", \"PSOE\"=\"#FF1C1C\"))+ # Color del relleno\n  theme( #Ajustes del tamaño y posición de los títulos\n        legend.position = \"bottom\",\n        legend.title = element_blank(), \n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 10))\n\n\n\n\n\n\n\nGráficoCódigoCódigo anotado\n\n\n\n\n\n\n\n\n\nggplot(brecha_gen, aes(x = gen, y = porcentaje, fill = genero)) +\n  scale_y_continuous(limits=c(0,30))+\n  geom_hline(yintercept = c(0, 10, 20,30), color = \"lightgrey\", alpha = 0.5) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.94), width = 0.87, colour=\"black\") +\n  labs(x = \"Generación\", y = \"Porcentaje de manifestantes\", fill = \"Género\", caption = \"Figura 3: Porcentaje de manifestantes en cada generación según su género\") +\n  theme_classic() +\n  geom_text(aes(label = porcentaje, y = porcentaje + 1),\n            position = position_dodge(width = 1), vjust = 1.1, size = 3) +\n  theme(plot.caption = element_text(hjust=0,family=\"Times New Roman\",size=15), #Ajustes del caption\n        text = element_text(size = 11),  # Tamaño del texto del gráfico\n        legend.position = \"bottom\",      # Posición de la leyenda\n        legend.title = element_blank(),   # Elimina el título de la leyenda\n        legend.text = element_text(size = 9),  # Tamaño del texto de la leyenda\n        axis.title = element_text(size = 12)) +  # Tamaño del texto de los títulos de los ejes\n  scale_fill_manual(values=c(\"Hombre\"=\"#d8d8d8\", \"Mujer\"=\"#777777\"))\n\n\nggplot(brecha_gen, aes(x = gen, y = porcentaje, fill = genero)) +\n\n## Ajustes del eje y: limites y líneas grises del fondo\n  scale_y_continuous(limits=c(0,30))+\n  geom_hline(yintercept = c(0, 10, 20,30), color = \"lightgrey\", alpha = 0.5) +\n\n## El gráfico de barras\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.94), width = 0.87, colour=\"black\") +\n\n## Otros ajustes estéticos (iguales que en el gráfico anterior)\n  labs(x = \"Generación\", y = \"Porcentaje de manifestantes\", fill = \"Género\", caption = \"Figura 3: Porcentaje de manifestantes en cada generación según su género\") +\n  theme_classic() +\n  geom_text(aes(label = porcentaje, y = porcentaje + 1),\n            position = position_dodge(width = 1), vjust = 1.1, size = 3) +\n  theme(plot.caption = element_text(hjust=0,family=\"Times New Roman\",size=15), #Ajustes del caption\n        text = element_text(size = 11),  # Tamaño del texto del gráfico\n        legend.position = \"bottom\",      # Posición de la leyenda\n        legend.title = element_blank(),   # Elimina el título de la leyenda\n        legend.text = element_text(size = 9),  # Tamaño del texto de la leyenda\n        axis.title = element_text(size = 12)) +  # Tamaño del texto de los títulos de los ejes\n  scale_fill_manual(values=c(\"Hombre\"=\"#d8d8d8\", \"Mujer\"=\"#777777\"))\n\n\n\n\n\n\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(diferencias_dcha, aes(x = Tema, y = diferencias, fill = Partido)) +\n  geom_hline(yintercept = seq(0,5,by=0.5), color = \"lightgrey\", alpha = 0.3) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha=0.8) +\n  theme_classic() +\n  labs(x = NULL,\n       y = \"Diferencia (0-10)\",\n       caption = \"Distancia entre el Vox y PP y los votantes de derechas y centro.\\nLa distancia se ha medido como la resta de la media del partido menos la del grupo ideológico (términos absolutos).\",\n       fill=\"Partido-ideología:\") +\n  geom_text(aes(label = round(diferencias, 2)), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 12))+\n  scale_fill_manual(\n    values = c(\"PP_c\"=\"#85B9ED\",\"PP_d\"=\"#17589d\",\"Vox_c\"=\"#B3E384\",\"Vox_d\"=\"#63ac33\"),\n    labels = c(\"PP_c\" = \"PP (centro)\",\"PP_d\" = \"PP (derecha)\",\"Vox_c\" = \"Vox (centro)\",\"Vox_d\" = \"Vox (derecha)\"))+\n  scale_x_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))\n\n\nggplot(diferencias_dcha, aes(x = Tema, y = diferencias, fill = Partido)) +\n\n## Ajustes del eje y: líneas grises del fondo\n  geom_hline(yintercept = seq(0,5,by=0.5), color = \"lightgrey\", alpha = 0.3) +\n\n## El gráfico de barras\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha=0.8) +\n\n## Otros ajustes estéticos (iguales que en el primer gráfico)\n  theme_classic() +\n  labs(x = NULL,\n       y = \"Diferencia (0-10)\",\n       caption = \"Distancia entre el Vox y PP y los votantes de derechas y centro.\\nLa distancia se ha medido como la resta de la media del partido menos la del grupo ideológico (términos absolutos).\",\n       fill=\"Partido-ideología:\") +\n  geom_text(aes(label = round(diferencias, 2)), position = position_dodge(width = 0.9), vjust = -0.5, size = 3)+\n  theme(legend.position = \"bottom\",\n        legend.text = element_text(size = 9),\n        axis.title = element_text(size = 12))+\n  scale_fill_manual(\n    values = c(\"PP_c\"=\"#85B9ED\",\"PP_d\"=\"#17589d\",\"Vox_c\"=\"#B3E384\",\"Vox_d\"=\"#63ac33\"),\n    labels = c(\"PP_c\" = \"PP (centro)\",\"PP_d\" = \"PP (derecha)\",\"Vox_c\" = \"Vox (centro)\",\"Vox_d\" = \"Vox (derecha)\"))+\n\n## Para cambiar las etiquetas del eje x\n  scale_x_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))",
    "crumbs": [
      "Gráficos",
      "Gráficos de barras"
    ]
  },
  {
    "objectID": "df-var/edicion-variables.html",
    "href": "df-var/edicion-variables.html",
    "title": "Edición de variables",
    "section": "",
    "text": "Opción 1:\nDatos &lt;- rename(Datos, nombre_nuevo = nombre_viejo)\nOpción 2:\ndatos &lt;- datos %&gt;% rename(nombre_nuevo = nombre_viejo)\nSe puede cambiar el nombre de varias variables a la vez:\n\ncolnames(Datos)\n\n[1] \"pclass\"   \"survived\" \"name\"     \"sex\"      \"age\"     \n\nDatos&lt;-Datos %&gt;% rename(\n  clase=pclass,\n  nombre=name,\n  sexo=sex,\n  edad=age)\n\n\ncolnames(Datos)\n\n[1] \"clase\"    \"survived\" \"nombre\"   \"sexo\"     \"edad\"    \n\n\nOpción 3:\nSe pueden renombrar las variables directamente al abrir la base de datos gracias al pipe:\ndatos &lt;- read_xlsx(\"dirección_datos-xlsx\") %&gt;% \n  rename(nombre_nuevo = nombre_viejo,\n         nombre_nuevo = nombre_viejo,\n         ...)",
    "crumbs": [
      "Bases de datos y variables",
      "Edición de variables"
    ]
  },
  {
    "objectID": "df-var/edicion-variables.html#renombrar-una-variable",
    "href": "df-var/edicion-variables.html#renombrar-una-variable",
    "title": "Edición de variables",
    "section": "",
    "text": "Opción 1:\nDatos &lt;- rename(Datos, nombre_nuevo = nombre_viejo)\nOpción 2:\ndatos &lt;- datos %&gt;% rename(nombre_nuevo = nombre_viejo)\nSe puede cambiar el nombre de varias variables a la vez:\n\ncolnames(Datos)\n\n[1] \"pclass\"   \"survived\" \"name\"     \"sex\"      \"age\"     \n\nDatos&lt;-Datos %&gt;% rename(\n  clase=pclass,\n  nombre=name,\n  sexo=sex,\n  edad=age)\n\n\ncolnames(Datos)\n\n[1] \"clase\"    \"survived\" \"nombre\"   \"sexo\"     \"edad\"    \n\n\nOpción 3:\nSe pueden renombrar las variables directamente al abrir la base de datos gracias al pipe:\ndatos &lt;- read_xlsx(\"dirección_datos-xlsx\") %&gt;% \n  rename(nombre_nuevo = nombre_viejo,\n         nombre_nuevo = nombre_viejo,\n         ...)",
    "crumbs": [
      "Bases de datos y variables",
      "Edición de variables"
    ]
  },
  {
    "objectID": "df-var/edicion-variables.html#recodificar-una-variable-o-crear-una-nueva",
    "href": "df-var/edicion-variables.html#recodificar-una-variable-o-crear-una-nueva",
    "title": "Edición de variables",
    "section": "2. Recodificar una variable (o crear una nueva)",
    "text": "2. Recodificar una variable (o crear una nueva)\nPara poder recodificar y crear varaibles se usa el comando mutate (de dplyr). Este es de gran utilidad si se usa junto a comandos que permiten añadir condiciones lógicas como ifelse o case_when.\n\nPasos previos\nAntes de recodificar una variable es necesario conocer cómo es la variable original. Para ello:\n\nSe mira de qué tipo es la variable (numérica -numeric/dbl- o factor) gracias al comando class:\n\n\nclass(Datos$edad)\n\n[1] \"numeric\"\n\n\n\nTambién conviene realizar una tabla para conocer el contenido de la variable, así como su distribución:\n\n\ntable(Datos$clase, useNA=\"ifany\") #La opción useNA=\"ifany\" es opcional, y se añade para que en la tabla se muestren también los valores perdidos.\n\n\n  1   2   3 \n322 273 702 \n\n\n\n\nCrear una nueva variable a partir de operaciones sobre otras existentes\n\nEj1.: calcular la edad de los encuestados a partir del año de nacimiento\n\ndatos &lt;- datos %&gt;% \n  mutate(edad = año_actual - año_nacimiento)\n\nEj2.: crear una variable para el porcentaje de voto de un partido a partir de los votos totales:\n\ndatos &lt;- datos %&gt;% \n  mutate(votosFO_porcentaje = votos_FO/votostotales*100)\n\n\nEl comando case_when\nDatos &lt;- Datos %&gt;%\n  mutate(edad = case_when(\n    edad == 29 ~ 30, # reemplaza 29 por 30\n    edad == 2 ~ 3, # reemplaza 2 por 3\n    TRUE ~ edad)) # Mantiene iguales los valores que no cambian.\n\nDatos &lt;- Datos %&gt;%\n  mutate(clase_rec = case_when(\n    clase %in% c(2, 3) ~ 0, # Si 'clase' es 2 o 3, asigna \"0\"\n    TRUE ~ clase)) \n\ntable(Datos$clase_rec)\n\n\n  0   1 \n975 322 \n\n\nLa opción TRUE en este comando significa “todos los demás valores”. Si no se añadiera, todos los valores que no coinciden con las condiciones se enviarían a perdidos (NA).\n\n\nEl comando ifelse\nEl comando ifelse es una secuencia lógica con tres elementos. Un primer número, que es la categoría que se quiere transformar, un segundo número, que es en el que se transforma, y una tercera condición para el resto de valores. Esta puede ser otro número, NA o otra secuencia de ifelse.\nDatos &lt;- Datos %&gt;%\n  mutate(edad = ifelse(edad == 29, 30, ifelse(edad == 2, 3, edad)))\n\nDatos &lt;- Datos %&gt;%\n  mutate(clase_rec2 = ifelse(clase == 1, 1,\n                             ifelse(clase %in% c(2, 3), 0, NA)))\n\n\nVariables categóricas\nLas variables categóricas se recodifidan del siguiente modo:\n\nTransformándolas en una variable numérica:\n\n#Por separado:\nDatos &lt;- Datos %&gt;% \n  mutate(sexo = as.numeric(sexo)) %&gt;% \n  mutate(sexo = case_when(\n    sexo == 1 ~ 0,\n    sexo == 2 ~ 1,\n    TRUE ~ sexo\n  ))\n  \n#A la vez:\nDatos &lt;- Datos %&gt;% \n  mutate(as.numeric(sexo) = case_when(\n    sexo == 1 ~ 0,\n    sexo == 2 ~ 1,\n    TRUE ~ sexo\n  ))\nEs la opción más útil si se quiere modificar una variable con muchas categorías\n\nEscribiendo las etiquetas entre ““:\n\nDatos &lt;- Datos %&gt;%\n  mutate(sexo = case_when(\n    sexo == \"female\" ~ \"mujer\",  \n    sexo == \"male\" ~ \"hombre\",   \n    TRUE ~ sexo                  \n  ))\nEsta opción es la más cómoda si la variable tiene pocas categorías.\n\nEspecificando los niveles que se quieren modificar:\n\ndatos &lt;- datos %&gt;%\n  mutate(estudios_universitarios = case_when(\n    estudios %in% levels(estudios)[1:5] ~ 0,  # Agrupar niveles 1 a 5 en 0\n    estudios %in% levels(estudios)[6] ~ 1,    # Agrupar nivel 6 en 1 \n    TRUE ~ NA_real_                           \n  ))\nEsta opción es útil si se quiere convertir en cardiotónico una variable categórica con muchas categorías, aunque la primera opción es igual de buena en estos casos\n\n\nEjemplos útiles\nOtros ejemplos de recodificar variables:\n\nSe pueden utilizar símbolos lógicos como el &gt;,&lt;,|,& etc a la hora de recodificar variables\n\ndatos&lt;-datos %&gt;%\n  mutate(municipio_cat=ifelse(población&gt;=20000,\"Ciudad\",\"Pueblo\") %&gt;% \n           as.factor())\n\nTambién se pueden realizar operaciones entre variables al mismo tiempo que se recodifican. Ej.: calcular el apoyo en cada municipio a los partidos principales:\n\nelec23 &lt;- elec23 %&gt;% \n  mutate(apoyo = case_when(\n    CA==\"Galicia\" ~ PP+BNG+PSOE+SUMAR+VOX,\n    CA==\"Cataluña\" ~ PP+PSOE+SUMAR+VOX+JxCAT+ERC,\n    CA==\"País Vasco\" ~ PP+PSOE+SUMAR+VOX+PNV+BILDU,\n    T ~ PP+PSOE+SUMAR+VOX),\n  apoyo=apoyo/Votantes*100)\n\n\nOtras opciones de mutate\n\nmutate_if. Se hacen cambios en múltiples variables que cumplan con una característica especificada. Es especialmente útil para transformar variables de un tipo a otro. Por ejemplo:\n\nConvertir todas las variables de tipo factor a carácter: mutate_if(is.factor, as.character)\nEstandardizar (=0, sd=1) todas las variables numéricas del dataset: mutate_if(is.numeric, scale)\nCuando se estandariza, el valor 0 de una observación implica que esta se corresponde a la media, y el 1 que esa observación está un punto por encima de la desviación típica.\n\nmutate_at. Cambia diferentes varaibles especificadas en un vector específico.\n\nEstandarizar una variable: mutate_at (c(\"n\", \"edad\"), scale)\nConvertir una escala en logarítmica: mutate_at (c(“pib\", “poblacion\"), log)\n\nmutate_all. Permite hacer cambios en todas las variables de un dataframe. Ej.: mutate_all(as.character)\nacross. Permite hacer cambios a varias variables a la vez dentro de la función básica de mutate. Ejs.:\n\nmutate(across(c(n, edad), round))\nmutate(across(where(is.numeric), round))\nmutate(across(starts_with(“nombr\"), tolower))",
    "crumbs": [
      "Bases de datos y variables",
      "Edición de variables"
    ]
  },
  {
    "objectID": "df-var/edicion-variables.html#añadir-etiquetas-a-la-variable",
    "href": "df-var/edicion-variables.html#añadir-etiquetas-a-la-variable",
    "title": "Edición de variables",
    "section": "3. Añadir etiquetas a la variable",
    "text": "3. Añadir etiquetas a la variable\nVer las etiquetas de una variable: attr(datos$var, \"labels\"):\nPara cambiar las etiquetas se usa el comando factor (de dyplr)\ndatos &lt;- datos %&gt;% \n  mutate(variable = factor(variable, \n                    levels = c(1,2,3),\n                    labels = c(\"Etiqueta1\",\"Etiqueta2\",\"Eriqueta3\")))\n\nlevels = c(1,2,3) indica el conjunto de números correspondientes con los valores de cada categoría de la variable.\nlabels =c(“Etiqueta1”…) indica las etiquetas correspondientes con cada valor especificado anteriormente. Por ejemplo, en este caso a la categoría de la variable que se identifica con un 1 se le asignaría la etiqueta “Etiqueta1”.\nEj. de cómo añadir etiquetas:\n\n\ntable(datos$mujer)\n\n\n    0     1 \n15023 14178 \n\ndatos &lt;- datos %&gt;%\n  mutate(mujer = factor(mujer, levels = c(0, 1), labels = c(\"Hombre\",\"Mujer\"))) \n\ntable(datos$mujer)\n\n\nHombre  Mujer \n 15023  14178 \n\n\nSi se quiere etiquetar algún carácter de una variable numérica sin transformarla en factor, se puede usar el siguiente comando:\nlibrary(labelled)\nval_labels(datos$variable) &lt;- c(Etiqueta1 = 0, Etiqueta2 = 1)\nEste comando también es útil en el caso de escalas: por ejemplo, en la escala de ideología del 1 al 10 para poner que el 1 es extrema izquierda y el 10 extrema derecha, pero dejarlo como numérico y sin necesidad de etiquetar todas las categorías.\n\nclass(datos$ideol)\n\n[1] \"numeric\"\n\nval_labels(datos$ideol) &lt;- c(Extrema_izq = 1, Extrema_dcha = 10)\n\nclass(datos$ideol)\n\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\nval_labels(datos$ideol)\n\n Extrema_izq Extrema_dcha \n           1           10",
    "crumbs": [
      "Bases de datos y variables",
      "Edición de variables"
    ]
  },
  {
    "objectID": "analisis/teoria.html",
    "href": "analisis/teoria.html",
    "title": "Teoría",
    "section": "",
    "text": "A la hora de interpretar los resultados de una prueba estadística, podemos fijarnos en tres cuestiones (relacionadas entre sí): el valor crítico, el nivel de significatividad o alpha y el intervalo de confianza.\n\nNivel de confianza: es la probabilidad de que el parámetro a estimar se encuentre en el intervalo de confianza.\nAlpha: es la probabilidad de quedarse fuera de ese intervalo (en términos sustantivos, la probabilidad de rechazar la hipótesis nula cuando es cierta.\nValor crítico: indica el número de desviaciones estándar que cubren el área bajo la curva para un determinado nivel de confianza. Por ejemplo, para un IC del 95%, este valor crítico indica los límites dentro de los cuales se encuentra el 95% de las observaciones en una distribución normal. Establece donde empieza y dónde termina la zona de rechazo de la hipótesis.\n\n\n\n\nNivel de confianza\nAlpha\nValor crítico\n\n\n\n\n95%\n5 - 2,5%\n1,96\n\n\n99%\n1 - 0,5%\n2,57\n\n\n99,9%\n0,1 - 0,05%\n3,27\n\n\n\n\n\n\n\nIntervalos de confianza\n\n\n\n\nIntervalo de confianza\nIndica, para un determiando nivel de confianza, el rango en el que se moverá la media real de un determinado rasgo para el universo estudiado, mientras que la media que se puede calcular a partir de una muestra indica únicamente el valor medio del rasgo de esa muestra. Es decir, si tomamos un intervalo de confianza del 95%, en el 95% de ocasiones la media real del universo de estudio se moverá entre los límites establecidos por el intervalo de confianza. Se emplean estos intervalos ya que la única forma de conocer el valor medio real de un determinado rasgo de una población completa es mediante un censo en el que se incluya a toda esa población, pero es imposible de conocer de forma exacta tomando solo una muestra poblacional.\nPor ejemplo, si para la media idológica tenemos un intervalo que va del 4,5 al 5 para un nivel de confianza del 95%, lo que quiere decir es que, en el caso de realizar 100 encuestas independientes a una población, en 95 de estas encuestas la media muestral tendrá un valor situado entre el 4,5 y el 5, y en otros 5 caso será superior o inferior a estas cifras.\n\nCálculo manual de los intervalos de confianza\nLa fórmula de los intervalos es: media muestral ± valor crírico (σ)*error estandar\nPara calcular el error, se utiliza el comando std.errorde la librería plotrix:\nstd.error(datos$variable)\nEn el ejemplo usado en el test de una media, el error se calcularía del siguiete modo:\n\nstd.error(datos$ideol)\n\n[1] 0.01568334\n\n\nEl error estándar es 0.016. De acuerdo con esto, al 95% los intervalos serían:\n\nIntervalo superior: 4.815857 + 1.96*0.01568334 = 4.775456\nIntervalo inferior: 4.815857 - 1.96*0.01568334 = 4.856257\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Teoría"
    ]
  },
  {
    "objectID": "analisis/reg-multiple.html",
    "href": "analisis/reg-multiple.html",
    "title": "Lineal múltiple",
    "section": "",
    "text": "Llamamos regresión lineal múltiple al análisis de regresión que incluye más de una variable independiente. Se representa como:\n\\[E(y) = \\beta_{0}  + \\beta_{1}{x_{1}} + \\ \\beta_{12}{x_{2}} +  \\beta_{3}{x_{3}} + u\\]\ndonde β0 es el valor de y cuando todas las xi valen 0, βi son los coeficientes de las variables independientes y el término u es el término de error.\nEsta ecuación definiría un hiperplano, pues con una VI se define una recta, con dos VIs un plano, con tres VIs un espacio de tres dimensiones, y así sucesivamente.\n\nResumen de las funciones principales\n# Eliminar los NA de la base de datos\nlista_variables &lt;- c(\"var1\",\"var2\",\"var3\"...)\ndatos_reg &lt;- datos[lista_variables]\ndatos_reg &lt;- na.omit(datos_Reg)\n\n# Función de la regresión\nregresión &lt;- lm(var1~var2 + var3 + var4, datos_reg) #Librería e1071\nsummary(regresión)\n\n#Visualizar los coeficientes\ncoefplot(regresión, xlim=c(-5, 5), col.pts=\"blue\", intercept=TRUE, main=\"Coeficientes de la regresión\") #Librería arm\n\n# Comprobación de los supuestos principales\nplot(regresión,2) #Normalidad de los residuos\nbptest(regresión) #Homocedasticidad (librería lmtest)\nvif(regresión) #Multicolinealidad (librería rms)\n\n# Valores predichos\n\n\n#Exportar los resultados\nstargazer(regresión, type=\"text\") #Librería stargazer\n\n#Comparación de modelos\nAIC(modelo1, modelo2, modelo3)\nBIC(modelo1, modelo2, modelo3)\n\n\nEjemplo práctico\nVamos a estimar la propensión de voto a un partido (variable escala) en función de las siguientes variables:\n\nedad del entrevistado (variable continua)\nsexo (variable dicotómica)\nnivel educativo (variable dicotómica)\nopinión sobre la situación económica personal (variable dicotómica)\nopinión sobre la situación económica en España (variable dicotómica)\nrecuerdo de voto (variable politómica)\nideología del entrevistado (variable escala)\n\nEs posible que estas variables no configuren un buen modelo. Sin embargo, son un buen ejercicio porque nos permitirá ver cómo se interpretan los diferentes tipos de variables e identificar algunos problemas.\n\n\nPreparar la base de datos\nLa regresión lineal es “sensible” a la existencia de casos perdidos en las variables que se introducen en los modelos. Para evitar que diferentes modelos tengan diferentes número de casos (en cuyo caso no serían comparables) creamos un nuevo data.frame que contenga únicamente las columnas que vamos a usar para estimar los modelos, para eliminar de estos los casos perdidos. A continuación, eliminamos todas las filas que continenen valores perdidos. Esto se hace usando la funciones na.omit() o na.exclude().\n\nmyvars &lt;- c(\"prop_psoe\", \"prop_pp\", \"edad\", \"hombre\", \"recuerdo19\", \"estudios_universitarios\", \"ideol\", \"ecoper\", \"ecoesp\")   # nuevo data.frame\ndatos_red&lt;-datos[myvars] #Los corchetes sirven para seleccionar solo el conjunto de datos especificado. También podría usarse la función select.\ndatos_red&lt;- na.omit(datos_red)\n\n\n\nEl modelo de regresión\nA continuación, esitmamos el modelo de regresión (modelPP) con las variables arriba especificadas. Usaremos la función lm() de la libería e1071 (como ocurre siempre, existen muchas otras librerías que incluyen funciones para estimar regresiones lineales y son igualmente válidas).\n\nlibrary(e1071)\n\nmodelPP &lt;- lm(prop_pp ~ edad + hombre + estudios_universitarios + ecoper + ecoesp + recuerdo19 + ideol, data=datos_red)  \nsummary(modelPP)\n\n\nCall:\nlm(formula = prop_pp ~ edad + hombre + estudios_universitarios + \n    ecoper + ecoesp + recuerdo19 + ideol, data = datos_red)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.6522 -1.4692 -0.2591  1.5518  9.8268 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    0.764501   0.082283   9.291  &lt; 2e-16 ***\nedad                          -0.000385   0.001114  -0.346 0.729637    \nhombreHombre                  -0.045523   0.033180  -1.372 0.170080    \nestudios_universitarioscon EU  0.120337   0.034416   3.497 0.000472 ***\necoperpositiva                 0.173926   0.038775   4.485 7.31e-06 ***\necoesppositiva                -0.729276   0.038624 -18.881  &lt; 2e-16 ***\nrecuerdo19PP                   4.149196   0.055763  74.407  &lt; 2e-16 ***\nrecuerdo19VOX                  0.580711   0.075540   7.687 1.56e-14 ***\nrecuerdo19Podemos             -0.969983   0.056628 -17.129  &lt; 2e-16 ***\nrecuerdo19Ciudadanos           2.837302   0.068713  41.292  &lt; 2e-16 ***\nrecuerdo19Más Madrid          -0.554132   0.189993  -2.917 0.003542 ** \nrecuerdo19Otros               -1.012513   0.052845 -19.160  &lt; 2e-16 ***\nrecuerdo19En blanco            0.666554   0.139864   4.766 1.89e-06 ***\nideol                          0.445504   0.008478  52.549  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.473 on 22880 degrees of freedom\nMultiple R-squared:  0.5873,    Adjusted R-squared:  0.5871 \nF-statistic:  2505 on 13 and 22880 DF,  p-value: &lt; 2.2e-16\n\n\nComo podemos observar, R transforma la variable politómica “recuerdo19” en c-1 variables. Lo hace porque está definida como factor, de lo contrario trataría la variable como numérica (lo cual no tendría ningún sentido). En este caso, cada variable se interpreta en relación a la categoría de refencia (en este caso, PSOE). La función relevel() nos permite cambiar cambiar la categoría de referencia. Por ejemplo, si queremos que “PP” sea nuestra categoría de referencia, haríamos lo siguiente:\nLo único que cambia es la categoría de referencia en la variable recuerdo19 y, por consiguiente, los coeficientes de las dummies. El resto de la tabla será idéntica.\nmodelPP_newrc&lt;- lm(prop_pp ~ edad + hombre + estudios_universitarios + ecoper + ecoesp +relevel(recuerdo19, ref =\"PP\") + ideol, data=datos_red) \nsummary(modelPP_newrc)\n\nSignificatividad del modelo\nLos resultados muestran que todas las variables menos edad y género son estadísticamente significativas para un NC del 99.9%. Esto es así porque, dado que los p-valores son &lt;0.001, podemos rechazar la hipótesis nula con una probabilidad de equivocarnos inferior a 0.001. \n\n\n\nInterpretación de los coeficientes\nMás allá de la significación estadística, es importante interpretar el tamaño del coeficiente. En otras palabras, la magnitud del efecto. En regresión lineal múltiple, los coeficientes de regresión representan el cambio promedio que se produce en la VD por cada unidad de cambio en la VI, mientras el resto de variables se mantiene constante (ceteris paribus). Este control estadístico que proporciona la regresión es muy importante, porque aisla el efecto de una variable del resto de variable incluidas en el modelo.\nEl valor de los coeficientes se obtiene con la función sumary() del modelo, y también puede extraerse fácilmente de la lista modelPP (ver función View(modelPP))\n\nmodelPP$coefficients\n\n                  (Intercept)                          edad \n                 0.7645004705                 -0.0003850228 \n                 hombreHombre estudios_universitarioscon EU \n                -0.0455226223                  0.1203369895 \n               ecoperpositiva                ecoesppositiva \n                 0.1739256464                 -0.7292760576 \n                 recuerdo19PP                 recuerdo19VOX \n                 4.1491958693                  0.5807105360 \n            recuerdo19Podemos          recuerdo19Ciudadanos \n                -0.9699832612                  2.8373014511 \n         recuerdo19Más Madrid               recuerdo19Otros \n                -0.5541319048                 -1.0125132971 \n          recuerdo19En blanco                         ideol \n                 0.6665536962                  0.4455040602 \n\n\nVamos a ver algunos ejemplos:\n\nEl coeficiente de estudios_universitarioscon_ES (0.1203) indica que, manteniendo constantes todas las demás variables, tener estudios universitarios está asociado con un aumento de 0.1203 unidades en la propensión de voto al Partido Popular. En otras palabras, las personas con estudios universitarios tienen, en promedio, una mayor inclinación a votar por el Partido Popular en comparación con aquellas que no tienen estudios universitario (ceteris paribus)\nEl coeficiente de recuerdo19PP (4.149) indica que, manteniendo constantes todas las demás variables, las personas que recuerdan haber votado al Partido Popular en las elecciones de 2019 tienen una propensión de voto al Partido Popular 4.149 unidades mayor en comparación con aquellas que recuerdan haber votado al PSOE (la categoría de referencia). Esto significa que, en términos de propensión al voto, el recuerdo de haber votado al PP en el pasado está fuertemente asociado con una mayor inclinación a votar nuevamente por este partido, mucho más que en comparación con aquellos que votaron al PSOE (ceteris paribus)\n\n\nVisualizacion de los coeficientes\nUna manera rápida de presentar los resultados de la regresión es representar gráficamente los coeficientes. Para ello, podemos usar la función coefplot()\n\np_load(arm)\ncoefplot(modelPP, xlim=c(-5, 5),col.pts=\"blue\", intercept=TRUE, main=\"Coeficientes de la regresión\")\n\n\n\n\n\n\n\n\nEste tipo de gráfico es particularmente útil cuando queremos comparar los coeficientes de dos o más modelos. Por ejemplo, si calculamos el mismo modelo para estimar la propensión de voto al PSOE, podemos visualizar los coeficientes de ambos modelos de la siguiente manera\n\n#Estimamos el modelo\nmodelPSOE &lt;- lm(prop_psoe ~ edad + hombre + estudios_universitarios + ecoper + ecoesp + recuerdo19 + ideol, data=datos_red)   \n\n#Representamos gráficamente los coeficientes de ambas regresiones (argumento add=T)\npar(mfrow = c(1,1))\ncoefplot(modelPP, xlim=c(-5, 5),col.pts=\"blue\", intercept=TRUE, main=\"Coeficientes\")\ncoefplot(modelPSOE, add=TRUE, col.pts=\"red\",  intercept=TRUE, offset=0.2, main=\"PSOE\") \n\n#Añadimos leyenda\nlegend(\"topright\",  \n       c(\"Propensión voto PP\", \"Propensión voto PSOE\"), \n       lty = c(1,1),       \n       col=c(\"blue\",\"red\"),\n       cex = 0.7)\n\n\n\n\n\n\n\n\n\n\n¿Qué variable es la más importante?\nDado que las variables están expresadas en diferentes unidades, los coeficientes de la regresión no son directamente comparables entre sí. Para hacer esto posible, es necesario transformar dichos coeficientes en coeficientes estandarizados (coeficientes Beta). Los coeficientes estandarizados se basan en puntuaciones típicas y, por lo tanto, son comparables entre sí.\n\np_load(lm.beta)\nbetaPP&lt;-lm.beta(modelPP)\nsummary(betaPP)\n\n\nCall:\nlm(formula = prop_pp ~ edad + hombre + estudios_universitarios + \n    ecoper + ecoesp + recuerdo19 + ideol, data = datos_red)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.6522 -1.4692 -0.2591  1.5518  9.8268 \n\nCoefficients:\n                               Estimate Standardized Std. Error t value\n(Intercept)                    0.764501           NA   0.082283   9.291\nedad                          -0.000385    -0.001541   0.001114  -0.346\nhombreHombre                  -0.045523    -0.005909   0.033180  -1.372\nestudios_universitarioscon EU  0.120337     0.015627   0.034416   3.497\necoperpositiva                 0.173926     0.020009   0.038775   4.485\necoesppositiva                -0.729276    -0.091072   0.038624 -18.881\nrecuerdo19PP                   4.149196     0.442365   0.055763  74.407\nrecuerdo19VOX                  0.580711     0.040263   0.075540   7.687\nrecuerdo19Podemos             -0.969983    -0.080576   0.056628 -17.129\nrecuerdo19Ciudadanos           2.837302     0.197182   0.068713  41.292\nrecuerdo19Más Madrid          -0.554132    -0.012506   0.189993  -2.917\nrecuerdo19Otros               -1.012513    -0.089720   0.052845 -19.160\nrecuerdo19En blanco            0.666554     0.020676   0.139864   4.766\nideol                          0.445504     0.310399   0.008478  52.549\n                              Pr(&gt;|t|)    \n(Intercept)                    &lt; 2e-16 ***\nedad                          0.729637    \nhombreHombre                  0.170080    \nestudios_universitarioscon EU 0.000472 ***\necoperpositiva                7.31e-06 ***\necoesppositiva                 &lt; 2e-16 ***\nrecuerdo19PP                   &lt; 2e-16 ***\nrecuerdo19VOX                 1.56e-14 ***\nrecuerdo19Podemos              &lt; 2e-16 ***\nrecuerdo19Ciudadanos           &lt; 2e-16 ***\nrecuerdo19Más Madrid          0.003542 ** \nrecuerdo19Otros                &lt; 2e-16 ***\nrecuerdo19En blanco           1.89e-06 ***\nideol                          &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.473 on 22880 degrees of freedom\nMultiple R-squared:  0.5873,    Adjusted R-squared:  0.5871 \nF-statistic:  2505 on 13 and 22880 DF,  p-value: &lt; 2.2e-16\n\n\nLos coeficientes estandarizados representan la cantidad de cambio, en unidades de desviación estándar, que se producirá en la variable dependiente por cada aumento de una unidad de desviación estándar en la correspondiente variable independiente (manteniendo constantes las demás variables). Al estandarizar las variables, la constante se iguala a 0, por lo que no se incluye en la ecuación de predicción. Estos coeficientes indican la importancia relativa de cada variable independiente en la ecuación de regresión. En general, cuanto mayor es el valor absoluto del coeficiente de regresión estandarizado, mayor es el peso de la variable en la ecuación de regresión.\n\n\nBondad de ajuste del modelo\nEl R2 tiene un valor de 0.5873, lo que indica que nuestro modelo explica el 58.73% de varianza de la VD. En este caso, el valor de R2 ajustado es prácticamente idéntico.\n\n\n\nDiagnóstico de la regresión\nVamos a comprobar los supuestos de la regresión\n\nNormalidad de los residuos. El test de normalidad que usamos en el ejemplo de regresión simple (Shapiro test) está limitado a n=5000. Dado que no tenemos esa opción, vamos a revisar el supuesto de normalidad un gráfico Q-Q:\n\n\nplot(modelPP, 2)\n\n\n\n\n\n\n\n\nComprobamos también que la media de los residuos=0\n\nmean(modelPP$residuals)\n\n[1] -2.04219e-16\n\n\n\nHomocedasticidad (varianza constante de los residuos)\n\n\nTest de homocedasticidad\n\n\n#install.packages(\"lmtest\")\nlibrary(lmtest)\nhet.lm&lt;-bptest(modelPP)\nhet.lm\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelPP\nBP = 2557.5, df = 13, p-value &lt; 2.2e-16\n\n\nLa hipótesis nula en este test es que la varianza de los residuos es constante (homocedástica). La evidencia permite rechazar la hipótesis nula, confirmando que la distribución es heterocedástica (no se cumple el suspuesto). La distrivución de los residuos no es constante.\n\nGráficamente:\n\n\nplot( modelPP, 3)\n\n\n\n\n\n\n\n\n\nMulticolinealidad.\n\n\nreg.lineal.vif &lt;- car::vif(modelPP)\nreg.lineal.vif\n\n                            GVIF Df GVIF^(1/(2*Df))\nedad                    1.102517  1        1.050008\nhombre                  1.028258  1        1.014030\nestudios_universitarios 1.107391  1        1.052327\necoper                  1.103228  1        1.050347\necoesp                  1.289873  1        1.135726\nrecuerdo19              2.198730  7        1.057891\nideol                   1.934408  1        1.390830\n\n\nNo parece que existan problemas de multicolinealidad en nuestro modelo. \n\n\nValores predichos\nAl igual que hicimos con los coeficientes, una vez calculado el modelo podemos extraer los valores predichos (estimados) para cada individuo en la muestra consultando modelPP$fitted.values. Esto nos permite, por ejemplo, calcular el valor medio de propensión de voto al PP:\n\nmean(modelPP$fitted.values)\n\n[1] 3.678606\n\n\nTambién podemos estimar qué valor tendrá la variable dependiente para determinados valores de las variables independientes. Por ejemplo, vamos a calcular la propensión de voto al PP de un varón de 50 años, sin estudios universitarios (0), que valora positivamente su situación económica personal (1) pero no la situación económica del país (0), con ideología 5 y que en las elecciones de 2019 votó a C`s.\n\ndata1 &lt;- data.frame(hombre=\"Hombre\", edad=50, estudios_universitarios=\"con EU\", ecoper=\"positiva\", ecoesp=\"negativa\", ideol=5, recuerdo19=\"Ciudadanos\")\nyhat1&lt;-predict(modelPP, newdata = data1)\nyhat1\n\n       1 \n6.058811 \n\n\nO calcular, por ejemplo, cómo cambia la propensión de voto al PP para un individuo con esas mismas características en función de su edad:\n\ndata2&lt;- data.frame(hombre=\"Hombre\", edad=c(20, 30, 40, 50, 60, 70, 80), estudios_universitarios=\"con EU\", ecoper=\"positiva\", ecoesp=\"negativa\", ideol=5, recuerdo19=\"Ciudadanos\")\nyhat2&lt;-predict(modelPP, newdata = data2)\nyhat2\n\n       1        2        3        4        5        6        7 \n6.070362 6.066512 6.062661 6.058811 6.054961 6.051111 6.047260 \n\n\n\nIntervalos de confianza\nLos intervalos de confianza reflejan la incertidumbre alrededor de las estimaciones medias. Siguiendo con el ejemplo anterior, vamos a calcular las probabilidades predichas con sus intervalos de confianza para todos los individuos en la muestra (fit es el valor predicho):\n\nyhat&lt;-predict(modelPP, newdata = datos_red, interval = \"confidence\")\nhead(yhat) #visualizamos los 5 primeros casos\n\n        fit       lwr       upr\n1 7.0760579 6.9727774 7.1793383\n2 8.1922896 8.0917476 8.2928316\n3 8.0114335 7.9169740 8.1058930\n4 0.5837394 0.4690074 0.6984715\n5 3.6770243 3.5669840 3.7870646\n6 1.9297500 1.8417350 2.0177651\n\n\nSi no queremos ver los casos perdidos usamos el argumento na.action para especificarlo\n\nyhat&lt;-predict(modelPP, newdata = datos_red, interval = \"confidence\", na.action=na.exclude)\nhead(yhat)\n\n        fit       lwr       upr\n1 7.0760579 6.9727774 7.1793383\n2 8.1922896 8.0917476 8.2928316\n3 8.0114335 7.9169740 8.1058930\n4 0.5837394 0.4690074 0.6984715\n5 3.6770243 3.5669840 3.7870646\n6 1.9297500 1.8417350 2.0177651\n\n\nEl output contiene 3 columnas:\n\nFIT: el valor predicho (que también habíamos consultado a través de modelPP$fitted.values)\nLWR: límite inferior de la banda de confianza\nUPR: límite superior de la banda de confianza\n\nPor defecto, R produce bandas de confianza al 95%, pero esto se puede cambiar con el argumento level\n\nyhat&lt;-predict(modelPP, newdata = datos_red, interval = \"confidence\", na.action=na.exclude, level=0.99)\nhead(yhat)\n\n        fit       lwr       upr\n1 7.0760579 6.9403202 7.2117955\n2 8.1922896 8.0601510 8.3244282\n3 8.0114335 7.8872889 8.1355781\n4 0.5837394 0.4329514 0.7345275\n5 3.6770243 3.5324024 3.8216462\n6 1.9297500 1.8140751 2.0454250\n\n\n\n\n\nExportar resultados\nVamos a exportar a formato científico los dos modelos que hemos estimado: modelPP y modelPSOE\n\nLibrería stargazer\n\n#install.packages(\"stargazer\")\nlibrary(stargazer)\nstargazer(modelPP, modelPSOE,      #Incluir aquí Modelo1, Modelo2, M3...\n          type=\"text\",\n          dep.var.labels=c(\"Propensión voto PP\", \"Propensión voto PSOE\"),\n          covariate.labels=c(\"Edad\", \"Hombre\", \"Estudios superiores\", \"Economia personal: positiva (cr:neg)\", \"Economia país: positiva (cr:neg)\", \"Voto 2019:PP (cr: PSOE)\", \"Voto 2019:VOX (cr: PSOE)\", \"Voto 2019:Podemos (cr: PSOE)\", \"Voto 2019:C´s (cr: PSOE)\", \"Voto 2019:Más Madrid (cr: PSOE)\", \"Voto 2019:Otros (cr: PSOE)\", \"Voto 2019:Blanco (cr: PSOE)\", \"Ideología\", \"Constante\"))\n\n\n============================================================================\n                                               Dependent variable:          \n                                     ---------------------------------------\n                                     Propensión voto PP Propensión voto PSOE\n                                            (1)                 (2)         \n----------------------------------------------------------------------------\nEdad                                      -0.0004             0.011***      \n                                          (0.001)             (0.001)       \n                                                                            \nHombre                                     -0.046            -0.536***      \n                                          (0.033)             (0.034)       \n                                                                            \nEstudios superiores                       0.120***           -0.220***      \n                                          (0.034)             (0.035)       \n                                                                            \nEconomia personal: positiva (cr:neg)      0.174***             0.073*       \n                                          (0.039)             (0.040)       \n                                                                            \nEconomia país: positiva (cr:neg)         -0.729***            1.597***      \n                                          (0.039)             (0.040)       \n                                                                            \nVoto 2019:PP (cr: PSOE)                   4.149***           -4.966***      \n                                          (0.056)             (0.057)       \n                                                                            \nVoto 2019:VOX (cr: PSOE)                  0.581***           -5.070***      \n                                          (0.076)             (0.077)       \n                                                                            \nVoto 2019:Podemos (cr: PSOE)             -0.970***           -2.444***      \n                                          (0.057)             (0.058)       \n                                                                            \nVoto 2019:C´s (cr: PSOE)                  2.837***           -4.226***      \n                                          (0.069)             (0.070)       \n                                                                            \nVoto 2019:Más Madrid (cr: PSOE)          -0.554***           -1.982***      \n                                          (0.190)             (0.195)       \n                                                                            \nVoto 2019:Otros (cr: PSOE)               -1.013***           -3.589***      \n                                          (0.053)             (0.054)       \n                                                                            \nVoto 2019:Blanco (cr: PSOE)               0.667***           -3.927***      \n                                          (0.140)             (0.143)       \n                                                                            \nIdeología                                 0.446***           -0.305***      \n                                          (0.008)             (0.009)       \n                                                                            \nConstante                                 0.765***            7.650***      \n                                          (0.082)             (0.084)       \n                                                                            \n----------------------------------------------------------------------------\nObservations                               22,894              22,894       \nR2                                         0.587               0.593        \nAdjusted R2                                0.587               0.592        \nResidual Std. Error (df = 22880)           2.473               2.532        \nF Statistic (df = 13; 22880)            2,504.777***        2,560.708***    \n============================================================================\nNote:                                            *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\nLibrería jtools\nEstá disponible únicamente para un tipo de modelos muy limitado, pero OLS y GLM están incluidos.\nInstalamos los paquetes que van a hacernos falta\n\np_load(jtools, ggstance, huxtable)\n\nLa función summ() muestra los resultados de la regresión\n\nsumm(modelPP)\n\nMODEL INFO:\nObservations: 22894\nDependent Variable: prop_pp\nType: OLS linear regression \n\nMODEL FIT:\nF(13,22880) = 2504.78, p = 0.00\nR² = 0.59\nAdj. R² = 0.59 \n\nStandard errors:OLS\n-------------------------------------------------------------\n                                  Est.   S.E.   t val.      p\n------------------------------ ------- ------ -------- ------\n(Intercept)                       0.76   0.08     9.29   0.00\nedad                             -0.00   0.00    -0.35   0.73\nhombreHombre                     -0.05   0.03    -1.37   0.17\nestudios_universitarioscon        0.12   0.03     3.50   0.00\nEU                                                           \necoperpositiva                    0.17   0.04     4.49   0.00\necoesppositiva                   -0.73   0.04   -18.88   0.00\nrecuerdo19PP                      4.15   0.06    74.41   0.00\nrecuerdo19VOX                     0.58   0.08     7.69   0.00\nrecuerdo19Podemos                -0.97   0.06   -17.13   0.00\nrecuerdo19Ciudadanos              2.84   0.07    41.29   0.00\nrecuerdo19Más Madrid             -0.55   0.19    -2.92   0.00\nrecuerdo19Otros                  -1.01   0.05   -19.16   0.00\nrecuerdo19En blanco               0.67   0.14     4.77   0.00\nideol                             0.45   0.01    52.55   0.00\n-------------------------------------------------------------\n\n\nLa representación gráfica de los coeficientes también se hace de manera muy sencilla y muy parecida a la que ya conocemos\n\nplot_summs(modelPP)\n\n\n\n\n\n\n\n\nSe pueden añadir tantos modelos como deseemos\n\nplot_summs(modelPP, modelPSOE)\n\n\n\n\n\n\n\n\nTambién permite visualizar de manera rápida el efecto de una variable sobre la variable dependiente, siempre que la primera sea continua. Por ejemplo, vamos cómo varía la propensión de votar al PP con la ideología, controlado por el resto de variables\n\neffect_plot(modelPP, pred = ideol, interval = TRUE)\n\n\n\n\n\n\n\n\nFinalmente, la función export_summs de jtools permite representar las tablas en formato “científico”.\n\nexport_summs(modelPP, modelPSOE)\n\n\n\nModel 1Model 2\n\n(Intercept)0.76 ***7.65 ***\n\n(0.08)   (0.08)   \n\nedad-0.00    0.01 ***\n\n(0.00)   (0.00)   \n\nhombreHombre-0.05    -0.54 ***\n\n(0.03)   (0.03)   \n\nestudios_universitarioscon EU0.12 ***-0.22 ***\n\n(0.03)   (0.04)   \n\necoperpositiva0.17 ***0.07    \n\n(0.04)   (0.04)   \n\necoesppositiva-0.73 ***1.60 ***\n\n(0.04)   (0.04)   \n\nrecuerdo19PP4.15 ***-4.97 ***\n\n(0.06)   (0.06)   \n\nrecuerdo19VOX0.58 ***-5.07 ***\n\n(0.08)   (0.08)   \n\nrecuerdo19Podemos-0.97 ***-2.44 ***\n\n(0.06)   (0.06)   \n\nrecuerdo19Ciudadanos2.84 ***-4.23 ***\n\n(0.07)   (0.07)   \n\nrecuerdo19Más Madrid-0.55 ** -1.98 ***\n\n(0.19)   (0.19)   \n\nrecuerdo19Otros-1.01 ***-3.59 ***\n\n(0.05)   (0.05)   \n\nrecuerdo19En blanco0.67 ***-3.93 ***\n\n(0.14)   (0.14)   \n\nideol0.45 ***-0.31 ***\n\n(0.01)   (0.01)   \n\nN22894       22894       \n\nR20.59    0.59    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nPara renombrar los modelos y las variables, usaremos los argumentos model.names y coefs de la siguiente manera\n\nexport_summs(modelPP, modelPSOE, \n  model.names=c(\"Prop. Voto PP\", \n                \"Prop. Voto PSOE\"), \n  coefs=c(\"Edad\"=\"edad\", \n          \"Hombre\"=\"hombreHombre\", \n          \"Estudios Universitarios\"=\"estudios_universitarioscon EU\", \n          \"Economía personal positiva (cr=neg)\"=\"ecoperpositiva\", \n          \"Economía país positiva (cr=neg)\"=\"ecoesppositiva\", \n          \"Voto 2019:PP (cr=PSOE)\"=\"recuerdo19PP\",\n          \"Voto 2019:VOX (cr=PSOE)\"=\"recuerdo19VOX\",\n          \"Voto 2019:Podemos (cr=PSOE)\"=\"recuerdo19Podemos\",\n          \"Voto 2019:C´s (cr=PSOE)\"=\"recuerdo19Ciudadanos\",\n          \"Voto 2019:Mas País (cr=PSOE)\"=\"recuerdo19Más Madrid\",\n          \"Voto 2019:Otros (cr=PSOE)\"=\"recuerdo19Otros\",\n          \"Voto 2019:Blanco (cr=PSOE)\"=\"recuerdo19En blanco\",\n          \"Ideología\"=\"ideol\",\n          \"Constante\"=\"(Intercept)\"\n))\n\n\n\nProp. Voto PPProp. Voto PSOE\n\nEdad-0.00    0.01 ***\n\n(0.00)   (0.00)   \n\nHombre-0.05    -0.54 ***\n\n(0.03)   (0.03)   \n\nEstudios Universitarios0.12 ***-0.22 ***\n\n(0.03)   (0.04)   \n\nEconomía personal positiva (cr=neg)0.17 ***0.07    \n\n(0.04)   (0.04)   \n\nEconomía país positiva (cr=neg)-0.73 ***1.60 ***\n\n(0.04)   (0.04)   \n\nVoto 2019:PP (cr=PSOE)4.15 ***-4.97 ***\n\n(0.06)   (0.06)   \n\nVoto 2019:VOX (cr=PSOE)0.58 ***-5.07 ***\n\n(0.08)   (0.08)   \n\nVoto 2019:Podemos (cr=PSOE)-0.97 ***-2.44 ***\n\n(0.06)   (0.06)   \n\nVoto 2019:C´s (cr=PSOE)2.84 ***-4.23 ***\n\n(0.07)   (0.07)   \n\nVoto 2019:Mas País (cr=PSOE)-0.55 ** -1.98 ***\n\n(0.19)   (0.19)   \n\nVoto 2019:Otros (cr=PSOE)-1.01 ***-3.59 ***\n\n(0.05)   (0.05)   \n\nVoto 2019:Blanco (cr=PSOE)0.67 ***-3.93 ***\n\n(0.14)   (0.14)   \n\nIdeología0.45 ***-0.31 ***\n\n(0.01)   (0.01)   \n\nConstante0.76 ***7.65 ***\n\n(0.08)   (0.08)   \n\nN22894       22894       \n\nR20.59    0.59    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\n\n\n\nComparación de modelos\nEs muy frecuente tener que elegir entre diferentes modelos. Hasta ahora, nos hemos fijado en el R2 para ver cuál era la bondad de ajuste del modelo. Aquí, vamos a introducir dos nuevos indicadores: BIC (Criterio de Información Bayesiano) y AIC (Criterio de Información de Akaike).\nCuando introducimos nuevas variables en el modelo aumentamos el ajuste (a mayor número de variables, mayor R2), pero corremos el peligro de caer en sobreajuste (introducir demasiadas variables, siendo algunas de ellas innecesarias para el modelo). Solo es conveniente incluir más variables en un modelo si la diferencia que añaden sobre la significatividad del modelo es lo suficiente relevante. BIC y AIC resuelven este problema mediante la introducción de un término de penalización para el número de parámetros en el modelo (esta penalización es mayor en el BIC que en el AIC). Así, dados dos modelos estimados, el modelo con el menor valor de BIC/AIC es preferible. Existe también el AIC corregido (AICc), que es una variante del AIC para muestras reducidas (pocos datos).\nNo es necesario realizar los dos análisis, sino que con uno de los dos es suficiente para ver qué modelo es más eficiente.\nEstimamos los modelos con el dataset reducido. El modelo1 incluye sólamente la variable ideología. El modelo2 añade el sexo y el nivel educativo. El modelo3 es el full-model, que incluye la edad y la situación laboral del entrevistado.\n\nmodelo1 &lt;- lm(prop_pp ~ hombre+estudios_universitarios, datos_red) \nmodelo2 &lt;- lm(prop_pp ~ hombre+estudios_universitarios+ ideol, datos_red)  \nmodelo3 &lt;- lm(prop_pp ~ hombre+estudios_universitarios+ideol+recuerdo19, datos_red)  \n\nVisualizamos los 3 modelos en una misma tabla\n\nlibrary(stargazer)\nstargazer(modelo1, modelo2, modelo3,    \n          type=\"text\",\n          dep.var.labels=c(\"M1\", \"M2\", \"M3\"),\n          covariate.labels=c(\"Hombre\", \"Estudios superiores\",\"Ideología\", \"Voto 2019:PP (cr: PSOE)\", \"Voto 2019:VOX (cr: PSOE)\", \"Voto 2019:Podemos (cr: PSOE)\", \"Voto 2019:C´s (cr: PSOE)\", \"Voto 2019:Más Madrid (cr: PSOE)\", \"Voto 2019:Otros (cr: PSOE)\", \"Voto 2019:Blanco (cr: PSOE)\",  \"Constante\"))\n\n\n=================================================================================================================\n                                                               Dependent variable:                               \n                                ---------------------------------------------------------------------------------\n                                                                       M1                                        \n                                         (1)                       (2)                           (3)             \n-----------------------------------------------------------------------------------------------------------------\nHombre                                 -0.112**                 -0.199***                     -0.110***          \n                                       (0.051)                   (0.039)                       (0.033)           \n                                                                                                                 \nEstudios superiores                     -0.007                   0.204***                     0.131***           \n                                       (0.051)                   (0.039)                       (0.033)           \n                                                                                                                 \nIdeología                                                        0.910***                     0.463***           \n                                                                 (0.007)                       (0.008)           \n                                                                                                                 \nVoto 2019:PP (cr: PSOE)                                                                       4.376***           \n                                                                                               (0.055)           \n                                                                                                                 \nVoto 2019:VOX (cr: PSOE)                                                                      0.842***           \n                                                                                               (0.074)           \n                                                                                                                 \nVoto 2019:Podemos (cr: PSOE)                                                                  -0.970***          \n                                                                                               (0.057)           \n                                                                                                                 \nVoto 2019:C´s (cr: PSOE)                                                                      3.069***           \n                                                                                               (0.068)           \n                                                                                                                 \nVoto 2019:Más Madrid (cr: PSOE)                                                               -0.535***          \n                                                                                               (0.191)           \n                                                                                                                 \nVoto 2019:Otros (cr: PSOE)                                                                    -0.914***          \n                                                                                               (0.053)           \n                                                                                                                 \nVoto 2019:Blanco (cr: PSOE)                                                                   0.901***           \n                                                                                               (0.140)           \n                                                                                                                 \nConstante                              3.741***                 -0.656***                     0.448***           \n                                       (0.045)                   (0.050)                       (0.047)           \n                                                                                                                 \n-----------------------------------------------------------------------------------------------------------------\nObservations                            22,894                    22,894                       22,894            \nR2                                      0.0002                    0.401                         0.581            \nAdjusted R2                             0.0001                    0.401                         0.581            \nResidual Std. Error               3.848 (df = 22891)        2.978 (df = 22890)           2.492 (df = 22883)      \nF Statistic                     2.434* (df = 2; 22891) 5,108.655*** (df = 3; 22890) 3,170.031*** (df = 10; 22883)\n=================================================================================================================\nNote:                                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nY calculamos los BIC/AIC\n\nAIC(modelo1, modelo2, modelo3)\n\n\n\ndfAIC\n\n41.27e+05\n\n51.15e+05\n\n121.07e+05\n\n\n\nBIC(modelo1, modelo2, modelo3)\n\n\n\ndfBIC\n\n41.27e+05\n\n51.15e+05\n\n121.07e+05\n\n\n\n\nDiferencias más notables:\n\nR2 ajustado es una medida de la varianza explicada en la variable de respuesta por los predictores, mientras que BIC/AIC son una compensación entre la bondad del ajuste y la complejidad del modelo.\nR2 puede subir o bajar según se agregue o no otra variable al modelo. Pero el AIC/BIC no necesariamente cambian con la adición de una variable, sino que cambia con la composición de los predictores.\nOtra ventaja adicional es que AIC/BIC permiten comparar entre modelos que no están anidados.\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Lineal múltiple"
    ]
  },
  {
    "objectID": "analisis/reg-lineal.html",
    "href": "analisis/reg-lineal.html",
    "title": "Lineal simple",
    "section": "",
    "text": "La regresión lineal se usa para predecir el valor de una variable y en función de una o más variables x. La variable dependiente debe ser numérica, y las independientes pueden ser tanto numéricas como categóricas. En el ejemplo usado, se tratará de comprobar si el Índice de Corrupción de un país (y) depende del nivel de PIB de este (x).\n\n\n# Análisis preliminar:\nscatter.smooth(x=datos_reg$var1, y=datos_reg$var2) #Gráfico de dispersión\nboxplot(datos_reg$var1, sub=paste(\"Outlier rows:  \", boxplot.stats(datos_reg$var1)$out)) #Boxplot para buscar datos atípicos\nggplot(datos_reg, aes(var1)) + geom_density(fill=\"red\", alpha=0.8) #Diagrama de densidad (librería ggplot)\n\n# Función de la regresión\nregresión &lt;- lm(var1~var2, datos_reg) #Librería e1071\nsummary(regresión)\n\n# Comprobación de los supuestos principales\nplot(regresión,2) #Normalidad de los residuos\nbptest(regresión) #Homocedasticidad (librería lmtest)\nvif(regresión) #Multicolinealidad (librería rms)\n\n#Exportar los resultados\nstargazer(regresión, type=\"text\") #Librería stargazer\n\n\n\nAntes de estimar la regresión, es importante explorar y entender la variable dependiente (fenómeno que queremos explicar).\n\nGráfico de dispersión: permite visualizar la relación lineal entre la variable independiente y la dependiente. (Es una línea de tendencia, no un gráfico de dispersión, por eso la línea no es recta)\n\n\nscatter.smooth(x=datos_reg$gdp, y=datos_reg$cpi, main=\"GDP ~ CPI\", xlab=\"GDP\", ylab=\"CPI\")\n\n\n\n\n\n\n\n\n\nBoxplot: permite detectar la presencia de observaciones atípicas (outliers). Los valores atípicos pueden afectar a la predicción, modificando la dirección/pendiente de la recta de regresión.\n\n\nboxplot(datos_reg$gdp, main=\"GDP\", sub=paste(\"Outlier rows:  \", boxplot.stats(datos_reg$gdp)$out)) \n\n\n\n\n\n\n\n\n\nSi se quiere comprobar con qué caso se corresponden los valores atípicos detectados se puede usar el siguiente comando:\n\n\n# Seleccionamos el nombre del país cuyo GDP es igual a 30491.34375\noutlier_gdp &lt;- datos_reg %&gt;%\n  filter(gdp == 30491.34375) %&gt;% \n  pull(cname)\ntable(outlier_gdp)\n\noutlier_gdp\nUnited States \n            1 \n\n\n\nDiagrama de densidad: para ver la distribución de la variable. Idealmente, la distribución ha de ser cercana a la normal. Si esto no ocurre, será necesario realizar alguna transformación en los datos empleados.\n\n\nggplot(datos_reg, aes(cpi)) + geom_density(fill=\"red\", alpha=0.8)\n\n\n\n\n\n\n\n\n\n\n\nLa función utilizada para construir modelos lineales es lm() del paquete e1071, que toma dos argumentos principales: lm(var_dependiente ~ var_independiente, datos)\n\nlibrary(e1071)\nreg.lineal &lt;- lm(cpi~gdp, data=datos_reg) #El argumento \"data=\" se puede omitir, basta con poner la base de datos. Es decir, se puede escribir directamente: lm(cpi~gdp, datos_reg)\nreg.lineal #Conviene guardar las regresiones dentro de un objeto, ya que de otra forma no se podrían realizar los pasos posteriores.\n\n\nCall:\nlm(formula = cpi ~ gdp, data = datos_reg)\n\nCoefficients:\n(Intercept)          gdp  \n  24.237839     0.002163  \n\n\n\n\n\nPara evaluar los resultados, imprimimos las estadísticas de resumen para el modelo:\n\nsummary(reg.lineal)\n\n\nCall:\nlm(formula = cpi ~ gdp, data = datos_reg)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.5964  -5.0369   0.3185   6.4699  25.9107 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.424e+01  1.521e+00   15.94   &lt;2e-16 ***\ngdp         2.163e-03  1.205e-04   17.95   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.22 on 108 degrees of freedom\n  (84 observations deleted due to missingness)\nMultiple R-squared:  0.749, Adjusted R-squared:  0.7467 \nF-statistic: 322.3 on 1 and 108 DF,  p-value: &lt; 2.2e-16\n\n\n\nLos coeficientes indican la contribución de cada variable independiente al modelo de regresión.\n\nIntercept(β0). Establece el valor de la variable y cuando la varible x es 0 (el punto donde la recta de regresión corta la ordenada en el orígen). En el ejemplo, el intercepto (β0)= 24.237, lo que significa que, para un país con GDP=0, el valor de su cpi sería 24.237.\nEl coeficiente de la variable independiente: establece el incremento promedio que experimentará la variable dependiente (y) por cada unidad que se incremetne la variable independiente (x). En el ejemplo, el coeficiente del gdp (β1)=0.002163, lo que significa que por cada incremento de un dolar en el gdp de un país, el cpi aumenta en 0.002163 puntos.\n\nLa evaluación de la significatividad de los coeficientes (βi) comienza con la definición de hipótesis sobre los valores de los parámetros poblacionales:\n\nHipótesis nula: H0: βi=0 (el valor del coeficiente en la población es 0).\nHipótesis alternativa: H1: βi≠0 (el valor del coeficiente en la población es distinto de 0).\nEn el summario de la regresión, se puede comprobar observando el valor de la columna con t value (muestra la prueba t asociada a cada βi) o el p-valor de la columna Pr (&gt; | t |).\n\nLa bondad de ajuste del modelo (R2) mide el porcentaje de varianza de la variable dependiente (Y) que queda explicado con nuestro modelo. Varía entre 0 y 1, y puede interpretarse como un porcentaje. Sin embargo, a medida que agregamos nuevas variables al modelo, el valor R-Squared será mayor. Adj R-Squared penaliza por el número de parámetros en el modelo. Por lo tanto, al comparar modelos anidados, es una buena práctica observar el valor de R2 ajustado sobre R2. En el ejemplo, podemos decir que un 74,67% de la variación en el índice de corrupción se puede explicar gracias a las diferencias en el PIB.\nLa significatividad del modelo (F de Snedecor). Un F estadísticamente significativo significa que al menos uno de los coficientes es estadísticamente significativo. Es decir, que nuestro modelo predice mejor que un modelo sin variables.\n\n\n\n\n\nLinealidad. El supuesto de linealidad puede ser comprobada con un gráfico de Residuos vs Valores Predichos.La línea horizontal, sin patrones distintivos en los puntos, indica una relación lineal.\n\n\nplot(reg.lineal, 1)\n\n\n\n\n\n\n\n\n\nNormalidad de los residuos.\n\n\n\nEl gráfico QQ de residuos puede usarse para comprobar visualmente el supuesto de normalidad. En este gráfico, los residuos debería seguir aproximadamente una línea recta.\n\n\nplot(reg.lineal, 2)\n\n\n\n\n\n\n\n\n\nCuando la visualización no es clara y tenemos dudas, podemos hacer un test. Por ejemplo, el de Shapiro-Wilk. La Ho en este test es que los residuos están normalmente distribuidos (lo que queremos). El problema de este test es que está limitado a bases de datos con n menor a 5000 casos. Los resultados confirman que no podemos rechazarla.\n\n\nnorm=rstudent(reg.lineal)\nshapiro.test(norm)\n\n\n    Shapiro-Wilk normality test\n\ndata:  norm\nW = 0.98446, p-value = 0.2316\n\n\nUsando estos mismos datos, también se puede comprobar que la media de los residuos es igual a 0, lo que se calcula gracias a la media. Idealmente, debemos encontrar un valor muy próximo a cero.\n\nmean(reg.lineal$residuals)\n\n[1] -2.959911e-16\n\n\n\nHistograma de los residuos.\n\n\nhist(reg.lineal$residuals, freq = F)\n# Para superponer la curva normal\nm&lt;-mean(reg.lineal$residuals)\nstd&lt;-sqrt(var(reg.lineal$residuals))\ncurve(dnorm(x, mean=m, sd=std), col=\"darkblue\", lwd=2, add=T)\n\n\n\n\n\n\n\n\nNo es necesario hacer las tres opciones, sino que con elegir una es suficiente.\n\nHomocedasticidad.\n\n\n\nEste supuesto puede comprobarse examinando el diagrama de scale-location. El gráfico muestra si los residuos se distribuyen equitativamente a lo largo de los rangos de las variables independientes. Deberíamos de observar una línea horizonal, sin fuertes tendencias.\n\n\nplot(reg.lineal, 3)\n\n\n\n\n\n\n\n\n\nPara tener un resultado más concluyente, hacemos un test de heterocedasticidad. La Ho en este test es que la varianza de los residuos es constante (homocedástica, lo que queremos). La evidencia no permite rechazar la hipótesis nula, por lo cual afirmamos que la distribución es homocedástica.\n\n\np_load(lmtest)\nbptest(reg.lineal)\n\n\n    studentized Breusch-Pagan test\n\ndata:  reg.lineal\nBP = 1.5496, df = 1, p-value = 0.2132\n\n\nPara este supuesto es mejor el test que la imágen (más dificil de interpretar)\n\nIndependencia de los residuos Durbin Watson permite examinar si los residuos se autocorrelacionan con ellos mismos. La Ho en este test es que no están autocorrelacionados (lo que queremos). Esta prueba podría ser especialmente útil cuando tenemos series temporales (correlación serial, encuestas tipo panel). Por ejemplo, esta prueba podría decirte si los residuos en el momento T1 están correlacionados con los residuos en el momento T2 (no deberían estarlo). En los datos de sección cruzada es menos común, aunque posible (correlación espacial).\n\n\np_load(car)\ndurbinWatsonTest(reg.lineal)\n\n lag Autocorrelation D-W Statistic p-value\n   1        0.151464      1.682134   0.096\n Alternative hypothesis: rho != 0\n\n\np-value&gt;0.5. No podemos rechazar la Ho, lo que indica que los errores no están autocorrelacionados (lo que queremos).\n\nMulticolinealidad. Hace referencia a la correlación entre las VIs. Podemos medir la existencia de multicolinealidad usado el VIF (Variation Inflation Factor). Si el valor está por debajo de 5 está bien, no hay multicolinealidad. Por encima, si no sobrepasa demasiado esta cifra, y las variables que correlacionan son importantes para el análisis que se quiere realizar, se puede aceptar este supuesto aunque la multicolinealidad sea superior a 5.\n\n\np_load(rms)\nvif(reg.lineal)\n\ngdp \n  1 \n\n\nHacer los test a la vez\n\nCon la función plot() de R base para obtener todos los gráficos de manera conjunta.\n\n\npar(mfrow=c(2,2))\nplot(reg.lineal, pch=23 ,bg='red', cex=2) \n\n\n\n\n\n\n\n\nHemos visto arriba cómo interpretar gráficos 1-3. El gráfico inferior-derecha nos ayuda a detectar casos influyentes. Leverage es una medida de cuánta influencia ejerce cada punto la recta de regresión. No todos los valores atípicos son influyentes en el análisis de regresión lineal. Al contrario, se puede dar el caso de que haya valores extremos que no son determinantes a la hora de estima la recta de gresión, por lo que los resultados no serían muy diferentes si los excluímos del análisis. Sin embargo, si los casos están fuera de la distancia de Cook (lo que significa que tienen puntuaciones de distancia de Cook altas), los resultados de la regresión se alterarán si excluimos esos casos. Para un buen modelo de regresión, la línea suavizada roja debe permanecer cerca de la línea media y ningún punto debe tener una distancia de Cook grande. Si queremos identificar esos puntos en concreto (son los que se indican con un *):\n\ninfluence.measures(reg.lineal)\n\nInfluence measures of\n     lm(formula = cpi ~ gdp, data = datos_reg) :\n\n       dfb.1_   dfb.gdp     dffit cov.r   cook.d     hat inf\n2   -4.80e-02  0.024368 -5.18e-02 1.026 1.35e-03 0.01167    \n3    4.81e-02 -0.029947  4.94e-02 1.030 1.23e-03 0.01438    \n5   -6.26e-02  0.044437 -6.29e-02 1.034 1.99e-03 0.01817    \n7   -1.05e-01  0.015211 -1.46e-01 0.985 1.06e-02 0.00919    \n8   -6.88e-02 -0.008246 -1.17e-01 1.000 6.87e-03 0.00914    \n9   -1.20e-02  0.027132  3.04e-02 1.065 4.68e-04 0.04418   *\n10   5.16e-02 -0.126716 -1.45e-01 1.048 1.06e-02 0.03792    \n12   1.36e-01 -0.072942  1.44e-01 1.000 1.03e-02 0.01223    \n13   2.22e-05 -0.000016  2.22e-05 1.038 2.49e-10 0.01891    \n14  -5.75e-02 -0.006348 -9.75e-02 1.009 4.75e-03 0.00913    \n16   1.25e-03 -0.003170 -3.67e-03 1.057 6.80e-06 0.03580   *\n18   3.75e-02 -0.024186  3.82e-02 1.033 7.35e-04 0.01518    \n19   6.45e-02 -0.033373  6.92e-02 1.023 2.41e-03 0.01185    \n21   2.45e-02 -0.009383  2.86e-02 1.028 4.13e-04 0.01019    \n25  -1.72e-02  0.002221 -2.43e-02 1.027 2.99e-04 0.00917    \n26  -1.29e-01  0.078765 -1.33e-01 1.010 8.77e-03 0.01405    \n28  -6.33e-02 -0.117466 -2.67e-01 0.920 3.39e-02 0.01128   *\n29  -1.20e-01  0.080819 -1.21e-01 1.019 7.36e-03 0.01636    \n30  -2.45e-02  0.017800 -2.46e-02 1.038 3.04e-04 0.01914    \n31  -2.20e-02  0.051373  5.82e-02 1.061 1.71e-03 0.04140   *\n34   1.15e-02 -0.005865  1.24e-02 1.031 7.81e-05 0.01169    \n36   3.87e-02  0.082522  1.79e-01 0.980 1.58e-02 0.01154    \n37  -1.21e-02  0.003088 -1.54e-02 1.028 1.20e-04 0.00947    \n38   8.58e-02 -0.222098 -2.58e-01 1.020 3.31e-02 0.03479    \n39  -2.93e-02  0.010693 -3.47e-02 1.027 6.06e-04 0.01005    \n42  -4.08e-02  0.030954 -4.08e-02 1.040 8.39e-04 0.02143    \n43   8.66e-02 -0.022573  1.10e-01 1.005 6.08e-03 0.00949    \n44   1.44e-02  0.000463  2.30e-02 1.027 2.68e-04 0.00909    \n47  -1.36e-02 -0.018070 -4.65e-02 1.026 1.09e-03 0.01071    \n49  -1.04e-01  0.264626  3.07e-01 1.008 4.63e-02 0.03563    \n52  -1.63e-03  0.000863 -1.73e-03 1.031 1.52e-06 0.01208    \n55   9.41e-02 -0.069173  9.42e-02 1.031 4.46e-03 0.01973    \n57  -6.04e-03  0.028439  3.76e-02 1.040 7.14e-04 0.02122    \n59  -9.07e-02  0.234781  2.73e-01 1.016 3.69e-02 0.03478    \n60  -1.39e-03  0.004254  5.16e-03 1.049 1.34e-05 0.02839    \n63   1.05e-01 -0.046799  1.17e-01 1.006 6.88e-03 0.01081    \n65  -3.47e-02  0.117655  1.46e-01 1.030 1.07e-02 0.02581    \n66   2.32e-01 -0.161852  2.34e-01 0.980 2.68e-02 0.01746    \n68  -2.54e-02 -0.094179 -1.79e-01 0.985 1.58e-02 0.01257    \n70  -5.22e-02  0.029655 -5.46e-02 1.028 1.50e-03 0.01289    \n75   8.46e-02 -0.018178  1.12e-01 1.003 6.22e-03 0.00934    \n77   5.23e-02 -0.032886  5.35e-02 1.030 1.44e-03 0.01463    \n79  -1.18e-01  0.049841 -1.34e-01 0.998 8.97e-03 0.01054    \n80  -1.57e-01  0.111283 -1.58e-01 1.012 1.24e-02 0.01815    \n81  -7.43e-04  0.002142  2.56e-03 1.050 3.31e-06 0.03019    \n82   1.15e-02 -0.052365 -6.88e-02 1.037 2.39e-03 0.02158    \n84   2.43e-03 -0.001763  2.44e-03 1.039 2.99e-06 0.01910    \n85   6.81e-02 -0.042009  7.00e-02 1.027 2.47e-03 0.01421    \n86  -1.15e-02  0.033553  4.02e-02 1.049 8.16e-04 0.02992    \n87  -1.07e-01 -0.042074 -2.21e-01 0.937 2.35e-02 0.00943   *\n88   8.25e-02 -0.040203  9.00e-02 1.017 4.06e-03 0.01136    \n89   4.05e-03 -0.002945  4.06e-03 1.039 8.30e-06 0.01923    \n91   7.80e-02 -0.232423 -2.80e-01 1.000 3.87e-02 0.02913    \n92  -2.90e-02 -0.024579 -7.87e-02 1.018 3.11e-03 0.01007    \n93  -8.00e-02  0.052025 -8.13e-02 1.027 3.32e-03 0.01540    \n97   1.22e-02  0.007756  2.94e-02 1.027 4.37e-04 0.00977    \n101  4.35e-02  0.013714  8.54e-02 1.014 3.65e-03 0.00933    \n103  3.26e-02 -0.024281  3.26e-02 1.039 5.37e-04 0.02037    \n104  1.59e-01 -0.118003  1.59e-01 1.016 1.26e-02 0.02023    \n105  2.22e-02  0.001854  3.69e-02 1.025 6.85e-04 0.00911    \n107  2.03e-02 -0.014865  2.04e-02 1.039 2.10e-04 0.01943    \n111 -5.39e-02  0.015849 -6.70e-02 1.020 2.25e-03 0.00963    \n114  1.97e-02 -0.011571  2.05e-02 1.032 2.12e-04 0.01335    \n115  3.18e-02 -0.010734  3.83e-02 1.026 7.39e-04 0.00987    \n116  4.49e-02 -0.026687  4.66e-02 1.030 1.09e-03 0.01354    \n117  1.36e-03 -0.000908  1.38e-03 1.035 9.60e-07 0.01604    \n118  8.97e-03  0.000233  1.43e-02 1.028 1.03e-04 0.00909    \n122 -4.47e-02  0.108235  1.24e-01 1.052 7.70e-03 0.03875    \n124 -5.86e-02  0.288122  3.84e-01 0.918 6.98e-02 0.02084   *\n126  1.24e-01 -0.093081  1.24e-01 1.026 7.73e-03 0.02076    \n127 -4.31e-02  0.030073 -4.33e-02 1.035 9.45e-04 0.01756    \n128 -1.32e-02  0.027227  2.98e-02 1.078 4.47e-04 0.05559   *\n132 -2.04e-02  0.013686 -2.06e-02 1.035 2.14e-04 0.01628    \n136  1.21e-02 -0.005783  1.33e-02 1.030 8.90e-05 0.01122    \n137  6.27e-02 -0.040580  6.38e-02 1.029 2.05e-03 0.01526    \n138  6.35e-02  0.015654  1.19e-01 1.000 7.02e-03 0.00925    \n139  1.33e-02  0.036739  7.44e-02 1.022 2.78e-03 0.01202    \n142  6.58e-02  0.051678  1.72e-01 0.975 1.46e-02 0.00999    \n143  9.18e-02 -0.051045  9.66e-02 1.018 4.68e-03 0.01261    \n144 -1.05e-01  0.017975 -1.43e-01 0.987 1.01e-02 0.00924    \n151 -1.68e-03 -0.000181 -2.85e-03 1.028 4.09e-06 0.00913    \n152  1.82e-01 -0.130145  1.83e-01 1.004 1.66e-02 0.01838    \n153  1.53e-02 -0.005150  1.85e-02 1.028 1.72e-04 0.00986    \n156  1.24e-02 -0.024756 -2.68e-02 1.085 3.63e-04 0.06108   *\n157 -1.62e-02 -0.018856 -5.14e-02 1.025 1.33e-03 0.01050    \n158 -2.32e-03  0.001476 -2.36e-03 1.034 2.82e-06 0.01490    \n159  5.01e-03 -0.047260 -6.79e-02 1.032 2.32e-03 0.01763    \n162 -6.86e-02  0.050899 -6.87e-02 1.035 2.37e-03 0.02018    \n163  4.94e-04 -0.013027 -1.97e-02 1.035 1.97e-04 0.01611    \n168 -8.21e-02  0.188530  2.12e-01 1.045 2.25e-02 0.04296    \n169 -5.23e-02  0.121760  1.38e-01 1.055 9.52e-03 0.04179    \n170 -1.90e-01  0.050467 -2.41e-01 0.922 2.77e-02 0.00951   *\n171 -7.74e-02  0.054745 -7.77e-02 1.031 3.04e-03 0.01803    \n172 -6.00e-02  0.003478 -8.95e-02 1.012 4.01e-03 0.00910    \n176  3.65e-02  0.071512  1.59e-01 0.989 1.26e-02 0.01138    \n177  2.67e-02 -0.011426  3.02e-02 1.028 4.59e-04 0.01061    \n179 -1.83e-01  0.104072 -1.91e-01 0.980 1.80e-02 0.01292    \n181 -1.02e-02  0.007416 -1.02e-02 1.039 5.27e-05 0.01919    \n182 -9.63e-02  0.054330 -1.01e-01 1.017 5.11e-03 0.01279    \n183  5.95e-02 -0.026691  6.65e-02 1.022 2.22e-03 0.01084    \n184 -1.59e-02  0.009246 -1.66e-02 1.032 1.39e-04 0.01317    \n185 -2.22e-03  0.005559  6.41e-03 1.058 2.07e-05 0.03666   *\n186  9.89e-02 -0.073192  9.90e-02 1.030 4.92e-03 0.02005    \n187  2.32e-01 -0.447094 -4.80e-01 1.034 1.13e-01 0.06919   *\n188  1.52e-01 -0.110254  1.53e-01 1.016 1.16e-02 0.01901    \n189  1.07e-01  0.052107  2.35e-01 0.927 2.65e-02 0.00956   *\n190 -1.92e-01  0.087686 -2.13e-01 0.956 2.20e-02 0.01095    \n191 -1.54e-01 -0.005725 -2.47e-01 0.911 2.90e-02 0.00910   *\n193 -1.57e-01  0.100145 -1.60e-01 1.003 1.27e-02 0.01500    \n194  1.70e-01 -0.126161  1.71e-01 1.013 1.45e-02 0.02007    \n\n\n\nGloval Validation of Linear Models Assumptions (paquete gvlma).\n\n\np_load(gvlma)\ngvlma::gvlma(reg.lineal)\n\n\nCall:\nlm(formula = cpi ~ gdp, data = datos_reg)\n\nCoefficients:\n(Intercept)          gdp  \n  24.237839     0.002163  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = reg.lineal) \n\n                    Value p-value                Decision\nGlobal Stat        5.2691 0.26078 Assumptions acceptable.\nSkewness           1.2784 0.25819 Assumptions acceptable.\nKurtosis           0.1015 0.75004 Assumptions acceptable.\nLink Function      0.4845 0.48641 Assumptions acceptable.\nHeteroscedasticity 3.4047 0.06501 Assumptions acceptable.\n\n\nConcretamente:\n\nGlobal Stat mide si relación entre las VIs y la VD es realmente lineal. El rechazo de la Ho indica que la relación no es lineal.\nSkewness mide si la distribución está sesgada y necesita una transformación para cumplir con el supuesto de normalidad. El rechazo de la Ho indica que los datos deberían ser transformados.\nKurtosis mide si la distribución es leptocúrtica o platicúrtica. El rechazo de la Ho indica que los datos deberían ser transformados.\nLink Function indica si la variable dependiente es realmente continua o es categórica. El rechazo de la Ho indica que sería conveniente usar un modelo alternativo de regresión, como el logístico o la regresión binomial.\nHeteroscedasticity mide el supuesto de homocedasticidad. El rechazo de la Ho indica que los residuos son heterocedásticos, y que el modelo precide unos rangos de la variable dependiente mejor que otros.\n\nEn la práctica, lo importante es mirar los siguientes supuetos: multicolinealidad (sobre todo esta, porque se puede ver a simple vista si sabes del tema) y homocedasticidad.\n\n\n\nEsta librería cuenta con numerosas opciones para modificar la tabla con los resultados (?stargazer)\n\np_load(stargazer)\nstargazer(reg.lineal,\n          type=\"text\",\n          dep.var.labels=c(\"Corruption Perception Index\"),\n          covariate.labels=c(\"GDP\",\"cte\"))\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                    Corruption Perception Index\n-----------------------------------------------\nGDP                          0.002***          \n                             (0.0001)          \n                                               \ncte                          24.238***         \n                              (1.521)          \n                                               \n-----------------------------------------------\nObservations                    110            \nR2                             0.749           \nAdjusted R2                    0.747           \nResidual Std. Error      10.225 (df = 108)     \nF Statistic          322.340*** (df = 1; 108)  \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Lineal simple"
    ]
  },
  {
    "objectID": "analisis/reg-lineal.html#en-r",
    "href": "analisis/reg-lineal.html#en-r",
    "title": "Lineal simple",
    "section": "",
    "text": "La regresión lineal se usa para predecir el valor de una variable y en función de una o más variables x. La variable dependiente debe ser numérica, y las independientes pueden ser tanto numéricas como categóricas. En el ejemplo usado, se tratará de comprobar si el Índice de Corrupción de un país (y) depende del nivel de PIB de este (x).\n\n\n# Análisis preliminar:\nscatter.smooth(x=datos_reg$var1, y=datos_reg$var2) #Gráfico de dispersión\nboxplot(datos_reg$var1, sub=paste(\"Outlier rows:  \", boxplot.stats(datos_reg$var1)$out)) #Boxplot para buscar datos atípicos\nggplot(datos_reg, aes(var1)) + geom_density(fill=\"red\", alpha=0.8) #Diagrama de densidad (librería ggplot)\n\n# Función de la regresión\nregresión &lt;- lm(var1~var2, datos_reg) #Librería e1071\nsummary(regresión)\n\n# Comprobación de los supuestos principales\nplot(regresión,2) #Normalidad de los residuos\nbptest(regresión) #Homocedasticidad (librería lmtest)\nvif(regresión) #Multicolinealidad (librería rms)\n\n#Exportar los resultados\nstargazer(regresión, type=\"text\") #Librería stargazer\n\n\n\nAntes de estimar la regresión, es importante explorar y entender la variable dependiente (fenómeno que queremos explicar).\n\nGráfico de dispersión: permite visualizar la relación lineal entre la variable independiente y la dependiente. (Es una línea de tendencia, no un gráfico de dispersión, por eso la línea no es recta)\n\n\nscatter.smooth(x=datos_reg$gdp, y=datos_reg$cpi, main=\"GDP ~ CPI\", xlab=\"GDP\", ylab=\"CPI\")\n\n\n\n\n\n\n\n\n\nBoxplot: permite detectar la presencia de observaciones atípicas (outliers). Los valores atípicos pueden afectar a la predicción, modificando la dirección/pendiente de la recta de regresión.\n\n\nboxplot(datos_reg$gdp, main=\"GDP\", sub=paste(\"Outlier rows:  \", boxplot.stats(datos_reg$gdp)$out)) \n\n\n\n\n\n\n\n\n\nSi se quiere comprobar con qué caso se corresponden los valores atípicos detectados se puede usar el siguiente comando:\n\n\n# Seleccionamos el nombre del país cuyo GDP es igual a 30491.34375\noutlier_gdp &lt;- datos_reg %&gt;%\n  filter(gdp == 30491.34375) %&gt;% \n  pull(cname)\ntable(outlier_gdp)\n\noutlier_gdp\nUnited States \n            1 \n\n\n\nDiagrama de densidad: para ver la distribución de la variable. Idealmente, la distribución ha de ser cercana a la normal. Si esto no ocurre, será necesario realizar alguna transformación en los datos empleados.\n\n\nggplot(datos_reg, aes(cpi)) + geom_density(fill=\"red\", alpha=0.8)\n\n\n\n\n\n\n\n\n\n\n\nLa función utilizada para construir modelos lineales es lm() del paquete e1071, que toma dos argumentos principales: lm(var_dependiente ~ var_independiente, datos)\n\nlibrary(e1071)\nreg.lineal &lt;- lm(cpi~gdp, data=datos_reg) #El argumento \"data=\" se puede omitir, basta con poner la base de datos. Es decir, se puede escribir directamente: lm(cpi~gdp, datos_reg)\nreg.lineal #Conviene guardar las regresiones dentro de un objeto, ya que de otra forma no se podrían realizar los pasos posteriores.\n\n\nCall:\nlm(formula = cpi ~ gdp, data = datos_reg)\n\nCoefficients:\n(Intercept)          gdp  \n  24.237839     0.002163  \n\n\n\n\n\nPara evaluar los resultados, imprimimos las estadísticas de resumen para el modelo:\n\nsummary(reg.lineal)\n\n\nCall:\nlm(formula = cpi ~ gdp, data = datos_reg)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.5964  -5.0369   0.3185   6.4699  25.9107 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 2.424e+01  1.521e+00   15.94   &lt;2e-16 ***\ngdp         2.163e-03  1.205e-04   17.95   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.22 on 108 degrees of freedom\n  (84 observations deleted due to missingness)\nMultiple R-squared:  0.749, Adjusted R-squared:  0.7467 \nF-statistic: 322.3 on 1 and 108 DF,  p-value: &lt; 2.2e-16\n\n\n\nLos coeficientes indican la contribución de cada variable independiente al modelo de regresión.\n\nIntercept(β0). Establece el valor de la variable y cuando la varible x es 0 (el punto donde la recta de regresión corta la ordenada en el orígen). En el ejemplo, el intercepto (β0)= 24.237, lo que significa que, para un país con GDP=0, el valor de su cpi sería 24.237.\nEl coeficiente de la variable independiente: establece el incremento promedio que experimentará la variable dependiente (y) por cada unidad que se incremetne la variable independiente (x). En el ejemplo, el coeficiente del gdp (β1)=0.002163, lo que significa que por cada incremento de un dolar en el gdp de un país, el cpi aumenta en 0.002163 puntos.\n\nLa evaluación de la significatividad de los coeficientes (βi) comienza con la definición de hipótesis sobre los valores de los parámetros poblacionales:\n\nHipótesis nula: H0: βi=0 (el valor del coeficiente en la población es 0).\nHipótesis alternativa: H1: βi≠0 (el valor del coeficiente en la población es distinto de 0).\nEn el summario de la regresión, se puede comprobar observando el valor de la columna con t value (muestra la prueba t asociada a cada βi) o el p-valor de la columna Pr (&gt; | t |).\n\nLa bondad de ajuste del modelo (R2) mide el porcentaje de varianza de la variable dependiente (Y) que queda explicado con nuestro modelo. Varía entre 0 y 1, y puede interpretarse como un porcentaje. Sin embargo, a medida que agregamos nuevas variables al modelo, el valor R-Squared será mayor. Adj R-Squared penaliza por el número de parámetros en el modelo. Por lo tanto, al comparar modelos anidados, es una buena práctica observar el valor de R2 ajustado sobre R2. En el ejemplo, podemos decir que un 74,67% de la variación en el índice de corrupción se puede explicar gracias a las diferencias en el PIB.\nLa significatividad del modelo (F de Snedecor). Un F estadísticamente significativo significa que al menos uno de los coficientes es estadísticamente significativo. Es decir, que nuestro modelo predice mejor que un modelo sin variables.\n\n\n\n\n\nLinealidad. El supuesto de linealidad puede ser comprobada con un gráfico de Residuos vs Valores Predichos.La línea horizontal, sin patrones distintivos en los puntos, indica una relación lineal.\n\n\nplot(reg.lineal, 1)\n\n\n\n\n\n\n\n\n\nNormalidad de los residuos.\n\n\n\nEl gráfico QQ de residuos puede usarse para comprobar visualmente el supuesto de normalidad. En este gráfico, los residuos debería seguir aproximadamente una línea recta.\n\n\nplot(reg.lineal, 2)\n\n\n\n\n\n\n\n\n\nCuando la visualización no es clara y tenemos dudas, podemos hacer un test. Por ejemplo, el de Shapiro-Wilk. La Ho en este test es que los residuos están normalmente distribuidos (lo que queremos). El problema de este test es que está limitado a bases de datos con n menor a 5000 casos. Los resultados confirman que no podemos rechazarla.\n\n\nnorm=rstudent(reg.lineal)\nshapiro.test(norm)\n\n\n    Shapiro-Wilk normality test\n\ndata:  norm\nW = 0.98446, p-value = 0.2316\n\n\nUsando estos mismos datos, también se puede comprobar que la media de los residuos es igual a 0, lo que se calcula gracias a la media. Idealmente, debemos encontrar un valor muy próximo a cero.\n\nmean(reg.lineal$residuals)\n\n[1] -2.959911e-16\n\n\n\nHistograma de los residuos.\n\n\nhist(reg.lineal$residuals, freq = F)\n# Para superponer la curva normal\nm&lt;-mean(reg.lineal$residuals)\nstd&lt;-sqrt(var(reg.lineal$residuals))\ncurve(dnorm(x, mean=m, sd=std), col=\"darkblue\", lwd=2, add=T)\n\n\n\n\n\n\n\n\nNo es necesario hacer las tres opciones, sino que con elegir una es suficiente.\n\nHomocedasticidad.\n\n\n\nEste supuesto puede comprobarse examinando el diagrama de scale-location. El gráfico muestra si los residuos se distribuyen equitativamente a lo largo de los rangos de las variables independientes. Deberíamos de observar una línea horizonal, sin fuertes tendencias.\n\n\nplot(reg.lineal, 3)\n\n\n\n\n\n\n\n\n\nPara tener un resultado más concluyente, hacemos un test de heterocedasticidad. La Ho en este test es que la varianza de los residuos es constante (homocedástica, lo que queremos). La evidencia no permite rechazar la hipótesis nula, por lo cual afirmamos que la distribución es homocedástica.\n\n\np_load(lmtest)\nbptest(reg.lineal)\n\n\n    studentized Breusch-Pagan test\n\ndata:  reg.lineal\nBP = 1.5496, df = 1, p-value = 0.2132\n\n\nPara este supuesto es mejor el test que la imágen (más dificil de interpretar)\n\nIndependencia de los residuos Durbin Watson permite examinar si los residuos se autocorrelacionan con ellos mismos. La Ho en este test es que no están autocorrelacionados (lo que queremos). Esta prueba podría ser especialmente útil cuando tenemos series temporales (correlación serial, encuestas tipo panel). Por ejemplo, esta prueba podría decirte si los residuos en el momento T1 están correlacionados con los residuos en el momento T2 (no deberían estarlo). En los datos de sección cruzada es menos común, aunque posible (correlación espacial).\n\n\np_load(car)\ndurbinWatsonTest(reg.lineal)\n\n lag Autocorrelation D-W Statistic p-value\n   1        0.151464      1.682134   0.096\n Alternative hypothesis: rho != 0\n\n\np-value&gt;0.5. No podemos rechazar la Ho, lo que indica que los errores no están autocorrelacionados (lo que queremos).\n\nMulticolinealidad. Hace referencia a la correlación entre las VIs. Podemos medir la existencia de multicolinealidad usado el VIF (Variation Inflation Factor). Si el valor está por debajo de 5 está bien, no hay multicolinealidad. Por encima, si no sobrepasa demasiado esta cifra, y las variables que correlacionan son importantes para el análisis que se quiere realizar, se puede aceptar este supuesto aunque la multicolinealidad sea superior a 5.\n\n\np_load(rms)\nvif(reg.lineal)\n\ngdp \n  1 \n\n\nHacer los test a la vez\n\nCon la función plot() de R base para obtener todos los gráficos de manera conjunta.\n\n\npar(mfrow=c(2,2))\nplot(reg.lineal, pch=23 ,bg='red', cex=2) \n\n\n\n\n\n\n\n\nHemos visto arriba cómo interpretar gráficos 1-3. El gráfico inferior-derecha nos ayuda a detectar casos influyentes. Leverage es una medida de cuánta influencia ejerce cada punto la recta de regresión. No todos los valores atípicos son influyentes en el análisis de regresión lineal. Al contrario, se puede dar el caso de que haya valores extremos que no son determinantes a la hora de estima la recta de gresión, por lo que los resultados no serían muy diferentes si los excluímos del análisis. Sin embargo, si los casos están fuera de la distancia de Cook (lo que significa que tienen puntuaciones de distancia de Cook altas), los resultados de la regresión se alterarán si excluimos esos casos. Para un buen modelo de regresión, la línea suavizada roja debe permanecer cerca de la línea media y ningún punto debe tener una distancia de Cook grande. Si queremos identificar esos puntos en concreto (son los que se indican con un *):\n\ninfluence.measures(reg.lineal)\n\nInfluence measures of\n     lm(formula = cpi ~ gdp, data = datos_reg) :\n\n       dfb.1_   dfb.gdp     dffit cov.r   cook.d     hat inf\n2   -4.80e-02  0.024368 -5.18e-02 1.026 1.35e-03 0.01167    \n3    4.81e-02 -0.029947  4.94e-02 1.030 1.23e-03 0.01438    \n5   -6.26e-02  0.044437 -6.29e-02 1.034 1.99e-03 0.01817    \n7   -1.05e-01  0.015211 -1.46e-01 0.985 1.06e-02 0.00919    \n8   -6.88e-02 -0.008246 -1.17e-01 1.000 6.87e-03 0.00914    \n9   -1.20e-02  0.027132  3.04e-02 1.065 4.68e-04 0.04418   *\n10   5.16e-02 -0.126716 -1.45e-01 1.048 1.06e-02 0.03792    \n12   1.36e-01 -0.072942  1.44e-01 1.000 1.03e-02 0.01223    \n13   2.22e-05 -0.000016  2.22e-05 1.038 2.49e-10 0.01891    \n14  -5.75e-02 -0.006348 -9.75e-02 1.009 4.75e-03 0.00913    \n16   1.25e-03 -0.003170 -3.67e-03 1.057 6.80e-06 0.03580   *\n18   3.75e-02 -0.024186  3.82e-02 1.033 7.35e-04 0.01518    \n19   6.45e-02 -0.033373  6.92e-02 1.023 2.41e-03 0.01185    \n21   2.45e-02 -0.009383  2.86e-02 1.028 4.13e-04 0.01019    \n25  -1.72e-02  0.002221 -2.43e-02 1.027 2.99e-04 0.00917    \n26  -1.29e-01  0.078765 -1.33e-01 1.010 8.77e-03 0.01405    \n28  -6.33e-02 -0.117466 -2.67e-01 0.920 3.39e-02 0.01128   *\n29  -1.20e-01  0.080819 -1.21e-01 1.019 7.36e-03 0.01636    \n30  -2.45e-02  0.017800 -2.46e-02 1.038 3.04e-04 0.01914    \n31  -2.20e-02  0.051373  5.82e-02 1.061 1.71e-03 0.04140   *\n34   1.15e-02 -0.005865  1.24e-02 1.031 7.81e-05 0.01169    \n36   3.87e-02  0.082522  1.79e-01 0.980 1.58e-02 0.01154    \n37  -1.21e-02  0.003088 -1.54e-02 1.028 1.20e-04 0.00947    \n38   8.58e-02 -0.222098 -2.58e-01 1.020 3.31e-02 0.03479    \n39  -2.93e-02  0.010693 -3.47e-02 1.027 6.06e-04 0.01005    \n42  -4.08e-02  0.030954 -4.08e-02 1.040 8.39e-04 0.02143    \n43   8.66e-02 -0.022573  1.10e-01 1.005 6.08e-03 0.00949    \n44   1.44e-02  0.000463  2.30e-02 1.027 2.68e-04 0.00909    \n47  -1.36e-02 -0.018070 -4.65e-02 1.026 1.09e-03 0.01071    \n49  -1.04e-01  0.264626  3.07e-01 1.008 4.63e-02 0.03563    \n52  -1.63e-03  0.000863 -1.73e-03 1.031 1.52e-06 0.01208    \n55   9.41e-02 -0.069173  9.42e-02 1.031 4.46e-03 0.01973    \n57  -6.04e-03  0.028439  3.76e-02 1.040 7.14e-04 0.02122    \n59  -9.07e-02  0.234781  2.73e-01 1.016 3.69e-02 0.03478    \n60  -1.39e-03  0.004254  5.16e-03 1.049 1.34e-05 0.02839    \n63   1.05e-01 -0.046799  1.17e-01 1.006 6.88e-03 0.01081    \n65  -3.47e-02  0.117655  1.46e-01 1.030 1.07e-02 0.02581    \n66   2.32e-01 -0.161852  2.34e-01 0.980 2.68e-02 0.01746    \n68  -2.54e-02 -0.094179 -1.79e-01 0.985 1.58e-02 0.01257    \n70  -5.22e-02  0.029655 -5.46e-02 1.028 1.50e-03 0.01289    \n75   8.46e-02 -0.018178  1.12e-01 1.003 6.22e-03 0.00934    \n77   5.23e-02 -0.032886  5.35e-02 1.030 1.44e-03 0.01463    \n79  -1.18e-01  0.049841 -1.34e-01 0.998 8.97e-03 0.01054    \n80  -1.57e-01  0.111283 -1.58e-01 1.012 1.24e-02 0.01815    \n81  -7.43e-04  0.002142  2.56e-03 1.050 3.31e-06 0.03019    \n82   1.15e-02 -0.052365 -6.88e-02 1.037 2.39e-03 0.02158    \n84   2.43e-03 -0.001763  2.44e-03 1.039 2.99e-06 0.01910    \n85   6.81e-02 -0.042009  7.00e-02 1.027 2.47e-03 0.01421    \n86  -1.15e-02  0.033553  4.02e-02 1.049 8.16e-04 0.02992    \n87  -1.07e-01 -0.042074 -2.21e-01 0.937 2.35e-02 0.00943   *\n88   8.25e-02 -0.040203  9.00e-02 1.017 4.06e-03 0.01136    \n89   4.05e-03 -0.002945  4.06e-03 1.039 8.30e-06 0.01923    \n91   7.80e-02 -0.232423 -2.80e-01 1.000 3.87e-02 0.02913    \n92  -2.90e-02 -0.024579 -7.87e-02 1.018 3.11e-03 0.01007    \n93  -8.00e-02  0.052025 -8.13e-02 1.027 3.32e-03 0.01540    \n97   1.22e-02  0.007756  2.94e-02 1.027 4.37e-04 0.00977    \n101  4.35e-02  0.013714  8.54e-02 1.014 3.65e-03 0.00933    \n103  3.26e-02 -0.024281  3.26e-02 1.039 5.37e-04 0.02037    \n104  1.59e-01 -0.118003  1.59e-01 1.016 1.26e-02 0.02023    \n105  2.22e-02  0.001854  3.69e-02 1.025 6.85e-04 0.00911    \n107  2.03e-02 -0.014865  2.04e-02 1.039 2.10e-04 0.01943    \n111 -5.39e-02  0.015849 -6.70e-02 1.020 2.25e-03 0.00963    \n114  1.97e-02 -0.011571  2.05e-02 1.032 2.12e-04 0.01335    \n115  3.18e-02 -0.010734  3.83e-02 1.026 7.39e-04 0.00987    \n116  4.49e-02 -0.026687  4.66e-02 1.030 1.09e-03 0.01354    \n117  1.36e-03 -0.000908  1.38e-03 1.035 9.60e-07 0.01604    \n118  8.97e-03  0.000233  1.43e-02 1.028 1.03e-04 0.00909    \n122 -4.47e-02  0.108235  1.24e-01 1.052 7.70e-03 0.03875    \n124 -5.86e-02  0.288122  3.84e-01 0.918 6.98e-02 0.02084   *\n126  1.24e-01 -0.093081  1.24e-01 1.026 7.73e-03 0.02076    \n127 -4.31e-02  0.030073 -4.33e-02 1.035 9.45e-04 0.01756    \n128 -1.32e-02  0.027227  2.98e-02 1.078 4.47e-04 0.05559   *\n132 -2.04e-02  0.013686 -2.06e-02 1.035 2.14e-04 0.01628    \n136  1.21e-02 -0.005783  1.33e-02 1.030 8.90e-05 0.01122    \n137  6.27e-02 -0.040580  6.38e-02 1.029 2.05e-03 0.01526    \n138  6.35e-02  0.015654  1.19e-01 1.000 7.02e-03 0.00925    \n139  1.33e-02  0.036739  7.44e-02 1.022 2.78e-03 0.01202    \n142  6.58e-02  0.051678  1.72e-01 0.975 1.46e-02 0.00999    \n143  9.18e-02 -0.051045  9.66e-02 1.018 4.68e-03 0.01261    \n144 -1.05e-01  0.017975 -1.43e-01 0.987 1.01e-02 0.00924    \n151 -1.68e-03 -0.000181 -2.85e-03 1.028 4.09e-06 0.00913    \n152  1.82e-01 -0.130145  1.83e-01 1.004 1.66e-02 0.01838    \n153  1.53e-02 -0.005150  1.85e-02 1.028 1.72e-04 0.00986    \n156  1.24e-02 -0.024756 -2.68e-02 1.085 3.63e-04 0.06108   *\n157 -1.62e-02 -0.018856 -5.14e-02 1.025 1.33e-03 0.01050    \n158 -2.32e-03  0.001476 -2.36e-03 1.034 2.82e-06 0.01490    \n159  5.01e-03 -0.047260 -6.79e-02 1.032 2.32e-03 0.01763    \n162 -6.86e-02  0.050899 -6.87e-02 1.035 2.37e-03 0.02018    \n163  4.94e-04 -0.013027 -1.97e-02 1.035 1.97e-04 0.01611    \n168 -8.21e-02  0.188530  2.12e-01 1.045 2.25e-02 0.04296    \n169 -5.23e-02  0.121760  1.38e-01 1.055 9.52e-03 0.04179    \n170 -1.90e-01  0.050467 -2.41e-01 0.922 2.77e-02 0.00951   *\n171 -7.74e-02  0.054745 -7.77e-02 1.031 3.04e-03 0.01803    \n172 -6.00e-02  0.003478 -8.95e-02 1.012 4.01e-03 0.00910    \n176  3.65e-02  0.071512  1.59e-01 0.989 1.26e-02 0.01138    \n177  2.67e-02 -0.011426  3.02e-02 1.028 4.59e-04 0.01061    \n179 -1.83e-01  0.104072 -1.91e-01 0.980 1.80e-02 0.01292    \n181 -1.02e-02  0.007416 -1.02e-02 1.039 5.27e-05 0.01919    \n182 -9.63e-02  0.054330 -1.01e-01 1.017 5.11e-03 0.01279    \n183  5.95e-02 -0.026691  6.65e-02 1.022 2.22e-03 0.01084    \n184 -1.59e-02  0.009246 -1.66e-02 1.032 1.39e-04 0.01317    \n185 -2.22e-03  0.005559  6.41e-03 1.058 2.07e-05 0.03666   *\n186  9.89e-02 -0.073192  9.90e-02 1.030 4.92e-03 0.02005    \n187  2.32e-01 -0.447094 -4.80e-01 1.034 1.13e-01 0.06919   *\n188  1.52e-01 -0.110254  1.53e-01 1.016 1.16e-02 0.01901    \n189  1.07e-01  0.052107  2.35e-01 0.927 2.65e-02 0.00956   *\n190 -1.92e-01  0.087686 -2.13e-01 0.956 2.20e-02 0.01095    \n191 -1.54e-01 -0.005725 -2.47e-01 0.911 2.90e-02 0.00910   *\n193 -1.57e-01  0.100145 -1.60e-01 1.003 1.27e-02 0.01500    \n194  1.70e-01 -0.126161  1.71e-01 1.013 1.45e-02 0.02007    \n\n\n\nGloval Validation of Linear Models Assumptions (paquete gvlma).\n\n\np_load(gvlma)\ngvlma::gvlma(reg.lineal)\n\n\nCall:\nlm(formula = cpi ~ gdp, data = datos_reg)\n\nCoefficients:\n(Intercept)          gdp  \n  24.237839     0.002163  \n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma::gvlma(x = reg.lineal) \n\n                    Value p-value                Decision\nGlobal Stat        5.2691 0.26078 Assumptions acceptable.\nSkewness           1.2784 0.25819 Assumptions acceptable.\nKurtosis           0.1015 0.75004 Assumptions acceptable.\nLink Function      0.4845 0.48641 Assumptions acceptable.\nHeteroscedasticity 3.4047 0.06501 Assumptions acceptable.\n\n\nConcretamente:\n\nGlobal Stat mide si relación entre las VIs y la VD es realmente lineal. El rechazo de la Ho indica que la relación no es lineal.\nSkewness mide si la distribución está sesgada y necesita una transformación para cumplir con el supuesto de normalidad. El rechazo de la Ho indica que los datos deberían ser transformados.\nKurtosis mide si la distribución es leptocúrtica o platicúrtica. El rechazo de la Ho indica que los datos deberían ser transformados.\nLink Function indica si la variable dependiente es realmente continua o es categórica. El rechazo de la Ho indica que sería conveniente usar un modelo alternativo de regresión, como el logístico o la regresión binomial.\nHeteroscedasticity mide el supuesto de homocedasticidad. El rechazo de la Ho indica que los residuos son heterocedásticos, y que el modelo precide unos rangos de la variable dependiente mejor que otros.\n\nEn la práctica, lo importante es mirar los siguientes supuetos: multicolinealidad (sobre todo esta, porque se puede ver a simple vista si sabes del tema) y homocedasticidad.\n\n\n\nEsta librería cuenta con numerosas opciones para modificar la tabla con los resultados (?stargazer)\n\np_load(stargazer)\nstargazer(reg.lineal,\n          type=\"text\",\n          dep.var.labels=c(\"Corruption Perception Index\"),\n          covariate.labels=c(\"GDP\",\"cte\"))\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                    Corruption Perception Index\n-----------------------------------------------\nGDP                          0.002***          \n                             (0.0001)          \n                                               \ncte                          24.238***         \n                              (1.521)          \n                                               \n-----------------------------------------------\nObservations                    110            \nR2                             0.749           \nAdjusted R2                    0.747           \nResidual Std. Error      10.225 (df = 108)     \nF Statistic          322.340*** (df = 1; 108)  \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Lineal simple"
    ]
  },
  {
    "objectID": "analisis/reg-lineal.html#teoría",
    "href": "analisis/reg-lineal.html#teoría",
    "title": "Lineal simple",
    "section": "Teoría",
    "text": "Teoría\n\nObjetivos:\n\nEstimar/predecir los valores que adoptará la variable dependiente (VD) a partir de valores conocidos del conjunto de variables independientes (VIs).\nCuantificar la relación de dependencia. Es decir, determinar qué proporción de varianza de la VD queda explicada por la suma de VIs.\nDeterminar el grado de confianza con que se puede afirmar que la relación observada en los datos muestras se da en la población.\n\n\n\nRegresión lineal simple\nCuando hacemos una regresión lineal modelamos una variable continua y como una función matemática de una o más variables xi, de manera que podamos usar ese modelo de regresión para predecir y cuando solo conozcamos xi. Hablamos de regresión simple cuando sólo están involucradas dos variables. En este caso, la ecuación de regresión se puede generalizar de la siguiente manera:\n\nFórmula matemática:\n\n\\[y = \\beta_1 + \\beta_2 x\\]\n\nFórmula regresiva:\n\n\\[\\hat{y} = \\hat{\\beta}_1 + \\hat{\\beta}_2 + u\\] donde β1 es la ordenada en el origen (o lo que es lo mismo, el valor de y cuando xi = 0) y β2 es la pendiente de la recta. En conjunto, se denominan coeficientes de regresión. El término u es el término de error, es decir, la parte de variable dependiente que el modelo de regresión no puede explicar. Gráficamente:\n\n\n\n\nIntervalos de confianza\n\n\n\n\n\nMínimos Cuadrados Ordinarios (MCO)\nMediante la regresión lineal de una variable y sobre una variable x, buscamos una función que sea una aproximación de una nube de puntos (xi, yi). Por una nube de puntos, sin embargo, pasan infinitas rectas. Para conocer cuál es la más adecuada, se emplea el método de MCO (OLS en inglés) para estimar los parámetros del modelo (βi).El método de los mínimos cuadrados se utiliza para calcular la recta de regresión lineal que minimiza los residuos, esto es, las diferencias entre los valores reales observados (yi) y los valores estimados por la recta (i).\n\n\nBondad de ajuste del modelo\nEl método de mínimos cuadrados selecciona la línea que más se ajusta a nuestras observaciones. Sin embargo, que esa recta sea la mejor, no quiere decir que sea necesariamente buena. Para determinar la bondad de ajuste de nuestro modelo vamos a utilizar el Coeficiente de Determinación R2.\nEl coeficiente de determinación explica cuánta varianza de la variable dependiente podemos explicar con nuestro modelo. Su valor puede oscilar entre 0 y 1. Cuanto mayor sea su valor, más preciso será el modelo de regresión. A menudo se interpreta como un porcentaje.\n\n\nSupuestos de la regresión\nPara ver si un modelo de regresión lineal ajustado es valido, debemos comprobar que se cumplen estas tres condiciones sobre los residuos:\n\nIndependencia: los residuos deben ser independientes entre sí\nHomocedasticidad: para cada valor de la variable x, la varianza de los residuos ei debe ser la misma (es decir, que el ajuste es igual de preciso independientemente de los valores que tome x).\nNormalidad: para cada valor de la variable independiente x, los residuos ei se distribuyen normalmente con media 0.\n\nAdemás:\n\nLa relación entre las variables x e y es lineal.\nAusencia de multicolinealidad (dos de las variables independientes están muy correlacionadas, una explica la otra).",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Lineal simple"
    ]
  },
  {
    "objectID": "analisis/descriptivo.html",
    "href": "analisis/descriptivo.html",
    "title": "Análisis descriptivo",
    "section": "",
    "text": "Lista con los estadísticos descriptivos básicos: summary()\n\nsummary(datos$edad)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   40.00   52.00   51.48   64.00   98.00 \n\n\nTambién se puede obtener un único estadístico de interés: min(), max(), median(), mean(), sd()",
    "crumbs": [
      "Análisis de datos",
      "Análisis descriptivo"
    ]
  },
  {
    "objectID": "analisis/descriptivo.html#estadísticos-básicos",
    "href": "analisis/descriptivo.html#estadísticos-básicos",
    "title": "Análisis descriptivo",
    "section": "",
    "text": "Lista con los estadísticos descriptivos básicos: summary()\n\nsummary(datos$edad)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   40.00   52.00   51.48   64.00   98.00 \n\n\nTambién se puede obtener un único estadístico de interés: min(), max(), median(), mean(), sd()",
    "crumbs": [
      "Análisis de datos",
      "Análisis descriptivo"
    ]
  },
  {
    "objectID": "analisis/descriptivo.html#tablas-de-frecuencias",
    "href": "analisis/descriptivo.html#tablas-de-frecuencias",
    "title": "Análisis descriptivo",
    "section": "2. Tablas de frecuencias",
    "text": "2. Tablas de frecuencias\nCon el comando table:\ntable(datos$variable)\n\nEj.:\n\n\ntable(datos$estudios)\n\n\nsin_estudios     primaria    fp basica  secundaria2     fp medio   superiores \n         496         1425         3768         4226         5859        13266 \n\n\nSi queremos ver también los valores perdidos de la variable, se añade al comando original la opción useNA = \"ifany\" (para que muestre los NA solo cuando existan) o useNA = \"always\" (si queremos que aparezca el número de NA incluso si este es 0):\n\ntable(datos$estudios, useNA = \"ifany\")\n\n\nsin_estudios     primaria    fp basica  secundaria2     fp medio   superiores \n         496         1425         3768         4226         5859        13266 \n        &lt;NA&gt; \n         161 \n\n\nCon el comando count:\ndatos %&gt;% count(variable)\n\nEj.:\n\n\ndatos %&gt;% count(estudios)\n\n# A tibble: 7 × 2\n  estudios         n\n  &lt;fct&gt;        &lt;int&gt;\n1 sin_estudios   496\n2 primaria      1425\n3 fp basica     3768\n4 secundaria2   4226\n5 fp medio      5859\n6 superiores   13266\n7 &lt;NA&gt;           161\n\n\nLa explicación de cómo hacer tablas de frecuencias bivariadas, así como su interpretación, está en el apartado de análisis bivariado",
    "crumbs": [
      "Análisis de datos",
      "Análisis descriptivo"
    ]
  },
  {
    "objectID": "analisis/correlacion.html",
    "href": "analisis/correlacion.html",
    "title": "Análisis de correlación",
    "section": "",
    "text": "Los análisis de correlación buscan averiguar si existe relación entre dos variables continuas.\n\n\ncov(datos$var1, datos$var2)\nEj. Se quiere comprobar la relación entre en índice de corrupción de un país (cpi, donde 0=más corrupto; 10=menos corrupto) y el índice de desarrollo humano (hdi, donde 0=más bajo; 1=más alto).\n\ncov(data$cpi, data$hdi)\n\n[1] 0.2435116\n\n\n\n\n\nLa función para calcular la correlación es cor() (funciona igual que el comando cov). Sin embargo, para poder interpretar más adecuadamente los resultados de la correlación conviene realizar un test para comprobar si dicha correlación es estadísticamente significativa. Las hipótesis de este test son:\n\nH0= la correlación es igual a 0, así que no hay relación\nH1= la correlación es significativamente distinta de 0\n\ncor.test(datos$var1, datos$var2)\nEj.:\n\ncor(data$cpi, data$hdi) # devuelve el valor de la correlación\n\n[1] 0.7238193\n\ncor.test(data$cpi, data$hdi) # hace un test\n\n\n    Pearson's product-moment correlation\n\ndata:  data$cpi and data$hdi\nt = 13.186, df = 158, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6406049 0.7902298\nsample estimates:\n      cor \n0.7238193 \n\n\nLos resultados muestran que la correlación entre ambas variables tiene un valor de 0,72. El test arroja tres resultados:\n\nt=13,186 –&gt; t&gt;3,26\np&lt;2.2e-16 –&gt; p&lt;0,001\nIC= [0.6406049, 0.7902298]\n\nBasándonos en estos resultados, podemos rechazar la hipótesis nula y afirmar que la correlación es significativamente distinta de cero para un nivel de confianza del 99,9%\n\n\n\n\nCorrelación entre todas las variables del dataset. Es fundamental que sean TODAS numéricas.\n\n\ncor(Data)\n\n            mpg        cyl       disp         hp        drat         wt\nmpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594\ncyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958\ndisp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799\nhp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479\ndrat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406\nwt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000\nqsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159\nvs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157\nam    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953\ngear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870\ncarb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059\n            qsec         vs          am       gear        carb\nmpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507\ncyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829\ndisp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686\nhp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247\ndrat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980\nwt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594\nqsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923\nvs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714\nam   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435\ngear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284\ncarb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000\n\n\n\nSi solo se quiere la relación entre varias variables concretas, se puede hacer de forma manual del siguiente modo:\n\n\nx &lt;- Data[c(1:3, 5)]\ny &lt;- Data[6:8]\ncor(x, y)\n\n             wt        qsec         vs\nmpg  -0.8676594  0.41868403  0.6640389\ncyl   0.7824958 -0.59124207 -0.8108118\ndisp  0.8879799 -0.43369788 -0.7104159\ndrat -0.7124406  0.09120476  0.4402785\n\n\n\n\n\nAdemás de usar funciones de cálculo, suele ser de gran ayuda visualizar las correlaciones entre variables gráficamente.\n\nNube de puntos (dos variables):\n\n\nplot(data$cpi, data$hdi, #Los datos que se van a usar para hacer el gráfico\n     main = \"CPI/HDI\", #El título del gráfico\n     xlab = \"Corruption perception index\", #El texto del eje X\n     ylab = \"Human development index\", #El texto del eje Y\n     pch = 18) #Establece la forma de los puntos (triángulos, círculos, x...)\n\n\n\n\n\n\n\n\n\nCorrelaciones para más de dos variables a la vez:\n\nlibrary(corrgram)\ncorrgram(datos)\nEj.:\n\ncorrgram(Data)\n\n\n\n\n\n\n\n\nEl comando cuenta con numerosas argumentos extra para modificar y mejorar la visualización del gráfico final (ver ?corrgram). P. ej.:\n\ncorrgram(Data, order=TRUE, lower.panel=NULL,\n         upper.panel=panel.pie, text.panel=panel.txt,\n         main=\"Car Milage Data in PC2/PC1 Order\")",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Análisis de correlación"
    ]
  },
  {
    "objectID": "analisis/correlacion.html#en-r",
    "href": "analisis/correlacion.html#en-r",
    "title": "Análisis de correlación",
    "section": "",
    "text": "Los análisis de correlación buscan averiguar si existe relación entre dos variables continuas.\n\n\ncov(datos$var1, datos$var2)\nEj. Se quiere comprobar la relación entre en índice de corrupción de un país (cpi, donde 0=más corrupto; 10=menos corrupto) y el índice de desarrollo humano (hdi, donde 0=más bajo; 1=más alto).\n\ncov(data$cpi, data$hdi)\n\n[1] 0.2435116\n\n\n\n\n\nLa función para calcular la correlación es cor() (funciona igual que el comando cov). Sin embargo, para poder interpretar más adecuadamente los resultados de la correlación conviene realizar un test para comprobar si dicha correlación es estadísticamente significativa. Las hipótesis de este test son:\n\nH0= la correlación es igual a 0, así que no hay relación\nH1= la correlación es significativamente distinta de 0\n\ncor.test(datos$var1, datos$var2)\nEj.:\n\ncor(data$cpi, data$hdi) # devuelve el valor de la correlación\n\n[1] 0.7238193\n\ncor.test(data$cpi, data$hdi) # hace un test\n\n\n    Pearson's product-moment correlation\n\ndata:  data$cpi and data$hdi\nt = 13.186, df = 158, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6406049 0.7902298\nsample estimates:\n      cor \n0.7238193 \n\n\nLos resultados muestran que la correlación entre ambas variables tiene un valor de 0,72. El test arroja tres resultados:\n\nt=13,186 –&gt; t&gt;3,26\np&lt;2.2e-16 –&gt; p&lt;0,001\nIC= [0.6406049, 0.7902298]\n\nBasándonos en estos resultados, podemos rechazar la hipótesis nula y afirmar que la correlación es significativamente distinta de cero para un nivel de confianza del 99,9%\n\n\n\n\nCorrelación entre todas las variables del dataset. Es fundamental que sean TODAS numéricas.\n\n\ncor(Data)\n\n            mpg        cyl       disp         hp        drat         wt\nmpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.68117191 -0.8676594\ncyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958\ndisp -0.8475514  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799\nhp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479\ndrat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406\nwt   -0.8676594  0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000\nqsec  0.4186840 -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159\nvs    0.6640389 -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157\nam    0.5998324 -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953\ngear  0.4802848 -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870\ncarb -0.5509251  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059\n            qsec         vs          am       gear        carb\nmpg   0.41868403  0.6640389  0.59983243  0.4802848 -0.55092507\ncyl  -0.59124207 -0.8108118 -0.52260705 -0.4926866  0.52698829\ndisp -0.43369788 -0.7104159 -0.59122704 -0.5555692  0.39497686\nhp   -0.70822339 -0.7230967 -0.24320426 -0.1257043  0.74981247\ndrat  0.09120476  0.4402785  0.71271113  0.6996101 -0.09078980\nwt   -0.17471588 -0.5549157 -0.69249526 -0.5832870  0.42760594\nqsec  1.00000000  0.7445354 -0.22986086 -0.2126822 -0.65624923\nvs    0.74453544  1.0000000  0.16834512  0.2060233 -0.56960714\nam   -0.22986086  0.1683451  1.00000000  0.7940588  0.05753435\ngear -0.21268223  0.2060233  0.79405876  1.0000000  0.27407284\ncarb -0.65624923 -0.5696071  0.05753435  0.2740728  1.00000000\n\n\n\nSi solo se quiere la relación entre varias variables concretas, se puede hacer de forma manual del siguiente modo:\n\n\nx &lt;- Data[c(1:3, 5)]\ny &lt;- Data[6:8]\ncor(x, y)\n\n             wt        qsec         vs\nmpg  -0.8676594  0.41868403  0.6640389\ncyl   0.7824958 -0.59124207 -0.8108118\ndisp  0.8879799 -0.43369788 -0.7104159\ndrat -0.7124406  0.09120476  0.4402785\n\n\n\n\n\nAdemás de usar funciones de cálculo, suele ser de gran ayuda visualizar las correlaciones entre variables gráficamente.\n\nNube de puntos (dos variables):\n\n\nplot(data$cpi, data$hdi, #Los datos que se van a usar para hacer el gráfico\n     main = \"CPI/HDI\", #El título del gráfico\n     xlab = \"Corruption perception index\", #El texto del eje X\n     ylab = \"Human development index\", #El texto del eje Y\n     pch = 18) #Establece la forma de los puntos (triángulos, círculos, x...)\n\n\n\n\n\n\n\n\n\nCorrelaciones para más de dos variables a la vez:\n\nlibrary(corrgram)\ncorrgram(datos)\nEj.:\n\ncorrgram(Data)\n\n\n\n\n\n\n\n\nEl comando cuenta con numerosas argumentos extra para modificar y mejorar la visualización del gráfico final (ver ?corrgram). P. ej.:\n\ncorrgram(Data, order=TRUE, lower.panel=NULL,\n         upper.panel=panel.pie, text.panel=panel.txt,\n         main=\"Car Milage Data in PC2/PC1 Order\")",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Análisis de correlación"
    ]
  },
  {
    "objectID": "analisis/correlacion.html#teoría",
    "href": "analisis/correlacion.html#teoría",
    "title": "Análisis de correlación",
    "section": "2. Teoría",
    "text": "2. Teoría\nSi queremos analizar la dependencia entre dos variables continuas XX e YY, no podemos estudiar sus distribuciones por separado, sino que debemos hacerlo de manera conjunta. Para ello, definimos una variable estadística bidimensional (X,Y)(X,Y), cuyos valores serán todos los pares formados por los valores de las variables XX e YY.\nLa representación gráfica más utilizada para examinar la relación entre dos variables numéricas es el diagrama de dispersión. Este consiste en representar, sobre un plano cartesiano, los puntos correspondientes a los pares de valores (\\(x_{i}\\), \\(y_{i}\\)) de la variable bidimensional. Estas nubes de puntos nos permiten visualizar el tipo de relación existente entre las variables (lineal, exponencial, positiva, negativa, etc.). Si además queremos cuantificar la intensidad de dicha relación, es necesario recurrir a medidas estadísticas, como la covarianza muestral o el coeficiente de correlación.\nLa covarianza de una variable bidimensional se obtiene promediando los productos de las desviaciones de cada valor con respecto a las medias de XX e YY. Una vez calculadas las medias, podemos calcular la covarianza siguiendo la siguiente fórmula:\n\\[cov_{x,y} = \\frac{\\sum\\limits_{i=1}^{n}{(x_i-\\overline{x}) \\cdot (y_i-\\overline{y})} }{n-1}\\]\nEl valor de la covarianza nos indica lo siguiente:\n\nSi cov&gt;0, relación lineal creciente entre las variables\nSi cov&lt;0, relación lineal decreciente entre las variables\nSi cov=0, no existe relación lineal entre las variables\n\nEl problema de esta medida es que depende de las unidades. Imaginemos que las unidades de la variable x son cm y las de la variable y son gr. En este caso, las unidades de la covarianza serán cm × gr, y si cambiamos la escala de las variables, la covarianza también cambiará. Esto hace que el valor de la covarianza sea difícil de interpretar. (la variazna es la distancia de los puntos hacia los ejes. La covarianza es la distancia de los puntos entre sí)\nPara evitar este problema, es recomendable utilizar una medida normalizada, como el coeficiente de correlación de Pearson, que toma valores entre -1 y 1, donde:\n\nρ = 1 indica una relación lineal perfecta y positiva\nρ = -1 indica una relación lineal perfecta y negativa\nρ = 0 indica ausencia de relación entre las variables\n\n\\[\\rho = \\frac{\\text{cov}(X,Y)}{\\sigma_x \\sigma_y}\\]\nCorrelación no implica causalidad\nLa correlación entre dos variables v1 y v2 puede deberse a:\n\nRelación causal: V1 es la causa, V2 el efecto (o viceversa)\nAzar\nVariable interviniente (confounding factor):\n\nRelaciones espúreas: es una correlación aparente entre dos variables que en realidad es causada por la influencia de una tercera variable, conocida como variable de confusión. Aunque las dos variables parecen estar relacionadas, su relación no es causal.\nParadoja de Simpson: ocurre cuando una tendencia observada en varios grupos desaparece o se invierte al combinar los datos de esos grupos. Esto sucede debido a la influencia de una variable oculta o de confusión que afecta la interpretación de la relación entre las variables. Aquí tenéis un ejemplo muy conocido.",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Análisis de correlación"
    ]
  },
  {
    "objectID": "analisis/predicciones-lineal.html",
    "href": "analisis/predicciones-lineal.html",
    "title": "Predicciones",
    "section": "",
    "text": "Hay ocasiones en las que queremos determinar la precisión de un modelo a la hora de predecir nuevas observaciones (que no se han utilizado para construir el modelo). En otras palabras, queremos estimar el error de predicción de nuestro modelo. Con validación cruzada nos referimos a un conjunto de métodos para medir el rendimiento de un modelo dado en nuevos conjuntos de datos de prueba.\nLa idea básica detrás de las técnicas de validación cruzada es la siguiente:\n\nConstruir el modelo en un conjunto de datos de entrenamiento (train set)\nAplicar el modelo en un nuevo conjunto de datos de prueba para hacer predicciones (test set)\nCalcular los errores de predicción. Si el modelo funciona bien en el conjunto de datos de prueba (test set), entonces es bueno.\n\nÉxisten diferentes métricas para cuantificar la calidad general de los modelos de regresión. Hasta ahora nos hemos centrado en el R2, pero hay otros como:\n\nEl error cuadrático medio (RMSE), que mide el error predictivo promedio. Es decir, la diferencia promedio entre los valores observados y los valores predichos por el modelo. Cuanto más bajo sea el RMSE, mejor será el modelo.\nEl error absoluto medio (MAE), una alternativa a RMSE que es menos sensible a los valores atípicos. Corresponde a la diferencia promedio, en términos absolutos, entre los resultados observados y predichos. Cuanto más bajo sea el MAE, mejor será el modelo.\n\nExisten diferentes métodos de validación cruzada para evaluar el rendimiento del modelo. A continuación, vamos a ver algunos de los más sencillos y frecuentes."
  },
  {
    "objectID": "analisis/predicciones-lineal.html#validación-del-modelo-de-regresión",
    "href": "analisis/predicciones-lineal.html#validación-del-modelo-de-regresión",
    "title": "Predicciones",
    "section": "",
    "text": "Hay ocasiones en las que queremos determinar la precisión de un modelo a la hora de predecir nuevas observaciones (que no se han utilizado para construir el modelo). En otras palabras, queremos estimar el error de predicción de nuestro modelo. Con validación cruzada nos referimos a un conjunto de métodos para medir el rendimiento de un modelo dado en nuevos conjuntos de datos de prueba.\nLa idea básica detrás de las técnicas de validación cruzada es la siguiente:\n\nConstruir el modelo en un conjunto de datos de entrenamiento (train set)\nAplicar el modelo en un nuevo conjunto de datos de prueba para hacer predicciones (test set)\nCalcular los errores de predicción. Si el modelo funciona bien en el conjunto de datos de prueba (test set), entonces es bueno.\n\nÉxisten diferentes métricas para cuantificar la calidad general de los modelos de regresión. Hasta ahora nos hemos centrado en el R2, pero hay otros como:\n\nEl error cuadrático medio (RMSE), que mide el error predictivo promedio. Es decir, la diferencia promedio entre los valores observados y los valores predichos por el modelo. Cuanto más bajo sea el RMSE, mejor será el modelo.\nEl error absoluto medio (MAE), una alternativa a RMSE que es menos sensible a los valores atípicos. Corresponde a la diferencia promedio, en términos absolutos, entre los resultados observados y predichos. Cuanto más bajo sea el MAE, mejor será el modelo.\n\nExisten diferentes métodos de validación cruzada para evaluar el rendimiento del modelo. A continuación, vamos a ver algunos de los más sencillos y frecuentes."
  },
  {
    "objectID": "analisis/predicciones-lineal.html#el-conjunto-de-validación",
    "href": "analisis/predicciones-lineal.html#el-conjunto-de-validación",
    "title": "Predicciones",
    "section": "El conjunto de validación",
    "text": "El conjunto de validación\nÉl método más sencillo consiste en dividir aleatoriamente los datos en dos conjuntos: un conjunto se usa para entrenar el modelo (train set) y el otro para probalo (test set).\nVamos a ver un ejemplo. Para ello, abrimos el dataset QoG2017 (Quality of Government, 2017) que ya conocemos. Como en ejemplos anteriores, renombramos nuestras 2 variables de interés:\n\nti_cpi (Transparency International Corruption Perception Index) = cpi\nmad_gdppc (GDP per capita) = gdp\n\n\ndim(datos_reg)\n\n[1] 194 362\n\ndatos_reg &lt;- datos_reg %&gt;%\n  mutate(cpi = ti_cpi,\n         gdp = mad_gdppc)\n\nsummary(datos_reg$cpi)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   8.00   28.00   37.00   42.12   54.00   91.00      14 \n\nsummary(datos_reg$gdp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n    260    3178    7331    9687   13724   30491      84 \n\n\nPara que todo funcione bien es necesario que la base de datos no contenga NAs. Para ello, procedemos de la siguiente manera:\n\nCreamos un nuevo dataset que incluya únicamente las variables que nos interesan\nEliminamos los casos perdidos usando la función na.omit() o na.exclude()\n\n\nmyvars &lt;- c(\"cpi\", \"gdp\")          # creo un vector con las variables de interés\nqog2017.red&lt;-datos_reg[myvars]       # creo un nuevo dataframe con las variables de interés\nqog2017.red&lt;- na.omit(qog2017.red) # elimino los casos perdidos del nuevo dataframe\nsummary(qog2017.red)               # compruebo que el nuevo dataset contiene únicamente las variables de interés\n\n      cpi             gdp       \n Min.   :16.00   Min.   :  260  \n 1st Qu.:29.00   1st Qu.: 3178  \n Median :40.00   Median : 7331  \n Mean   :45.19   Mean   : 9687  \n 3rd Qu.:58.50   3rd Qu.:13724  \n Max.   :91.00   Max.   :30491  \n\ndim(qog2017.red)\n\n[1] 110   2\n\n\nUna vez tenemos el dataset preparado, pasamos a crear el conjunto de entrenamiento y test. Hay otras muchas maneras de hacerlo y aquí hemos elegido una sencilla, pero hay otras funciones disponibles en el paquete caret o caTools.\n\n# Establecemos la semilla para la reproducibilidad (puede ser cualquier número)\nset.seed(1)\n\n# Creamos un id para las filas\nqog2017.red &lt;- qog2017.red %&gt;%\n  rownames_to_column(var = \"row_id\")\n\n# Dividimos el dataset en 70% para entrenamiento y 30% para prueba\ntrain.data &lt;- qog2017.red %&gt;%\n  sample_frac(0.7) # selecciona aleatoriamente el 70% de las filas del dataset.\n\n# El test set son las filas que no están en el train set\ntest.data &lt;- qog2017.red %&gt;%\n  anti_join(train.data, by = \"row_id\") # se usa para obtener el 30% restante (las filas que no están en el set de entrenamiento), asegurando que no haya filas duplicadas.\n\nNota: set.seet()establece el número inicial que se usa para generar una secuencia de números aleatorios. De esta manera, nos aseguramos de que obtener el mismo resultado cada vez que se ejecuta el mismo proceso.\nA continuación, estimamos el modelo de regresión con los datos de entrenamiento (train.data):\n\nmodelo1 &lt;- lm(cpi ~ gdp, data=train.data)\nprint(modelo1)\n\n\nCall:\nlm(formula = cpi ~ gdp, data = train.data)\n\nCoefficients:\n(Intercept)          gdp  \n  25.283658     0.002097  \n\n\nUna vez hemos estimado el modelo en el conjunto de entrenamiento, pasamos a hacer la predicción. Es decir, usamos los parámetros obtenidos en el modelo1 para estimar yhat (valores predichos) en el conjunto de prueba (test.data):\n\n# Usamos el modelo para predecir los valores de CPI en test.data y guardamos el resultado en una nueva columna yhat1\ntest.data &lt;- test.data %&gt;%\n  mutate(yhat1 = predict(modelo1, newdata = test.data))\n\n# Visualizamos los primeros valores de la columna de predicciones\nhead(test.data$yhat1)\n\n       1        2        3        4        5        6 \n28.63831 43.81926 46.78745 35.61843 27.95946 46.70095 \n\n\nComo resultado, el dataset tiene ahora 4 columnas. El id, la variable dependiente (cpi), la variable independiente (gdp) y el valor predicho (yhat). Una vez tenemos estos tres valores, ya podemos calcular la calidad general del modelo de regresión.\n\nhead(test.data)\n\n# A tibble: 6 × 4\n  row_id   cpi    gdp yhat1\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 3         23  1600.  28.6\n2 4         28  8841.  43.8\n3 5         34 10256.  46.8\n4 8         48  4929.  35.6\n5 9         27  1276.  28.0\n6 10        36 10215.  46.7\n\n\nCalculamos el R2, el RMSE y el MAE del modelo 1:\n\nlibrary(caret)\ndata.frame(R2.m1 = R2(test.data$yhat1, test.data$cpi),\n           RMSE.m1 = RMSE(test.data$yhat1, test.data$cpi),\n           MAE.m1 = MAE(test.data$yhat1, test.data$cpi))\n\n      R2.m1  RMSE.m1   MAE.m1\n1 0.7182977 9.445556 6.936436\n\n\nRMSE y el MAE se miden en la misma escala que la variable dependiente. Para tener una medida más fácilmente interpretable, dividimos RMSE por el valor promedio de la variable dependiente. De esta manera obtendremos la tasa de error de predicción que varía entre 0 y 1. La predicción será mejor cuanto menor sea su valor:\n\nRMSE(test.data$yhat1, test.data$cpi)/mean(test.data$cpi)\n\n[1] 0.2359602\n\n\nEste método de validación cruzada es útil cuando tenemos una muestra suficientemente grande para particionar. Una desventaja es que construimos el modelo a partir de fracción del conjunto de datos, posiblemente omitiendo alguna información interesante sobre los datos, lo que nos puede conducir a un mayor sesgo. Por lo tanto, la tasa de error de la prueba puede ser muy variable, dependiendo de qué observaciones se incluyen en el conjunto de entrenamiento y qué observaciones se incluyen en el conjunto de validación."
  },
  {
    "objectID": "analisis/predicciones-lineal.html#método-leave-one-out-loocv",
    "href": "analisis/predicciones-lineal.html#método-leave-one-out-loocv",
    "title": "Predicciones",
    "section": "Método Leave-one-out (LOOCV)",
    "text": "Método Leave-one-out (LOOCV)\nLa validación cruzada dejando uno fuera (método leave-one-out) funciona de la siguiente manera:\n\nDejar un único caso fuera y construye el modelo con el resto del dataset (n-1)\nValida el modelo con dicho dato, y guarda el error de predicción asociado\nRepite el proceso tantas veces como casos (n) tenemos\nComputa el error de predicción total, que es el promedio de todos los errores estimados en cada paso\n\nPara cada uno de los casos de la muestra, hace una regresión con el resto del dataset, y testea esta regresión con el que se ha quedado apartado. Este proceso se repite con todos los casos, calculando el error de todas estas regresiones y la media de ellos. Con esta forma de realizar predicciones, todos los casos son usados tanto en la muestra de entrenamiento como en la de testeo. (No tiene por qué ser necesariamente un mejor modelo que el anterior)\nVamos a ver un ejemplo con nuestros datos:\n\ntrain.control &lt;- trainControl(method=\"LOOCV\") # Con la función trainControl definimos el tipo de método (loocv en este caso)\n# Entrenamos el modelo\nmodelo2 &lt;- train(cpi ~., data=qog2017.red, method=\"lm\", trControl=train.control) # ~. significa que utilice todas las varaibles del dataset, en lugar de tener que escribirlas todas una por una.\nprint(modelo2)\n\nLinear Regression \n\n110 samples\n  2 predictor\n\nNo pre-processing\nResampling: Leave-One-Out Cross-Validation \nSummary of sample sizes: 109, 109, 109, 109, 109, 109, ... \nResampling results:\n\n  RMSE      Rsquared     MAE     \n  24.71235  0.004517315  18.08182\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n\n\nLa función print() nos devuelve el resultado del modelo calculado con el método LOOCV. Como veis, nos devuelve el valor del RMSE, R2y MAE. Para facilitar la interpretación, volvemos a calcular la tasa de error de predicción. En primer lugar, tenemos que extraer el valor de RMSE de la lista de resultados del modelo (lo podéis consultar haciendo click sobre el modelo2):\n\nqog2017.red$RMSE.m2&lt;-modelo2$results$RMSE\nhead(qog2017.red)\n\n# A tibble: 6 × 4\n  row_id   cpi    gdp RMSE.m2\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 1         31  5375.    24.7\n2 2         36  3513.    24.7\n3 3         23  1600.    24.7\n4 4         28  8841.    24.7\n5 5         34 10256.    24.7\n6 6         81 25584.    24.7\n\n\nComos veis, el dataframe contiene ahora nueva columna RMSE.m2. Ya podemos dividir el RMSE por la media de la variable dependiente (cpi)\n\nmean(qog2017.red$RMSE.m2/mean(qog2017.red$cpi))\n\n[1] 0.5468433\n\n\nLa ventaja del método LOOCV es que usamos todos los puntos de datos para reducir el sesgo potencial. La desventaja es que el proceso se repite tantas veces como casos hay, lo que tiene un coste computacional importante si la muestra es muy grande."
  },
  {
    "objectID": "analisis/predicciones-lineal.html#k-fold-cross-validation",
    "href": "analisis/predicciones-lineal.html#k-fold-cross-validation",
    "title": "Predicciones",
    "section": "K-fold cross validation",
    "text": "K-fold cross validation\nEl método de validación cruzada de k-fold evalúa el rendimiento del modelo en diferentes subconjuntos de los datos de entrenamiento y luego calcula la tasa de error predictivo promedio. El proceso es el siguiente:\n\nDividir al azar el conjunto de datos en k-subconjuntos (k-folds)\nReservar un subconjunto y entrenar el modelo en todos los demás subconjuntos\nProbar el modelo en el subconjunto reservado y registrar el error de predicción\nRepetir este proceso hasta que cada uno de los k subconjuntos haya servido como conjunto de prueba.\nCalcular el promedio de los errores registrados. Esto se llama el error de validación cruzada que sirve como la métrica de rendimiento para el modelo.\n\nLa ventaja más obvia de este método, en comparación con LOOCV, es computacional. Una ventaja menos obvia, pero potencialmente más importante, es que a menudo proporciona estimaciones más precisas de la tasa de error de prueba que LOOCV (James et al., 2014).\nPregunta clave: ¿cómo elegir el valor correcto de k? No es difícil ver que un valor pequeño de k (p.ej., k=2) nos lleva a un enfoque parecido al del conjunto de validación que vimos en primer lugar. Por el contrario, valores altos de k (p.ej., k=m) nos lleva al enfoque de LOOCV. En general, usaremos valores intermedios (5, 10, incluso 20)\nVamos a hacer un ejemplo con k=10\n\n# Definimos el training control para 10 folders\nset.seed(123) \ntrain.control &lt;- trainControl(method=\"cv\", number=10)  # en este caso, usamos el método \"cv\"\n# Entrenamos el modelo\nmodelo3 &lt;- train(cpi ~., data=qog2017.red, method=\"lm\", trControl=train.control)\nprint(modelo3)\n\nLinear Regression \n\n110 samples\n  3 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 99, 98, 98, 100, 98, 101, ... \nResampling results:\n\n  RMSE      Rsquared  MAE     \n  24.82126  NaN       18.30197\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n\n\nComo en el ejemplo anterior, el modelo calculado a través de “cv” nos devuelve el RMSE, R2 y MAE. Al igual que hicimos arriba, extraemos el RMSE para calcular la tasa de error de predicción de la siguiente manera:\n\nqog2017.red$RMSE.m3&lt;-modelo3$results$RMSE         # extraemos RMSE del modelo3\nhead(qog2017.red)                                 # comprobamos que se ha añadido al data.frame\n\n# A tibble: 6 × 5\n  row_id   cpi    gdp RMSE.m2 RMSE.m3\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 1         31  5375.    24.7    24.8\n2 2         36  3513.    24.7    24.8\n3 3         23  1600.    24.7    24.8\n4 4         28  8841.    24.7    24.8\n5 5         34 10256.    24.7    24.8\n6 6         81 25584.    24.7    24.8\n\n\n\nmean(qog2017.red$RMSE.m3/mean(qog2017.red$cpi))   # calculamos la tasa del error de predicción\n\n[1] 0.5492534"
  },
  {
    "objectID": "analisis/reg-logistica.html",
    "href": "analisis/reg-logistica.html",
    "title": "Regresión logística",
    "section": "",
    "text": "La clasificación supervisada es una tarea muy frecuente en todas las áreas de análisis de datos. Existe un gran número de algoritmos desarrollados tanto por la estadística (regresión logística, análisis discriminante) como por la inteligencia artificial (redes neuronales, árboles de decisión, redes bayesianas) diseñados para realizar las tareas propias de la clasificación.\nVamos a centrarnos en el análisis de regresión logística, una técnica para el análisis de variables dependientes categóricas con dos categorías (dicotómicas) o más (polinómicas). Sirve para modelar la probabilidad de ocurrencia de un evento como función de otros factores, y responder preguntas como:\n\n¿Qué factores explican la victoria/derrota de un candidato en unas elecciones?\n¿Qué variables determinan que una persona vote?\n¿Qué factores incrementan/disminuyen el riesgo de caer en la pobreza?\n¿Cómo podemos explicar el abandono escolar?\netc\n\nEl análisis de regresión logística pertenece al grupo de Modelos Lineales Generalizados (GLM por sus siglas en inglés), y usa como función de enlace la función logit.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#análisis-de-clasificación",
    "href": "analisis/reg-logistica.html#análisis-de-clasificación",
    "title": "Regresión logística",
    "section": "",
    "text": "La clasificación supervisada es una tarea muy frecuente en todas las áreas de análisis de datos. Existe un gran número de algoritmos desarrollados tanto por la estadística (regresión logística, análisis discriminante) como por la inteligencia artificial (redes neuronales, árboles de decisión, redes bayesianas) diseñados para realizar las tareas propias de la clasificación.\nVamos a centrarnos en el análisis de regresión logística, una técnica para el análisis de variables dependientes categóricas con dos categorías (dicotómicas) o más (polinómicas). Sirve para modelar la probabilidad de ocurrencia de un evento como función de otros factores, y responder preguntas como:\n\n¿Qué factores explican la victoria/derrota de un candidato en unas elecciones?\n¿Qué variables determinan que una persona vote?\n¿Qué factores incrementan/disminuyen el riesgo de caer en la pobreza?\n¿Cómo podemos explicar el abandono escolar?\netc\n\nEl análisis de regresión logística pertenece al grupo de Modelos Lineales Generalizados (GLM por sus siglas en inglés), y usa como función de enlace la función logit.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#regresión-logística-vs-regresión-lineal",
    "href": "analisis/reg-logistica.html#regresión-logística-vs-regresión-lineal",
    "title": "Regresión logística",
    "section": "Regresión logística vs regresión lineal",
    "text": "Regresión logística vs regresión lineal\nEl modelo de regresión lineal no es válido cuando la variable respuesta no tiene una distribución normal. Por ejemplo: respuestas si/no, conteos, probabilidades, etc.\nAl igual que la regresión lineal, la regresión logística busca:\n\npredecir/explicar una VD a partir de una o mas VI,\nmedir el grado de relación de la VD con las VI\ncomprobar su significatividad\n\nA diferencia de la regresión lineal:\n\nlos coeficientes de regresión se estiman por el procedimiento de Máxima Verosimilitud, que busca maximizar la probabilidad de ocurrencia del evento que se analiza",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#supuestos-básicos",
    "href": "analisis/reg-logistica.html#supuestos-básicos",
    "title": "Regresión logística",
    "section": "Supuestos básicos",
    "text": "Supuestos básicos\nCompartidos con la Regresión Lineal:\n\nTamaño muestral elevado\nIntroducción de VIs relevantes\nVariables predictoras continuas o dicotómicas\nAusencia de colinealidad entre las VIs\nAditividad\n\nEspecíficos:\n\nNo-linealidad: La función de vinculación logit es no-lineal. Esto implica que el cambio en la VD producido por el incremento de una unidad en la VI depende del valor que tome la variable. Es menos importante en los extremos de las VI, y mas importante en los valores centrales.\n\n\n\n\n\n\n\nHeterocedasticidad: En regresión logística se asume heterocedasticidad (varianza de los residuos no constante). Es lo contrario que en la regresión lineal, ya que la representación de la regresión logística no es lineal, sino que se busca que debe existir varianza en los residuos no constante.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#la-ecuación-de-la-regresión-logística",
    "href": "analisis/reg-logistica.html#la-ecuación-de-la-regresión-logística",
    "title": "Regresión logística",
    "section": "La ecuación de la regresión logística",
    "text": "La ecuación de la regresión logística\nLa función de enlace logit, utilizada principalmente en modelos de regresión logística, es como hemos mencionado no lineal, ya que transforma una combinación lineal de predictores en probabilidades mediante la fórmula:\n\\[\n\\ln\\left(\\frac{p(x)}{1 - p(x)}\\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p\n\\]\nEn esta ecuación, la VD aparece en una forma que no es directamente interpretable (concretamente, el logaritmo neperiano de la razón de probabilidades). Haciendo transformaciones, podemos expresar la probabilidad de ocurrencia del suceso de la siguiente manera:\n\\[\np(x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p)}} = \\sigma\\left(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p\\right)\n\\]\ndonde:\n\\[\n\\sigma(x) = \\frac{e^x}{1 + e^x} = \\frac{1}{1 + e^{-x}}\n\\]",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#ejercicio-de-regresión-logística",
    "href": "analisis/reg-logistica.html#ejercicio-de-regresión-logística",
    "title": "Regresión logística",
    "section": "Ejercicio de regresión logística",
    "text": "Ejercicio de regresión logística\nVamos a hacer un sencillo ejercicio de regresión logística usando los datos del la encuesta preelectoral CIS 2023. En concreto, vamos a estimar la probabilidad de que un individuo i tenga intención de votar a un parido p en las elecciones generales de 2023. Dado que se trata de un ejercicio de clase, vamos a incluir unas pocas variables y no vamos a tomar en consideración los casos perdidos (indecisos, etc). En consecuencia, los resultados no sirven para predicción electoral, solo practicar.\nComo de costumbre, abrimos fichero “Limpieza de datos” en su versión más reciente.\nA partir de la variable intención de voto (´INTENCIONG`), vamos a crear nuestra variable dependiente de intención voto VOX (intovox).\n\n# Intención de voto\ntable(datos$INTENCIONG)\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   15   16   17 \n7200 7592 2652   36   21   86   89  250  170    3    3    7   12    8    1    9 \n  19   21   23   25  101  102  106  107  201  202  203  301  401  402  501  502 \n   3 2877    1    6   10   18    2    2    4   57    3    6    1    2   66   16 \n 601  801  802  803  804  808  809  814  901  902  903  904  905 1001 1101 1201 \n   7   37   37   10    1    4    1    1  296  230   17  108   15   75    1  281 \n1202 1301 1501 1502 1601 1602 1701 8993 8994 8995 8996 9977 9997 9998 9999 \n   2    3   30    8  233  302    1   27    7  106  376  226  700 4084  762 \n\n# Intención voto VOX\ndatos &lt;- datos %&gt;%\n  mutate(\n    intvox = case_when(\n      INTENCIONG == 3 ~ 1,            \n      INTENCIONG &gt;= 9977 ~ NA,  \n      TRUE ~ 0))\n\ntable(datos$intvox, useNA = \"ifany\")\n\n\n    0     1  &lt;NA&gt; \n20777  2652  5772 \n\n\nComo variables independientes, vamos a utilizar las variables “edad”, “hombre”, “estudios_universitarios”, “ecoesp”, “ideol” y “recuerdo19” que ya tenemos preparadas de clases anteriores. Una vez tenemos todas las variables preparadas, procedemos a crear el data.frame data con el conjunto de variables que vamos a incluir nuestros análisis y eliminamos los casos perdidos.\nQue existan tantos casos perdidos en la variable dependiente (5772) no importa en este caso al ser un ejemplo, pero a la hora de hacer un modelo de predicción real se deberían imputar todos estos valores para que el modelo sea más fiable.\n\ndatos_log &lt;- datos %&gt;%\n  dplyr::select(intvox, hombre, estudios_universitarios, edad, ecoesp, ideol, recuerdo19) %&gt;%\n  drop_na()\n\nsummary(datos_log)\n\n     intvox          hombre      estudios_universitarios      edad      \n Min.   :0.0000   Mujer : 9373   sin EU:10482            Min.   :21.00  \n 1st Qu.:0.0000   Hombre:10475   con EU: 9366            1st Qu.:41.00  \n Median :0.0000                                          Median :53.00  \n Mean   :0.1068                                          Mean   :52.78  \n 3rd Qu.:0.0000                                          3rd Qu.:65.00  \n Max.   :1.0000                                          Max.   :95.00  \n                                                                        \n      ecoesp          ideol             recuerdo19  \n negativa:12417   Min.   : 1.000   PSOE      :7104  \n positiva: 7431   1st Qu.: 3.000   PP        :4557  \n                  Median : 5.000   Otros     :2534  \n                  Mean   : 4.817   Podemos   :2292  \n                  3rd Qu.: 7.000   VOX       :1648  \n                  Max.   :10.000   Ciudadanos:1360  \n                                   (Other)   : 353",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#estimación-del-modelo",
    "href": "analisis/reg-logistica.html#estimación-del-modelo",
    "title": "Regresión logística",
    "section": "Estimación del modelo",
    "text": "Estimación del modelo\nYa podemos estimar la regresión logística. De las 4 variables dependientes que tenemos, vamos a empezamos por calcular la probabilidad de votar a VOX frente a otros partidos, en función de la ideología, recuerdo de voto en 2019, opinión sobre la economía en España y perfil socio-demográfico de la persona. Usamos la función glm() con link function binominal.\n\nlibrary(MASS)\nm.vox &lt;- glm(intvox ~ hombre + estudios_universitarios + edad + ecoesp + ideol + recuerdo19, data = datos_log, family = \"binomial\")\nsummary(m.vox)\n\n\nCall:\nglm(formula = intvox ~ hombre + estudios_universitarios + edad + \n    ecoesp + ideol + recuerdo19, family = \"binomial\", data = datos_log)\n\nCoefficients:\n                               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   -3.488087   0.164352 -21.223  &lt; 2e-16 ***\nhombreHombre                   0.758371   0.064308  11.793  &lt; 2e-16 ***\nestudios_universitarioscon EU -0.266082   0.063597  -4.184 2.87e-05 ***\nedad                          -0.027296   0.002093 -13.043  &lt; 2e-16 ***\necoesppositiva                -1.352050   0.109386 -12.360  &lt; 2e-16 ***\nideol                          0.290559   0.016197  17.939  &lt; 2e-16 ***\nrecuerdo19PP                   0.478263   0.107785   4.437 9.11e-06 ***\nrecuerdo19VOX                  3.378650   0.109928  30.735  &lt; 2e-16 ***\nrecuerdo19Podemos             -0.313977   0.206227  -1.522    0.128    \nrecuerdo19Ciudadanos           0.693385   0.127396   5.443 5.25e-08 ***\nrecuerdo19Más Madrid          -1.109060   1.011114  -1.097    0.273    \nrecuerdo19Otros               -0.266386   0.164990  -1.615    0.106    \nrecuerdo19En blanco           -0.123526   0.340733  -0.363    0.717    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 13484.3  on 19847  degrees of freedom\nResidual deviance:  7595.5  on 19835  degrees of freedom\nAIC: 7621.5\n\nNumber of Fisher Scoring iterations: 7",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#significatividad-de-las-variables",
    "href": "analisis/reg-logistica.html#significatividad-de-las-variables",
    "title": "Regresión logística",
    "section": "Significatividad de las variables",
    "text": "Significatividad de las variables\nAl igual que en la regresión lineal, contrastamos las siguientes hipótesis:\n\nH0:βi=0 -&gt; la VIi no tiene efecto sobre la VD\nHa:βi!=0 -&gt;la VIi sí tiene efecto sobre la VD\n\nComo ya sabemos, podemos rechazar la hipótesis nula siempre que:\n\np-valor&lt;0.05, NC:95%\np-valor&lt;0.01, NC:99%\np-valor&lt;0.001, NC:99.9%\n\nSi además queremos calcular los intervalos de confianza, podemos usar la función cofint()\n\nconfint(m.vox)\n\n                                    2.5 %      97.5 %\n(Intercept)                   -3.81281533 -3.16847185\nhombreHombre                   0.63278731  0.88491727\nestudios_universitarioscon EU -0.39093054 -0.14158952\nedad                          -0.03141038 -0.02320544\necoesppositiva                -1.57030106 -1.14124336\nideol                          0.25887651  0.32237807\nrecuerdo19PP                   0.26914384  0.69187062\nrecuerdo19VOX                  3.16575149  3.59683507\nrecuerdo19Podemos             -0.73570089  0.07550088\nrecuerdo19Ciudadanos           0.44317980  0.94295525\nrecuerdo19Más Madrid          -3.98404616  0.41077929\nrecuerdo19Otros               -0.59785450  0.05018137\nrecuerdo19En blanco           -0.85381772  0.49558218",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#interpretación-de-los-coeficientes",
    "href": "analisis/reg-logistica.html#interpretación-de-los-coeficientes",
    "title": "Regresión logística",
    "section": "Interpretación de los coeficientes",
    "text": "Interpretación de los coeficientes\nLos estimadores representan el logaritmo del cociente de probabilidades. Por ejemplo, ceteris paribus:\n\nIdeología: Para cada punto que aumenta la ideología, el log de la probabilidad de votar a VOX (versus votar otro partido) aumenta en 0.290559.\nVotó PP en 2019: el logaritmo de la probabilidad de votar a VOX en 2023 es 0.478263 mayor que entre los que en 2019 votaron al PP que entre los que votaron al PSOE (categoría de referencia).\n\nComo se puede observar, esta interpretación de los coeficientes es muy poco intuitiva. Este tipo de coeficiente es útil si lo que nos interesa es conocer la dirección del efecto (signo positivo o negativo) y el nivel de significación (p-valor). Si por el contrario estamos interesados en interpretar el valor coeficiente, tenemos dos alternativas mejores: expresar los coeficientes como odds ratio o calcular las probabilidades de ocurrencia del evento.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#odds-ratio",
    "href": "analisis/reg-logistica.html#odds-ratio",
    "title": "Regresión logística",
    "section": "Odds ratio",
    "text": "Odds ratio\nCon el odds ratio lo que hago es exponenciar el coeficiente, osea e exponencial de Beta: \\(e^{\\text{coef}}\\) y es la frecuencia de ocurrencia de un suceso sobre la frecuencia de su no ocurrencia:\n\nOdds ratio &gt;1: la variable tiene un efecto positivo sobre la probabilidad de ocurrencia del suceso.\n0 &gt; Odds ratio &lt;1: la variable tiene un efecto negativo sobre la probabilidad de ocurrencia del suceso.\nOdds ratio =1: la variable no tiene efecto sobre la probabilidad de ocurrencia del suceso.\n\nEn la tabla:\n\nOdds ratioideología=e0.290559=1.337. Para cada punto que nos movemos a la derecha en la escala de ideología, la probabilidad de votar a VOX (sobre votar a otro partido) aumenta en un factor de 1.337 (cuando el resto de variables permanecen constantes). O si se quiere expresar en porcentaje.\n\n(1,337 - 1)* 100 = 0,337 * 100 = 33,7%\n\nSale 1,33, el cual es el mismo valor del coeficiente solo que ahora lo calcula las betas elevadas a \\(e\\) para desahacer el logaritmo neperiano.\nOdds ratiovotó PP(2019)= e0.478263=1,61. La probabilidad de votar a VOX (sobre votar a otro partido) es 1,61 veces mayor entre las personas que en 2019 votaron al PP que entre las personas que en 2019 votaron al PSOE (cuando el resto de variables permanecen constantes). O si se quiere expresar en porcentaje.\n\n(1,61 - 1)* 100 = 0,61 * 100 = 61%\n\nEn el caso de que el coeficiente sea negativo, como por ejemplo “opinión sobre la situación de la economía en España” haríamos así: Odds ratioecoesp=e-1.352050=0.259. En este caso, la probabilidad de votar a VOX es 0.259 veces menor entre las personas que consideran que la economía nacional va bien, que entre los que consideran que la economía nacional va mal (ceteris paribus). Expresado en porcentaje, sería:\n\n(1 - 0.259)* 100 = 0.741 * 100 = 74%\n\n\nPara obtener los coeficientes exponenciados usamos la función exp(): Con este código le estoy pidiendo los odds ratio porque le estoy pidiendo el exponente de los coeficientes de la regresión logística.\n\nexp(coef(m.vox))\n\n                  (Intercept)                  hombreHombre \n                   0.03055927                    2.13479521 \nestudios_universitarioscon EU                          edad \n                   0.76637648                    0.97307287 \n               ecoesppositiva                         ideol \n                   0.25870935                    1.33717441 \n                 recuerdo19PP                 recuerdo19VOX \n                   1.61327017                   29.33114991 \n            recuerdo19Podemos          recuerdo19Ciudadanos \n                   0.73053605                    2.00047661 \n         recuerdo19Más Madrid               recuerdo19Otros \n                   0.32986896                    0.76614347 \n          recuerdo19En blanco \n                   0.88379885 \n\n\nPara ponerlo todo en una tabla, usamos la función cbind (column bind), que nos permite unir la columna de los coeficientes y la de los intervalos de confianza.\n\nexp(cbind(OR = coef(m.vox), confint(m.vox)))\n\n                                       OR       2.5 %      97.5 %\n(Intercept)                    0.03055927  0.02208591  0.04206783\nhombreHombre                   2.13479521  1.88285136  2.42278395\nestudios_universitarioscon EU  0.76637648  0.67642714  0.86797747\nedad                           0.97307287  0.96907780  0.97706174\necoesppositiva                 0.25870935  0.20798256  0.31942162\nideol                          1.33717441  1.29547382  1.38040656\nrecuerdo19PP                   1.61327017  1.30884340  1.99744850\nrecuerdo19VOX                 29.33114991 23.70655269 36.48258675\nrecuerdo19Podemos              0.73053605  0.47916950  1.07842418\nrecuerdo19Ciudadanos           2.00047661  1.55765237  2.56755800\nrecuerdo19Más Madrid           0.32986896  0.01861019  1.50799250\nrecuerdo19Otros                0.76614347  0.54999038  1.05146178\nrecuerdo19En blanco            0.88379885  0.42578629  1.64145359\n\n\nComparar coeficientes\nLos odds ratio se pueden comparar entre sí para saber qué variable es más explicativa o está asociada de manera más fuerte con la VD. Pero OJO! Para comparar un odds ratio mayor que uno (relación positiva) con un odds ratio menor que uno (relación negativa), es necesario calcular el valor inverso de uno de los datos porque el rango es distinto. Por ejemplo:\n\necoesp: 1/0,259=3,86\n\nCuando hacemos esto para poder comparar debemos tener en cuenta que este coeficiente es para la variable de referencia. En este caso 3,86 es para la economíanegativa, porque estamos dandole la vuelta al numerador y denominador.\nLa inversión de variables también es útil en el caso de las variables dicotómicas para comprobar el supuesto contrario al establecido. Por ejemplo, la probabilidad de las mujeres (en lugar del de los hombres) es de 1/2,13=0,47.\nSe puede hacer para cualquier tipo de variable, en el caso de la categóricas se invierte a su variable de referencias, y en el caso de las de escala (como la variable ideologia) lo entendemos como el aumento de una unidad.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#probabilidades-predichas",
    "href": "analisis/reg-logistica.html#probabilidades-predichas",
    "title": "Regresión logística",
    "section": "Probabilidades predichas",
    "text": "Probabilidades predichas\nComo alternativa a los coeficientes y a los odds ratio se pueden calcular las probabilidades predichas. Las probabilidades predichas son la mejor manera de entender las variables de un modelo. Para calcularlas, primero debemos crear un data.frame con los valores que queremos que tomen las variables independientes en nuestras predicciones.\n\ndata1 &lt;- with(datos_log, data.frame(ideol = mean(ideol), recuerdo19 = c(\"PSOE\",\"PP\",\"VOX\",\"Podemos\",\"Ciudadanos\", \"Más Madrid\", \"Otros\", \"En blanco\"), edad = mean(edad), hombre=\"Hombre\", estudios_universitarios=\"con EU\", ecoesp=\"negativa\"))\n\nhead(data1, 8)\n\n     ideol recuerdo19     edad hombre estudios_universitarios   ecoesp\n1 4.816505       PSOE 52.77877 Hombre                  con EU negativa\n2 4.816505         PP 52.77877 Hombre                  con EU negativa\n3 4.816505        VOX 52.77877 Hombre                  con EU negativa\n4 4.816505    Podemos 52.77877 Hombre                  con EU negativa\n5 4.816505 Ciudadanos 52.77877 Hombre                  con EU negativa\n6 4.816505 Más Madrid 52.77877 Hombre                  con EU negativa\n7 4.816505      Otros 52.77877 Hombre                  con EU negativa\n8 4.816505  En blanco 52.77877 Hombre                  con EU negativa\n\n\nEste código predice con la media de ideología en la muestra en vez de con ideología = 5, para todos los recuerdos de voto, que esté en la media de edad de la muestra, que sea hombre, con estudios y con una opinión negativa para la economía.\nEs importante que las variables en este data.frame tengan el mismo nombre que las variables en la regresión logística anterior. Una vez creado el data.frame, ya podemos pedirle a R que calcule las probabilidades predichas.\n\ndata1$probpredichas_vox&lt;- predict(m.vox, newdata = data1, type = \"response\")\ndata1[, c(2, 7)]  #le pido que muestre todas las filas de las columnas 2 (recuerdo voto) y 7(probabilidad predicha)\n\n  recuerdo19 probpredichas_vox\n1       PSOE        0.04578266\n2         PP        0.07184266\n3        VOX        0.58459468\n4    Podemos        0.03386365\n5 Ciudadanos        0.08757578\n6 Más Madrid        0.01558029\n7      Otros        0.03545569\n8  En blanco        0.04067907\n\n\nLos resultados muestran la probabilidad predicha de votar a VOX en 2023 para hombres con edad media, ideología media y con estudios universitarios, que opinan que la economía en España va mal, según el partido que habían votado en las elecciones anteriores.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#efectos-marginales",
    "href": "analisis/reg-logistica.html#efectos-marginales",
    "title": "Regresión logística",
    "section": "Efectos marginales",
    "text": "Efectos marginales\nEl paquete margins responde a un intento de trasladar el comando “margins” de Stata a R, como un método genérico para calcular los efectos marginales -o efectos parciales- de las variables independientes. Por ejemplo, vamos calcular el efecto marginal de las VIs en nuestro modelo\n\nlibrary(margins)\nmargins_vox &lt;- margins(m.vox)\n\n# Resumen\nsummary_margins &lt;- summary(margins_vox) \nsummary_margins\n\n                        factor     AME     SE        z      p   lower   upper\n                ecoesppositiva -0.0621 0.0042 -14.6920 0.0000 -0.0704 -0.0538\n                          edad -0.0015 0.0001 -13.0236 0.0000 -0.0017 -0.0012\n estudios_universitarioscon EU -0.0142 0.0034  -4.1951 0.0000 -0.0208 -0.0076\n                  hombreHombre  0.0405 0.0034  11.9060 0.0000  0.0339  0.0472\n                         ideol  0.0155 0.0009  17.8011 0.0000  0.0138  0.0172\n          recuerdo19Ciudadanos  0.0365 0.0071   5.1327 0.0000  0.0225  0.0504\n           recuerdo19En blanco -0.0047 0.0124  -0.3784 0.7051 -0.0291  0.0197\n          recuerdo19Más Madrid -0.0289 0.0159  -1.8197 0.0688 -0.0601  0.0022\n               recuerdo19Otros -0.0096 0.0057  -1.6861 0.0918 -0.0208  0.0016\n             recuerdo19Podemos -0.0111 0.0067  -1.6524 0.0985 -0.0243  0.0021\n                  recuerdo19PP  0.0231 0.0049   4.6900 0.0000  0.0135  0.0328\n                 recuerdo19VOX  0.3882 0.0146  26.5553 0.0000  0.3596  0.4169\n\n\nTambién podemos representarlos gráficamente. El gráfico a continuación representa la columna AME (Average Marginal Effect) y las columnas low and upper (bandas de confianza inferior y superior).\n\n# Convertimos el resumen en un data.frame para poder hacer un gráfico\ndata_to_plot &lt;- data.frame(\n  factor = summary_margins$factor,\n  AME = summary_margins$AME,\n  lower = summary_margins$lower,\n  upper = summary_margins$upper)\n\n\nggplot(data_to_plot, aes(x = AME, y = factor)) +\n  geom_point(color = \"blue\", size = 3) +  # Puntos para los AME\n  geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2, color = \"black\") +  # Barras de error\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey\") +  # Línea vertical en 0\n  labs(\n    title = \"Average Marginal Effects (AME) with Confidence Intervals\",\n    x = \"AME\",\n    y = \"Variables\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14),  # Centrar título\n    axis.text.y = element_text(size = 10))  # Ajustar tamaño de texto\n\n\n\n\n\n\n\n\nInterpretación: Cuando se dice que un efecto marginal es 0.3882, significa que haber votado a VOX en 2019 está asociado con un aumento promedio de 0.17 unidades en la variable dependiente. En el contexto de una probabilidad o un porcentaje, como suele ser el caso en la regresión logística o modelos similares, un efecto marginal de 0.3882 corresponde a un aumento del 38,82 puntos porcentuales.\nPara hacer un modelo robusto puedes elegir poner las variables con sus valores que conformarían el escenario mas adverso. El escenario que más desfavorece la hipótesis planteada.\nPara más información sobre opciones del paquete margins podéis consultar aquí y aquí.\nResumen\nLa primera transformación es pasar el logaritmo al otro lado, es decir \\(e^{\\text{coef}}\\) –&gt; los odds ratios, porque al otro lado del igual queda \\((\\frac{p(x)}{1 - p(x)})\\) , es decir la probabilidad del que el evento suceda partido de la probabilidad de que no suceda.\nLa última transfomación de la ecuación nos deja despejado \\(p(x)\\), de esta manera podemos hacer probabilidades predichas de x sustituyendo los betas y las x (como hacías valores predichos en lm). Como la distribución de la muestra no es lineal los efectos de x no son iguales a lo largo de todo y, de esta manera podemos calcular casos específicos de y. Podemos conocer a lo largo de la regresión la probabilidad de y para cada x seleccionada por nosotros.\nPor último podemos calcular los Average Marginal Effects (margins en Stata). El efecto marginal no es la probabilidad de ocurrencia de x, sino el fecto de la VI sobre la probabilidad de ocurrencia de x. Es la manera de conseguir el equivalente a los coeficientes de la regresión lineal porque calcular todas las y para ciertos valores de x y luego hace el promedio de esos impactos de la x. En el caso de lineales no hace falta transformar nada porque la media del efectos de una VI sobre todos los valores de y es igual a el efecto de de VI sobre un solo valor de y porque es un efecto estable a lo largo de toda la regresión.\nAME se usa principalmente cuando tienes un interés particular por el efecto de una VI.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#diagnóstico",
    "href": "analisis/reg-logistica.html#diagnóstico",
    "title": "Regresión logística",
    "section": "Diagnóstico",
    "text": "Diagnóstico\n\nMulticolinealidad\n\nlibrary(rms)\nlogit.vif&lt;- vif(m.vox)\nlogit.vif\n\n                 hombreHombre estudios_universitarioscon EU \n                     1.032483                      1.048952 \n                         edad                ecoesppositiva \n                     1.077446                      1.058599 \n                        ideol                  recuerdo19PP \n                     1.428741                      2.968629 \n                recuerdo19VOX             recuerdo19Podemos \n                     2.498353                      1.189084 \n         recuerdo19Ciudadanos          recuerdo19Más Madrid \n                     1.726136                      1.006883 \n              recuerdo19Otros           recuerdo19En blanco \n                     1.295863                      1.061883 \n\n\nTodos los valores están por debajo de 5. No parece que existan problemas de multicolinealidad\n\n\nHeterocedasticidad\n\nlibrary(lmtest)\nlogit.het&lt;-bptest(m.vox)\nlogit.het\n\n\n    studentized Breusch-Pagan test\n\ndata:  m.vox\nBP = 2273.9, df = 12, p-value &lt; 2.2e-16\n\n\nLa hipótesis nula en este test es que la varianza de los residuos es constante. La evidencia permite rechazar la hipótesis nula, confirmando que se cumple el supuesto de heterocedasticidad (que es lo que buscamos).",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#presentación-de-los-resultados",
    "href": "analisis/reg-logistica.html#presentación-de-los-resultados",
    "title": "Regresión logística",
    "section": "Presentación de los resultados",
    "text": "Presentación de los resultados\n\nlibrary(stargazer)\n\nstargazer(m.vox,\n          type=\"text\",\n          dep.var.labels=c(\"Voto VOX\"),\n          covariate.labels=c(\"Hombre\", \"Estudios Universitarios\", \"Edad\", \"Valoración + economia\", \"Ideología\", \"Voto 2019: PP (cr:PSOE)\", \"Voto 2019: VOX (cr:PSOE)\", \"Voto 2019: Podemos (cr:PSOE)\", \"Voto 2019: Ciudadanos (cr:PSOE)\", \"Voto 2019: +Madrid (cr:PSOE)\", \"Voto 2019: Otros (cr:PSOE)\", \"Voto 2019: blanco (cr:PSOE)\", \"Constante\"))\n\n\n===========================================================\n                                    Dependent variable:    \n                                ---------------------------\n                                         Voto VOX          \n-----------------------------------------------------------\nHombre                                   0.758***          \n                                          (0.064)          \n                                                           \nEstudios Universitarios                  -0.266***         \n                                          (0.064)          \n                                                           \nEdad                                     -0.027***         \n                                          (0.002)          \n                                                           \nValoración + economia                    -1.352***         \n                                          (0.109)          \n                                                           \nIdeología                                0.291***          \n                                          (0.016)          \n                                                           \nVoto 2019: PP (cr:PSOE)                  0.478***          \n                                          (0.108)          \n                                                           \nVoto 2019: VOX (cr:PSOE)                 3.379***          \n                                          (0.110)          \n                                                           \nVoto 2019: Podemos (cr:PSOE)              -0.314           \n                                          (0.206)          \n                                                           \nVoto 2019: Ciudadanos (cr:PSOE)          0.693***          \n                                          (0.127)          \n                                                           \nVoto 2019: +Madrid (cr:PSOE)              -1.109           \n                                          (1.011)          \n                                                           \nVoto 2019: Otros (cr:PSOE)                -0.266           \n                                          (0.165)          \n                                                           \nVoto 2019: blanco (cr:PSOE)               -0.124           \n                                          (0.341)          \n                                                           \nConstante                                -3.488***         \n                                          (0.164)          \n                                                           \n-----------------------------------------------------------\nObservations                              19,848           \nLog Likelihood                          -3,797.747         \nAkaike Inf. Crit.                        7,621.493         \n===========================================================\nNote:                           *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#validación-del-modelos-de-clasificaicón",
    "href": "analisis/reg-logistica.html#validación-del-modelos-de-clasificaicón",
    "title": "Regresión logística",
    "section": "Validación del modelos de clasificaicón",
    "text": "Validación del modelos de clasificaicón\nA continuación, vamos examinar cómo de bueno/malo es nuestro modelo a la hora de clasificar datos nuevos. Para ello, continuamos con el ejemplo anterior, en el que estimábamos la probabilidad de que un individiuo vote a un determinado partido. Se llama clasficación porque estoy intentado clasificar a los individuos en función de los valores de la VD, que en este caso es 0 y 1.\nEn primer lugar, creamos el conjunto de entrenamiento (60%) y test (40%). Como hay pocos 1 en la muestra (de la var dependiente), se amplia el % de casos destinados al test para evitar que dentro de este la proporción de 1 sea demasiado bajo como para comprobar el modelo.Se saca una muestra aleatoria y por eso ponermos el seed, para que nos escoja los mismos datos aleatorios y sea replicable.\n\nset.seed(123)\nindex &lt;- 1:nrow(datos_log)\nporc_test &lt;- 0.40\n# Dividir datos\ntest.data &lt;- datos_log %&gt;% sample_frac(porc_test)  \ntrain.data &lt;- datos_log %&gt;% anti_join(test.data)\n\nCreamos la variable clase_real, que corresponde a la variable dependiente (intentación voto a VOX) en el conjunto de test. Es la variable que luego comparemos con los valores estimados para ver nuestro nivel de acierto/error:\n\nclase_real &lt;- test.data$intvox\n\nEntrenamos el modelo (intención de voto a VOX) con los datos del train.data:\n\nlibrary(MASS)\nlogit.vox &lt;- glm(intvox ~ hombre + estudios_universitarios + edad + ecoesp + ideol + recuerdo19, data = train.data, family = \"binomial\")\nsummary(logit.vox)\n\n\nCall:\nglm(formula = intvox ~ hombre + estudios_universitarios + edad + \n    ecoesp + ideol + recuerdo19, family = \"binomial\", data = train.data)\n\nCoefficients:\n                               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   -2.647381   0.223754 -11.832  &lt; 2e-16 ***\nhombreHombre                   0.514395   0.091050   5.650 1.61e-08 ***\nestudios_universitarioscon EU -0.201434   0.089109  -2.261 0.023788 *  \nedad                          -0.019516   0.002758  -7.077 1.47e-12 ***\necoesppositiva                -1.382171   0.133390 -10.362  &lt; 2e-16 ***\nideol                          0.203899   0.021920   9.302  &lt; 2e-16 ***\nrecuerdo19PP                   0.952857   0.142989   6.664 2.67e-11 ***\nrecuerdo19VOX                  2.713181   0.147704  18.369  &lt; 2e-16 ***\nrecuerdo19Podemos             -0.421267   0.245799  -1.714 0.086553 .  \nrecuerdo19Ciudadanos           0.585503   0.168807   3.468 0.000523 ***\nrecuerdo19Más Madrid          -1.237565   1.017536  -1.216 0.223895    \nrecuerdo19Otros               -0.600585   0.217137  -2.766 0.005676 ** \nrecuerdo19En blanco           -0.948500   0.526124  -1.803 0.071418 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5182.6  on 5941  degrees of freedom\nResidual deviance: 3442.7  on 5929  degrees of freedom\nAIC: 3468.7\n\nNumber of Fisher Scoring iterations: 6\n\n\nDespués, calculamos los valores predichos en el conjunto de test. Estos son los valores que luego vamos a comparar con la “clase real”:\n\npredicted_logit&lt;- predict(logit.vox, newdata=test.data, type=\"response\")\nhead(predicted_logit)\n\n          1           2           3           4           5           6 \n0.006046023 0.024786792 0.050014734 0.009515188 0.213903071 0.064099475 \n\n\nPara valorar cómo de bien/mal clasifica nuestro modelo, vamos a calcular la curva ROC(Receiver operating characteristics) y el AUC (Area under the curve). Cuando hacemos una clasificación binaria, existen 4 tipos de resultados posibles:\n\nTrue negative (TN): predecimos 0 y la clase real es 0\nFalse negative (FN): predecimos 0 y la clase real es 1\nTrue positive (TP): predecimos 1 y la clase real es 1\nFalse positive (FP): predecimos 1 y la clase real es 0\n\nA partir de estos resultados se construye la matriz de confusión:\n\n\n\n\n\nLa matriz de confusión sive para calcular la curva ROC, que es la representación gráfico de la razón de Verdaderos Positivos (TPR) frente a la razón de falsos positivos (FPR):\n\nRazón de verdaderos positivos (TPR - true positive rate): proporción de positivos reales que son correctamente identificados como positivos por el modelo. También se le conoce como sensibilidad o recall. Se calcula como:\n\n\\[\nTPR = \\frac{TP}{TP + FN}\n\\]\n\nRazón de falsos positivos (FPR - false positive rate) = proporción de negativos reales que son incorrectamente identificados como positivos por el modelo. Se calcula como:\n\n\\[\nFPR = \\frac{FP}{FP + TN}\n\\]\nGráficamente, el espacio ROC se representa de la siguiente manera:\n\n\n\n\n\nLo ideal es encontrar una curva que se acerque lo máximo posible al punto de clasificación perfecta. Si está en la línea, los resultados de la predicción son completamente aleatorios, y si está por debajo de esta el modelo predice aún peor que asignar cifras al azar.\nPintamos la curva ROC de nuestro modelo:\n\nlibrary(ROCR)\n\n# Curva ROC\npred_logit &lt;-  prediction(predicted_logit, clase_real) # crea un objeto \"predicción\"\nperf_logit &lt;- performance(pred_logit, measure = \"tpr\", x.measure = \"fpr\") \npar(mfrow = c(1,1))\nplot(perf_logit, lty=1, col=\"darkgrey\", main = \"Logit ROC Curve\")\n\n\n\n\n\n\n\n\nEsto se interpreta en función del area que hay debajo de la línea, lo ideal es que el area sea 1 (100%) es decir, que todo lo ha clasificado bien.\nCalculamos el area bajo la curva (AUC). El AUC (Área Bajo la Curva) es una métrica que mide el desempeño de un modelo de clasificación binaria. Un valor de AUC:\n\n1.0: El modelo clasifica perfectamente todas las instancias\n0.5: El modelo no tiene poder predictivo (es como adivinar al azar)\n&lt; 0.5: El modelo clasifica peor que al azar.\n\n\nauc.logit&lt;- performance(pred_logit, measure = \"auc\", x.measure = \"fpr\") \nauc.logit@y.values \n\n[[1]]\n[1] 0.9201428\n\n\nEn nuestro caso, AUC=0.920. Este valor indica que nuestro modelo clasifica bien en un 92% por de los casos.\nNota: AUC es un S4 object system, por eso las consultas de sus elementos son un poco diferentes a lo que hemos visto hasta ahora. Nosotros no vamos a entrar en esto, pero si teneís curiosidad podéis leer este capítulo del libro de Hadley Wickham.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#comparación-de-modelos",
    "href": "analisis/reg-logistica.html#comparación-de-modelos",
    "title": "Regresión logística",
    "section": "Comparación de modelos",
    "text": "Comparación de modelos\nNormalmente, la curva ROC se utiliza para comparar la precisión de diferentes algoritmos de clasificación (como regresión logística, Naive Bayes, Random Forest, LDA, etc). Aunque en nuestro caso solo hemos trabajado con regresión logística, vamos a estimar diferentes modelos a modo de ejemplo, pero sin profundizar en los detalles de su funcionamiento.\n\nModelo de clasificación Random Forest\nEmpezamos con un random forest\n\nlibrary(randomForest)\n\n# Convertimos la variable intvoto en factor (de lo contrario, da error)\ntrain.data$intvox &lt;- as.factor(train.data$intvox)\ntest.data$intvox &lt;- as.factor(test.data$intvox)\n\n# Entrenamos el modelo Random Forest \nrf.vox &lt;- randomForest(\n  intvox ~ hombre + estudios_universitarios + edad + ecoesp + ideol + recuerdo19,\n  data = train.data,\n  ntree = 500,      # número de árboles\n  mtry = 2,         # número de predictores seleccionados aleatoriamente por árbol\n  importance = TRUE # importancia de variables\n)\n\n# Importancia de las variables\nimportance(rf.vox) \n\n                                 0          1 MeanDecreaseAccuracy\nhombre                  12.8426166   9.205945             16.10155\nestudios_universitarios 17.3804480   1.960043             15.25825\nedad                    31.4921348  10.755326             31.06569\necoesp                   0.3002038  24.733429             24.64840\nideol                   29.2955504  20.302083             45.27504\nrecuerdo19              63.0086066 104.221899             96.01329\n                        MeanDecreaseGini\nhombre                          20.12300\nestudios_universitarios         19.83165\nedad                           157.91882\necoesp                          59.64442\nideol                          149.24749\nrecuerdo19                     374.84054\n\n\nLe indicamos que haga 500 arboles; mtry es el número de predictores seecionados aleatoriamente. Importance indica que en los 500 arboles que variables han tenido más peso de manera sistemática en todos los modelos. Este valor no lo puedes interpretar pero te hace un ranking, cuanto más altos mejor (Accuracy y Gini). En vez de conocer la significatividad estadística tienemos la importancia de las variables en el modelo. El random forest va apartando poco a pode preditores que no sean relevantes para el modelo, según va haciendo los modelos de manera altearia.\nCuanto mayor es el número dentro del Accuracy, más relevante es esa variable dentro de la predicción. Que una variable sea más importante que otra no implica que sea mejor, ya que al no tener ninguna medida como el p-valor no se puede saber si la variable es significativa o no. Por tanto, que una variable sea más importante no la hace relevante en sí.\nEn este modelo el type se llama “prob” y luego si entre corchetes se pone [1] clasifica sobre los 0 y [,2] quiere decir que clasifica sobre los 1.\n\n# Calculamos los valores predichos en el conjunto de test\npredicted_rf &lt;- predict(rf.vox, newdata = test.data, type = \"prob\")[, 2]\n\n# Creamos el objeto de predicción para ROC\npred_rf &lt;- prediction(predicted_rf, clase_real) # valores predichos, valores reales\n\n# Calculamos rendimiento (ROC)\nperf_rf &lt;- performance(pred_rf, measure = \"tpr\", x.measure = \"fpr\")\n\n# Pintamos la curva ROC\npar(mfrow = c(1,1)) \nplot(perf_rf, lty = 1, col = \"gold\", main = \"Random Forest ROC Curve\")\n\n\n\n\n\n\n\n\n\n# Calculamos el AUC\nauc.rf&lt;- performance(pred_rf, measure = \"auc\", x.measure = \"fpr\") \nauc.rf@y.values\n\n[[1]]\n[1] 0.8862379\n\n\nEn este caso, AUC es de 88,7%. Esto indica que en el 87% de los casos, el modelo clasifica correctamente.\n\n\nModelo de clasificación Naive Bayes\nRepetimos el proceso con el algoritmo Naive Bayes (misma filosofía que un modelo bayesiano pero es otro modelo de clasificación).\n\nlibrary(e1071)  \n\n# Entrenamos el modelo Naive Bayes \nnb_model &lt;- naiveBayes(\n  intvox ~ hombre + estudios_universitarios + edad + ecoesp + ideol + recuerdo19, data = train.data)\n\n# Calculamos los valores predichos en el conjunto de test\npredicted_nb &lt;- predict(nb_model, newdata = test.data, type = \"raw\")[, 2] # raw en esta librería equivale a prob en la de random.forest\n\n# Creamos el objeto de predicción para ROC\npred_nb &lt;- prediction(predicted_nb, clase_real) #comparar datos predichos con reales\n\n# Calculamos el rendimiento (ROC)\nperf_nb &lt;- performance(pred_nb, measure = \"tpr\", x.measure = \"fpr\")\n\n# Pintamos la curva ROC\npar(mfrow = c(1,1)) # Configuración de un solo gráfico\nplot(perf_nb, lty = 1, col = \"steelblue\", main = \"Naive Bayes ROC Curve\")\n\n\n\n\n\n\n\n\n\n# Calculamos el AUC\nauc.nb&lt;- performance(pred_nb, measure = \"auc\", x.measure = \"fpr\") \nauc.nb@y.values \n\n[[1]]\n[1] 0.9161327\n\n\nEn este caso, el porcentaje de casos correctamente clasificados es 91,6%.\nPara tener una visión global vamos a representar todas las curvas ROC de manera conjunta. Esto nos permite comparar los resultados de los tres algoritmos:\n\npar(mfrow = c(1,1))\nplot(perf_logit, lty=1, col=\"darkgrey\", main = \"ROC Curves\")\nplot(perf_rf, lty=1, col=\"gold\", add = TRUE)\nplot(perf_nb, lty=1, col=\"steelblue\", add = TRUE)\nlegend(0.4, 0.6,  \n       c(\"Logit=0.920\", \"Random Forest=0.887\", \"Naive Bayes=0.916\"), \n       lty = c(1,1,1),       \n       bty = \"n\",\n       col=c(\"darkgrey\", \"gold\",\"steelblue\"),\n       cex = 0.7)\n\n\n\n\n\n\n\n\nEs importante recordar que nuestros modelos sólo están teniendo en consideración a los individuos que han respondido a todas las preguntas incluidas en el modelo. De esta manera, estamos dejando fuera a muchos entrevistados que no ofrecen información sobre alguna de las variables, particularmente, ideología y recuerdo. Esto genera un importante sesgo. ¿Sería mejor dejar estas variables fuera? A modo de ejemplo, vamos a ver cuál hubiera sido el resultado de no haber incluido información sobre esas variables. Repitamos nuestro modelo original, esta vez excluyendo ideología y recuerdo de voto en el 2019.\n\n# Modelo sin ideología ni recuerdo de voto\nlogit2.vox &lt;- glm(intvox ~ hombre + estudios_universitarios + edad + ecoesp, data = train.data, family = \"binomial\")\n\n# Predicción\npredicted_logit2&lt;- predict(logit2.vox, newdata=test.data, type=\"response\")\n\n# ROC\npred_logit2 &lt;-  prediction(predicted_logit2, clase_real)\nperf_logit2&lt;- performance(pred_logit2, measure = \"tpr\", x.measure = \"fpr\") \n\n# AUC\nauc.logit2 &lt;- performance(pred_logit2, measure = \"auc\", x.measure = \"fpr\") \nauc.logit2@y.values\n\n[[1]]\n[1] 0.7653978\n\n\nLa AUC en este caso es considerablemente más baja. Comparamos ambos modelos gráficamente:\n\npar(mfrow = c(1,1))\nplot(perf_logit, lty=1, col=\"darkgrey\", main = \"Logit ROC Curves\")\nplot(perf_logit2, lty=2, col=\"grey\", add = TRUE)\n\nlegend(0.4, 0.6,  \n       c(\"Logit=0.920\", \"Logit(sin ideología ni recuerdo de voto)=0.765\"), \n       lty = c(1,2),       \n       bty = \"n\",\n       col=c(\"darkgrey\", \"grey\"),\n       cex = 0.7)\n\n\n\n\n\n\n\n\nComo se puede observar en el gráfico arriba, la predicción es mucho peor cuando no disponemos de información sobre ideología y recuerdo de voto. Una alternativa sería imputar los valores perdidos en las variables que tienen un número elevado de NA antes de hacer la regresión.",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/reg-logistica.html#mejora-de-modelos",
    "href": "analisis/reg-logistica.html#mejora-de-modelos",
    "title": "Regresión logística",
    "section": "Mejora de modelos",
    "text": "Mejora de modelos\nVamos a explorar qué ocurre si tomamos en consideración que algunas variables pueden no tener un efecto lineal. Por ejemplo, la edad. Sabemos por otros estudios que el perfil de edad de los votantes de Vox es diverso, pero el partido tiene un respaldo importante entre votantes de mediana edad (35-54 años). Para tomar en cuenta esto, vamos a elevar ambos la variable edad al cuadrado. Recordad que siempre hay que incluir el efecto principal y el cuadrático\n\nlogit3.vox &lt;- glm(intvox ~ hombre + estudios_universitarios + edad + I(edad^2) + ecoesp + ideol + recuerdo19,\n  data = train.data, family = \"binomial\")\nsummary(logit3.vox)\n\n\nCall:\nglm(formula = intvox ~ hombre + estudios_universitarios + edad + \n    I(edad^2) + ecoesp + ideol + recuerdo19, family = \"binomial\", \n    data = train.data)\n\nCoefficients:\n                                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   -3.9443595  0.4471310  -8.821  &lt; 2e-16 ***\nhombreHombre                   0.5160163  0.0912237   5.657 1.54e-08 ***\nestudios_universitarioscon EU -0.2110982  0.0891749  -2.367 0.017921 *  \nedad                           0.0361276  0.0166679   2.167 0.030197 *  \nI(edad^2)                     -0.0005431  0.0001611  -3.372 0.000747 ***\necoesppositiva                -1.3912122  0.1335494 -10.417  &lt; 2e-16 ***\nideol                          0.2082346  0.0220012   9.465  &lt; 2e-16 ***\nrecuerdo19PP                   0.9575919  0.1427256   6.709 1.96e-11 ***\nrecuerdo19VOX                  2.6741532  0.1477779  18.096  &lt; 2e-16 ***\nrecuerdo19Podemos             -0.4081878  0.2457836  -1.661 0.096761 .  \nrecuerdo19Ciudadanos           0.5629760  0.1688350   3.334 0.000855 ***\nrecuerdo19Más Madrid          -1.1715752  1.0172350  -1.152 0.249434    \nrecuerdo19Otros               -0.6173077  0.2172718  -2.841 0.004495 ** \nrecuerdo19En blanco           -0.9736638  0.5261391  -1.851 0.064230 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5182.6  on 5941  degrees of freedom\nResidual deviance: 3430.9  on 5928  degrees of freedom\nAIC: 3458.9\n\nNumber of Fisher Scoring iterations: 6\n\n\nEn nuestro modelo, el efecto principal es positivo, y el cuadrático es negativo. Además, ambos son estadísticamente significativos. La combinación de estos efectos sugiere que la relación entre la variable independiente y la dependiente tiene forma de “U” invertida: La variable dependiente aumenta hasta cierto punto (el máximo) y luego comienza a disminuir.\nEn este post se explica bastante bien la relación entre signos del efecto principal y cuadrático y la forma del efecto",
    "crumbs": [
      "Análisis de datos",
      "Regresiones",
      "Regresión logística"
    ]
  },
  {
    "objectID": "analisis/tablas-contingencia.html",
    "href": "analisis/tablas-contingencia.html",
    "title": "Tablas de contingencia",
    "section": "",
    "text": "Permite conocer la relación existente entre variables categóricas. Para ello nos valemos de las tablas de contingencia, donde se muestran las frecuencias de dos variables.\n\n\n\nCrear la tabla con las dos variables y guardarla:\n\ntabla &lt;- table(datos$var1, datos$var2)\nEj.:\n\ntabla &lt;- table(datos$situ_lab, datos$hombre)  # (filas, columnas)\ntabla\n\n                   \n                    Mujer Hombre\n  Trabajador/a       7552   9549\n  Pensionista        3515   3854\n  Desempleado/a      1424    846\n  Estudiante          502    617\n  Trabajo doméstico   994     30\n  Otra situación      182    113\n\n\nLa primera variable son las filas de la tabla y la segunda las columnas. La variable con menos categorías se pone en las columnas porque así es más sencillo de visualizar e interpretar, creando una tabla que se extiende de forma vertical en lugar de horizontal (mejor la primera tabla que la segunda).\n\nCrear la tabla de frecuencias:\n\n\nprop.table(tabla) Porcentaje de tabla (el % sobre el total)\nprop.table(tabla, 1) Porcentajes de fila (el 100% lo suman las filas)\nprop.table(tabla, 2) Porcentajes de columna (el 100% lo suman las columnas) Para leer estas tablas adecuadamente, hay que fijarse si el 100% lo suman las filas, las columnas o toda la tabla.\n\nEj.:\n\nprop.table(tabla)   \n\n                   \n                          Mujer      Hombre\n  Trabajador/a      0.258825142 0.327267119\n  Pensionista       0.120467475 0.132085818\n  Desempleado/a     0.048803893 0.028994448\n  Estudiante        0.017204743 0.021146069\n  Trabajo doméstico 0.034066763 0.001028172\n  Otra situación    0.006237576 0.003872781\n\n\nIndica el porcentaje de cada subgrupo sobre el total de la muestra. Por ejemplo, de esta tabla se puede deducir que del total de la población un 25% son mujeres trabajadoras.\n\nprop.table(tabla, 1)\n\n                   \n                         Mujer     Hombre\n  Trabajador/a      0.44161160 0.55838840\n  Pensionista       0.47699824 0.52300176\n  Desempleado/a     0.62731278 0.37268722\n  Estudiante        0.44861483 0.55138517\n  Trabajo doméstico 0.97070312 0.02929688\n  Otra situación    0.61694915 0.38305085\n\n\nIndica la composición de género de cada una de las situaciones laborales. Por ejemplo, de los trabajadores un 44% son mujeres y un 56% hombres.\n\nprop.table(tabla, 2)\n\n                   \n                          Mujer      Hombre\n  Trabajador/a      0.532994566 0.636218269\n  Pensionista       0.248076787 0.256779266\n  Desempleado/a     0.100501094 0.056366180\n  Estudiante        0.035429459 0.041108668\n  Trabajo doméstico 0.070153151 0.001998801\n  Otra situación    0.012844943 0.007528816\n\n\nIndica el perfil laboral dentro de cada género. Por ejemplo, un 54% de las mujeres son trabajadoras, mientras que un 63% de los hombres son trabajadores.\n\n\n\nOtros dos comandos para realizar tablas de contingencia son xtablsy CrossTable. Estos comandos resultan más útiles cuando, a parte de las frecuencias y los porcentajes, se quieren conocer también otros estadísticos como el Chi2 o los residuos.\nEs mejor usar la función CrossTable.\n\nCrossTable()xtabs()\n\n\nlibrary(gmodels)\ntabla3 &lt;- CrossTable(datos$var1, datos$var2, #Las variables\n                     digits = 1, #El número de decimales de la tabla\n                     #Otras opciones de la tabla,\n                     format = \"SPSS\") #El formato de salida de la tabla\nEj.:\n\nCrossTable(datos$situ_lab, datos$hombre, digits=1, expected=T, asresid=TRUE, chisq=TRUE, prop.chisq=F, format=\"SPSS\")\n\n\n   Cell Contents\n|-------------------------|\n|                   Count |\n|         Expected Values |\n|             Row Percent |\n|          Column Percent |\n|           Total Percent |\n|           Adj Std Resid |\n|-------------------------|\n\nTotal Observations in Table:  29178 \n\n                  | datos$hombre \n   datos$situ_lab |    Mujer  |   Hombre  | Row Total | \n------------------|-----------|-----------|-----------|\n     Trabajador/a |     7552  |     9549  |    17101  | \n                  |   8304.3  |   8796.7  |           | \n                  |     44.2% |     55.8% |     58.6% | \n                  |     53.3% |     63.6% |           | \n                  |     25.9% |     32.7% |           | \n                  |    -17.9  |     17.9  |           | \n------------------|-----------|-----------|-----------|\n      Pensionista |     3515  |     3854  |     7369  | \n                  |   3578.4  |   3790.6  |           | \n                  |     47.7% |     52.3% |     25.3% | \n                  |     24.8% |     25.7% |           | \n                  |     12.0% |     13.2% |           | \n                  |     -1.7  |      1.7  |           | \n------------------|-----------|-----------|-----------|\n    Desempleado/a |     1424  |      846  |     2270  | \n                  |   1102.3  |   1167.7  |           | \n                  |     62.7% |     37.3% |      7.8% | \n                  |     10.1% |      5.6% |           | \n                  |      4.9% |      2.9% |           | \n                  |     14.1  |    -14.1  |           | \n------------------|-----------|-----------|-----------|\n       Estudiante |      502  |      617  |     1119  | \n                  |    543.4  |    575.6  |           | \n                  |     44.9% |     55.1% |      3.8% | \n                  |      3.5% |      4.1% |           | \n                  |      1.7% |      2.1% |           | \n                  |     -2.5  |      2.5  |           | \n------------------|-----------|-----------|-----------|\nTrabajo doméstico |      994  |       30  |     1024  | \n                  |    497.3  |    526.7  |           | \n                  |     97.1% |      2.9% |      3.5% | \n                  |      7.0% |      0.2% |           | \n                  |      3.4% |      0.1% |           | \n                  |     31.6  |    -31.6  |           | \n------------------|-----------|-----------|-----------|\n   Otra situación |      182  |      113  |      295  | \n                  |    143.3  |    151.7  |           | \n                  |     61.7% |     38.3% |      1.0% | \n                  |      1.3% |      0.8% |           | \n                  |      0.6% |      0.4% |           | \n                  |      4.5  |     -4.5  |           | \n------------------|-----------|-----------|-----------|\n     Column Total |    14169  |    15009  |    29178  | \n                  |     48.6% |     51.4% |           | \n------------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  1308.347     d.f. =  5     p =  9.930323e-281 \n\n\n \n       Minimum expected frequency: 143.2537 \n\n\nPara comprobar qué opciones se pueden aplicar a la tabla, conviene mirar ?(CrossTable)\nEj. de interpretación de los residuos ajustados: en la celda de mujer y trabajadoras, los residuos ajustados son de -17,9. Esta cifra es inferior a -3,27, por lo que podemos decir que con un nivel de confianza del 99,9% las mujeres se encuentran infrarepresentadas (el símbolo es negativo) dentro del grupo de los trabajadores.\n\n\ntabla2 &lt;- xtabs(~var1+var2, data = datos) #Crear y guardar la tabla\nftable(tabla2) #Visualizar la tabla\nsummary(tabla2) #Para ver los estadísticos de la tabla (como el chi2 y el p-valor)\nEj.:\n\ntabla2 &lt;- xtabs(~situ_lab+hombre, data=datos)\nftable(tabla2) \n\n                  hombre Mujer Hombre\nsitu_lab                             \nTrabajador/a              7552   9549\nPensionista               3515   3854\nDesempleado/a             1424    846\nEstudiante                 502    617\nTrabajo doméstico          994     30\nOtra situación             182    113\n\nsummary(tabla2) \n\nCall: xtabs(formula = ~situ_lab + hombre, data = datos)\nNumber of cases in table: 29178 \nNumber of factors: 2 \nTest for independence of all factors:\n    Chisq = 1308.3, df = 5, p-value = 9.93e-281",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Tablas de contingencia"
    ]
  },
  {
    "objectID": "analisis/tablas-contingencia.html#en-r",
    "href": "analisis/tablas-contingencia.html#en-r",
    "title": "Tablas de contingencia",
    "section": "",
    "text": "Permite conocer la relación existente entre variables categóricas. Para ello nos valemos de las tablas de contingencia, donde se muestran las frecuencias de dos variables.\n\n\n\nCrear la tabla con las dos variables y guardarla:\n\ntabla &lt;- table(datos$var1, datos$var2)\nEj.:\n\ntabla &lt;- table(datos$situ_lab, datos$hombre)  # (filas, columnas)\ntabla\n\n                   \n                    Mujer Hombre\n  Trabajador/a       7552   9549\n  Pensionista        3515   3854\n  Desempleado/a      1424    846\n  Estudiante          502    617\n  Trabajo doméstico   994     30\n  Otra situación      182    113\n\n\nLa primera variable son las filas de la tabla y la segunda las columnas. La variable con menos categorías se pone en las columnas porque así es más sencillo de visualizar e interpretar, creando una tabla que se extiende de forma vertical en lugar de horizontal (mejor la primera tabla que la segunda).\n\nCrear la tabla de frecuencias:\n\n\nprop.table(tabla) Porcentaje de tabla (el % sobre el total)\nprop.table(tabla, 1) Porcentajes de fila (el 100% lo suman las filas)\nprop.table(tabla, 2) Porcentajes de columna (el 100% lo suman las columnas) Para leer estas tablas adecuadamente, hay que fijarse si el 100% lo suman las filas, las columnas o toda la tabla.\n\nEj.:\n\nprop.table(tabla)   \n\n                   \n                          Mujer      Hombre\n  Trabajador/a      0.258825142 0.327267119\n  Pensionista       0.120467475 0.132085818\n  Desempleado/a     0.048803893 0.028994448\n  Estudiante        0.017204743 0.021146069\n  Trabajo doméstico 0.034066763 0.001028172\n  Otra situación    0.006237576 0.003872781\n\n\nIndica el porcentaje de cada subgrupo sobre el total de la muestra. Por ejemplo, de esta tabla se puede deducir que del total de la población un 25% son mujeres trabajadoras.\n\nprop.table(tabla, 1)\n\n                   \n                         Mujer     Hombre\n  Trabajador/a      0.44161160 0.55838840\n  Pensionista       0.47699824 0.52300176\n  Desempleado/a     0.62731278 0.37268722\n  Estudiante        0.44861483 0.55138517\n  Trabajo doméstico 0.97070312 0.02929688\n  Otra situación    0.61694915 0.38305085\n\n\nIndica la composición de género de cada una de las situaciones laborales. Por ejemplo, de los trabajadores un 44% son mujeres y un 56% hombres.\n\nprop.table(tabla, 2)\n\n                   \n                          Mujer      Hombre\n  Trabajador/a      0.532994566 0.636218269\n  Pensionista       0.248076787 0.256779266\n  Desempleado/a     0.100501094 0.056366180\n  Estudiante        0.035429459 0.041108668\n  Trabajo doméstico 0.070153151 0.001998801\n  Otra situación    0.012844943 0.007528816\n\n\nIndica el perfil laboral dentro de cada género. Por ejemplo, un 54% de las mujeres son trabajadoras, mientras que un 63% de los hombres son trabajadores.\n\n\n\nOtros dos comandos para realizar tablas de contingencia son xtablsy CrossTable. Estos comandos resultan más útiles cuando, a parte de las frecuencias y los porcentajes, se quieren conocer también otros estadísticos como el Chi2 o los residuos.\nEs mejor usar la función CrossTable.\n\nCrossTable()xtabs()\n\n\nlibrary(gmodels)\ntabla3 &lt;- CrossTable(datos$var1, datos$var2, #Las variables\n                     digits = 1, #El número de decimales de la tabla\n                     #Otras opciones de la tabla,\n                     format = \"SPSS\") #El formato de salida de la tabla\nEj.:\n\nCrossTable(datos$situ_lab, datos$hombre, digits=1, expected=T, asresid=TRUE, chisq=TRUE, prop.chisq=F, format=\"SPSS\")\n\n\n   Cell Contents\n|-------------------------|\n|                   Count |\n|         Expected Values |\n|             Row Percent |\n|          Column Percent |\n|           Total Percent |\n|           Adj Std Resid |\n|-------------------------|\n\nTotal Observations in Table:  29178 \n\n                  | datos$hombre \n   datos$situ_lab |    Mujer  |   Hombre  | Row Total | \n------------------|-----------|-----------|-----------|\n     Trabajador/a |     7552  |     9549  |    17101  | \n                  |   8304.3  |   8796.7  |           | \n                  |     44.2% |     55.8% |     58.6% | \n                  |     53.3% |     63.6% |           | \n                  |     25.9% |     32.7% |           | \n                  |    -17.9  |     17.9  |           | \n------------------|-----------|-----------|-----------|\n      Pensionista |     3515  |     3854  |     7369  | \n                  |   3578.4  |   3790.6  |           | \n                  |     47.7% |     52.3% |     25.3% | \n                  |     24.8% |     25.7% |           | \n                  |     12.0% |     13.2% |           | \n                  |     -1.7  |      1.7  |           | \n------------------|-----------|-----------|-----------|\n    Desempleado/a |     1424  |      846  |     2270  | \n                  |   1102.3  |   1167.7  |           | \n                  |     62.7% |     37.3% |      7.8% | \n                  |     10.1% |      5.6% |           | \n                  |      4.9% |      2.9% |           | \n                  |     14.1  |    -14.1  |           | \n------------------|-----------|-----------|-----------|\n       Estudiante |      502  |      617  |     1119  | \n                  |    543.4  |    575.6  |           | \n                  |     44.9% |     55.1% |      3.8% | \n                  |      3.5% |      4.1% |           | \n                  |      1.7% |      2.1% |           | \n                  |     -2.5  |      2.5  |           | \n------------------|-----------|-----------|-----------|\nTrabajo doméstico |      994  |       30  |     1024  | \n                  |    497.3  |    526.7  |           | \n                  |     97.1% |      2.9% |      3.5% | \n                  |      7.0% |      0.2% |           | \n                  |      3.4% |      0.1% |           | \n                  |     31.6  |    -31.6  |           | \n------------------|-----------|-----------|-----------|\n   Otra situación |      182  |      113  |      295  | \n                  |    143.3  |    151.7  |           | \n                  |     61.7% |     38.3% |      1.0% | \n                  |      1.3% |      0.8% |           | \n                  |      0.6% |      0.4% |           | \n                  |      4.5  |     -4.5  |           | \n------------------|-----------|-----------|-----------|\n     Column Total |    14169  |    15009  |    29178  | \n                  |     48.6% |     51.4% |           | \n------------------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  1308.347     d.f. =  5     p =  9.930323e-281 \n\n\n \n       Minimum expected frequency: 143.2537 \n\n\nPara comprobar qué opciones se pueden aplicar a la tabla, conviene mirar ?(CrossTable)\nEj. de interpretación de los residuos ajustados: en la celda de mujer y trabajadoras, los residuos ajustados son de -17,9. Esta cifra es inferior a -3,27, por lo que podemos decir que con un nivel de confianza del 99,9% las mujeres se encuentran infrarepresentadas (el símbolo es negativo) dentro del grupo de los trabajadores.\n\n\ntabla2 &lt;- xtabs(~var1+var2, data = datos) #Crear y guardar la tabla\nftable(tabla2) #Visualizar la tabla\nsummary(tabla2) #Para ver los estadísticos de la tabla (como el chi2 y el p-valor)\nEj.:\n\ntabla2 &lt;- xtabs(~situ_lab+hombre, data=datos)\nftable(tabla2) \n\n                  hombre Mujer Hombre\nsitu_lab                             \nTrabajador/a              7552   9549\nPensionista               3515   3854\nDesempleado/a             1424    846\nEstudiante                 502    617\nTrabajo doméstico          994     30\nOtra situación             182    113\n\nsummary(tabla2) \n\nCall: xtabs(formula = ~situ_lab + hombre, data = datos)\nNumber of cases in table: 29178 \nNumber of factors: 2 \nTest for independence of all factors:\n    Chisq = 1308.3, df = 5, p-value = 9.93e-281",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Tablas de contingencia"
    ]
  },
  {
    "objectID": "analisis/tablas-contingencia.html#teoría",
    "href": "analisis/tablas-contingencia.html#teoría",
    "title": "Tablas de contingencia",
    "section": "2. Teoría",
    "text": "2. Teoría\nLas hipótesis a comprobar en una tabla de contingencia son:\n\nH0= no existe asociación entre las variables (son independientes)\nH1= sí existe asociación entre las variables\n\nPara saber si existe relación entre las variables debemos fijarnos en:\n\nEl análisis de los residuos\nA la hora de examinar la asociación entre variable categóricas es importante diferenciar entre:\n\nFrecuencia observada: la frecuencia en la muestra\nFrecuencia esperada: la frecuencia que observaríamos en el caso de que no hubiera relación entre las 2 variables\nResiduo: diferencia entre el valor observado y el esperado, que manifiesta dependencia entre pares de valores cuando es distinto de cero. Cuanto mayor sea el residuo, mayor será la probabilidad de que la muestra provenga de una población en la que las variables estén relacionadas. Para determinar si el valor de los residuos es significativo, es necesario estandarizarlos.\n\nSi el residuo ajustado es mayor (en términos absolutos) que el valor crítico para un determinado nivel de confianza (1,96 para el 95%), se puede decir que la diferencia entre los valores esperados y los ajustados para una celda concreta de la tabla es significativa. En función de si el signo de estos residuos es positivo o negativo, sabremos si la relación establecida en la celda es de sobrerrepresentación dentro de la muestra (signo +) o de infrarrepresentación (signo -). (Hay un ejemplo de esto al final de la explicación de CrossTables en R)\n\n\nChi2\nEl chi-cuadrado (χ²) es una prueba estadística que se utiliza para comparar frecuencias observadas con frecuencias esperadas, a fin de determinar si hay una diferencia significativa entre ellas. Se emplea comúnmente para analizar tablas de contingencia y evaluar si dos variables categóricas están relacionadas. El𝜒2 se define como:\n\\[\\chi^2 = \\sum \\frac {(O - E)^2}{E}\\] Donde:\n\nO = Frecuencias observadas\nE = Frecuencias esperadas\n\nPor ser suma de cuadrados, se cumple que 𝜒2≥0:\n\n𝜒2=0 cuando las variables son independientes\n𝜒2 crece a medida que aumenta la dependencia entre las variables\n\nSabemos que el valor de chi-cuadrado (χ²) es lo suficientemente alto para ser significativo comparándolo con un valor crítico de una tabla de chi-cuadrado, o mediante su p-valor.",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "Tablas de contingencia"
    ]
  },
  {
    "objectID": "analisis/ttest.html",
    "href": "analisis/ttest.html",
    "title": "T-test",
    "section": "",
    "text": "El objetivo de este tipo de test es comprobar si la media poblacional de una variable se corresponde con una determinada cifra.\nt.test(datos$variable, mu = 5, conf.level = 0.99)\n\nmu = número es donde se indica el valor de la media para el cual se quiere comprobar si la media poblacional es significativamente distinta. Es decir, si se quiere comprobar si la media es igual a 5, se escribirá mu = 5.\nconf.level sirve para establecer un intervalo de confianza específico. Si no se añade esta opción, el intervalo será al 95%.\n\n\nt.test(datos$ideol, mu=5.5)\n\n\n    One Sample t-test\n\ndata:  datos$ideol\nt = -43.622, df = 28265, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 5.5\n95 percent confidence interval:\n 4.785116 4.846597\nsample estimates:\nmean of x \n 4.815857 \n\n\nEn este caso, se puede decir que al 95% de confianza la media ideológica de la población es distinta de 5.5 (en una escala del 1 al 10). Se sabe por tres motivos:\n\nEl p-value es &lt; de 0,05\nEl valor de t &lt; -1,96\nEn el intervalo de confianza no se incluye el 5.5\n\nLa explicación del por qué está en el apartado de la teoría",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "T-test"
    ]
  },
  {
    "objectID": "analisis/ttest.html#test-de-una-media",
    "href": "analisis/ttest.html#test-de-una-media",
    "title": "T-test",
    "section": "",
    "text": "El objetivo de este tipo de test es comprobar si la media poblacional de una variable se corresponde con una determinada cifra.\nt.test(datos$variable, mu = 5, conf.level = 0.99)\n\nmu = número es donde se indica el valor de la media para el cual se quiere comprobar si la media poblacional es significativamente distinta. Es decir, si se quiere comprobar si la media es igual a 5, se escribirá mu = 5.\nconf.level sirve para establecer un intervalo de confianza específico. Si no se añade esta opción, el intervalo será al 95%.\n\n\nt.test(datos$ideol, mu=5.5)\n\n\n    One Sample t-test\n\ndata:  datos$ideol\nt = -43.622, df = 28265, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 5.5\n95 percent confidence interval:\n 4.785116 4.846597\nsample estimates:\nmean of x \n 4.815857 \n\n\nEn este caso, se puede decir que al 95% de confianza la media ideológica de la población es distinta de 5.5 (en una escala del 1 al 10). Se sabe por tres motivos:\n\nEl p-value es &lt; de 0,05\nEl valor de t &lt; -1,96\nEn el intervalo de confianza no se incluye el 5.5\n\nLa explicación del por qué está en el apartado de la teoría",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "T-test"
    ]
  },
  {
    "objectID": "analisis/ttest.html#test-de-proporciones",
    "href": "analisis/ttest.html#test-de-proporciones",
    "title": "T-test",
    "section": "Test de proporciones",
    "text": "Test de proporciones\nPara variables dicotómicas. Lo que se intenta con este tipo de test no es comprobar si una determinada cifra se incluye dentro de la media poblacional, sino si una variable alcanza un determinado porcentaje.\nP.ej., para saber si el PP puede alcanzar un 35% de los votos, se crea una variable dicotómica donde 0 es no votarlo y 1 sí. Después, se hace un ttest como el anterior, pero en el mu se especifica el porcentaje que se quiere comprobar si se alcanza (0.35 en este caso).\n\nt.test(datos$intvoto_pp, mu=0.35)\n\n\n    One Sample t-test\n\ndata:  datos$intvoto_pp\nt = -8.4891, df = 23428, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0.35\n95 percent confidence interval:\n 0.3180496 0.3300361\nsample estimates:\nmean of x \n0.3240429 \n\n\nLos resultados se interpretan igual que en el test de una media.",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "T-test"
    ]
  },
  {
    "objectID": "analisis/ttest.html#test-de-dos-medias",
    "href": "analisis/ttest.html#test-de-dos-medias",
    "title": "T-test",
    "section": "Test de dos medias",
    "text": "Test de dos medias\nLa hipótesis nula en este tipo de prueba es que las dos medias son iguales y la hipótesis alternativa es que no lo son.\nt.test(datos$var1 ~ datos$var2)\n\nvar2 es la variable dicotómica que divide a la muestra en los dos grupos de interés, para los cuales se tratará de averiguar si la media de la\nvar1 (variable numérica) es igual en ambos o no.\n\n\nt.test(datos$ideol ~ datos$hombre)\n\n\n    Welch Two Sample t-test\n\ndata:  datos$ideol by datos$hombre\nt = -3.7778, df = 27496, p-value = 0.0001586\nalternative hypothesis: true difference in means between group Mujer and group Hombre is not equal to 0\n95 percent confidence interval:\n -0.1806671 -0.0572345\nsample estimates:\n mean in group Mujer mean in group Hombre \n            4.754256             4.873207 \n\n\nLos resultados indican que la media de ideología de las mujeres en la muestra es 4.75 y la de los hombres 4.87. Esta diferencia es suficiente para rechazar la Ho, es decir, existen diferencias significativas en la ideología en función del género.",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "T-test"
    ]
  },
  {
    "objectID": "analisis/ttest.html#comparación-de-medias-para-dos-variables-numéricas",
    "href": "analisis/ttest.html#comparación-de-medias-para-dos-variables-numéricas",
    "title": "T-test",
    "section": "Comparación de medias para dos variables numéricas",
    "text": "Comparación de medias para dos variables numéricas\nSi son muestras independientes:\nt.test(datos$variable1, datos$variable2)\nEn el caso de muestras dependientes, el comando es el siguiente:\nt.test(datos$variable1, datos$variable2, paired = TRUE)\nLa prueba t pareada se utiliza cuando las medias que estamos comparando no son independientes. En otras palabras:\n\nCorrenponden al mismo conjunto de sujetos en dos momentos diferentes (por ejemplo, antes y después de un tratamiento).\nSe comparan dos variables medidas en las mismas personas o unidades (las mismas personas opinan o responden sobre dos cosas diferentes).\n\nEj.: comprobar si las personas tienen la misma probabilidad de votar al PP y VOX:\n\nt.test(datos$prop_vox, datos$prop_pp, paired=TRUE) \n\n\n    Paired t-test\n\ndata:  datos$prop_vox and datos$prop_pp\nt = -69.828, df = 28775, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.652107 -1.561891\nsample estimates:\nmean difference \n      -1.606999",
    "crumbs": [
      "Análisis de datos",
      "Análisis bivariado",
      "T-test"
    ]
  },
  {
    "objectID": "df-var/ficheros-datos.html",
    "href": "df-var/ficheros-datos.html",
    "title": "Ficheros de datos (dataframe)",
    "section": "",
    "text": "Para poder abrir un fichero no basta con el comando, sino que estos se deben guardar dentro de un nuevo objeto:\ndatos&lt;- read_csv(\"filename\")\nFicheros de texto plano (.csv, .txt, tsv, etc)\nSe necisita abrir la librería readr: library(readr). El comando a utilizar varía en función del separador del archivo:\n\nread_csv() para ficheros csv delimitados por coma (,).\nread_csv2() para ficheros csv delimitados por punto y coma (;).\nread_tsv() lee ficheros separados por tabulador\nread_delim() lee ficheros sin delimitador\nread_fwf() lee ficheros de ancho fijo\nread_table() lee ficheros separados por espacio\n\nSi las columnas tienen nombre, se debe especificar dentro de la función:\ndata&lt;-read_csv(\"filename\", col_names=FALSE)\nFicheros de excel\nCuando los datos están un fichero .xlsx, utilizamos función read_excel() del paquete readxl\nSi los datos están la primera hoja del fichero mi_excel.xlsx\nlibrary(readxl)\ndatos &lt;- read_excel(\"mi_excel.xlsx\", 1)\nSi los datos están en una hoja llamada “mi_hoja”\ndatos &lt;- read.excel(\"mi_excel.xlsx\", sheetName = \"mi_hoja\") \nLectura de datos desde ficheros SPSS, Stata y SAS\nUna de las opciones existentes es la función haven() del paquete haven nos permite abrir ficheros en formatoStata/SPSS/SAS. Por ejemplo:\nlibrary(haven)\ndatos &lt;- read_dta(\"filename.dta\")\nLas funciones read_spss() y read_sas() tienen la misma sintaxis.\n\nApertura manual de los ficheros\nCuando los ficheros se abren así, lo mejor es copiar el comando que se ha empleado y copiarlo en un chunk del rmd o el script en el que se esté trabajando, para que cuando se quiera volver a abrir el archivo sea más rapido hacerlo.",
    "crumbs": [
      "Bases de datos y variables",
      "Ficheros de datos (dataframe)"
    ]
  },
  {
    "objectID": "df-var/ficheros-datos.html#apertura-de-ficheros",
    "href": "df-var/ficheros-datos.html#apertura-de-ficheros",
    "title": "Ficheros de datos (dataframe)",
    "section": "",
    "text": "Para poder abrir un fichero no basta con el comando, sino que estos se deben guardar dentro de un nuevo objeto:\ndatos&lt;- read_csv(\"filename\")\nFicheros de texto plano (.csv, .txt, tsv, etc)\nSe necisita abrir la librería readr: library(readr). El comando a utilizar varía en función del separador del archivo:\n\nread_csv() para ficheros csv delimitados por coma (,).\nread_csv2() para ficheros csv delimitados por punto y coma (;).\nread_tsv() lee ficheros separados por tabulador\nread_delim() lee ficheros sin delimitador\nread_fwf() lee ficheros de ancho fijo\nread_table() lee ficheros separados por espacio\n\nSi las columnas tienen nombre, se debe especificar dentro de la función:\ndata&lt;-read_csv(\"filename\", col_names=FALSE)\nFicheros de excel\nCuando los datos están un fichero .xlsx, utilizamos función read_excel() del paquete readxl\nSi los datos están la primera hoja del fichero mi_excel.xlsx\nlibrary(readxl)\ndatos &lt;- read_excel(\"mi_excel.xlsx\", 1)\nSi los datos están en una hoja llamada “mi_hoja”\ndatos &lt;- read.excel(\"mi_excel.xlsx\", sheetName = \"mi_hoja\") \nLectura de datos desde ficheros SPSS, Stata y SAS\nUna de las opciones existentes es la función haven() del paquete haven nos permite abrir ficheros en formatoStata/SPSS/SAS. Por ejemplo:\nlibrary(haven)\ndatos &lt;- read_dta(\"filename.dta\")\nLas funciones read_spss() y read_sas() tienen la misma sintaxis.\n\nApertura manual de los ficheros\nCuando los ficheros se abren así, lo mejor es copiar el comando que se ha empleado y copiarlo en un chunk del rmd o el script en el que se esté trabajando, para que cuando se quiera volver a abrir el archivo sea más rapido hacerlo.",
    "crumbs": [
      "Bases de datos y variables",
      "Ficheros de datos (dataframe)"
    ]
  },
  {
    "objectID": "df-var/ficheros-datos.html#visualizar-el-contenido-de-un-dataframe",
    "href": "df-var/ficheros-datos.html#visualizar-el-contenido-de-un-dataframe",
    "title": "Ficheros de datos (dataframe)",
    "section": "2. Visualizar el contenido de un dataframe",
    "text": "2. Visualizar el contenido de un dataframe\n\nView(datos) → abre una nueva pestaña con la base de datos.\nglimpse(datos) (del paquete tydiverse) → muestra el número de filas y de columnas, el nombre de las variables, su clase y los primeros valores de cada una de ellas.\n\n\n\nRows: 29,201\nColumns: 10\n$ ESTUDIO  &lt;dbl+lbl&gt; 3411, 3411, 3411, 3411, 3411, 3411, 3411, 3411, 3411, 341…\n$ REGISTRO &lt;dbl&gt; 492777, 70655, 46423, 103464, 112810, 126567, 137692, 182178,…\n$ CUES     &lt;dbl&gt; 29043, 5848, 3893, 8711, 9517, 10736, 11573, 14839, 16793, 17…\n$ CCAA     &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ PROV     &lt;dbl+lbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, …\n$ MUN      &lt;dbl+lbl&gt;  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  …\n$ CAPITAL  &lt;dbl+lbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ TAMUNI   &lt;dbl+lbl&gt; 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, …\n$ ENTREV   &lt;dbl+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ TIPO_TEL &lt;dbl+lbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n\n\n\ndim(datos) → permite conocer el número de filas y de columnas.\n\n\n\n[1] 29201   228\n\n\n\nsummary(datos) → muestra los descriptivos principales de cada una de las variables del dataframe (media y cuartiles).\n\n\n\n    ESTUDIO        REGISTRO           CUES            CCAA       \n Min.   :3411   Min.   :   229   Min.   :    1   Min.   : 1.000  \n 1st Qu.:3411   1st Qu.: 86385   1st Qu.: 7301   1st Qu.: 4.000  \n Median :3411   Median :177688   Median :14601   Median : 9.000  \n Mean   :3411   Mean   :206694   Mean   :14601   Mean   : 8.062  \n 3rd Qu.:3411   3rd Qu.:307076   3rd Qu.:21901   3rd Qu.:12.000  \n Max.   :3411   Max.   :494973   Max.   :29201   Max.   :19.000  \n      PROV      \n Min.   : 1.00  \n 1st Qu.:11.00  \n Median :26.00  \n Mean   :24.67  \n 3rd Qu.:36.00  \n Max.   :52.00  \n\n\n\ncolnames(datos) → lista con el nombre de todas las variables.\n\n\n\n [1] \"ESTUDIO\"  \"REGISTRO\" \"CUES\"     \"CCAA\"     \"PROV\"     \"MUN\"     \n [7] \"CAPITAL\"  \"TAMUNI\"   \"ENTREV\"   \"TIPO_TEL\" \"sexo\"     \"edad\"    \n[13] \"P0A\"      \"ECOPER\"   \"ECOESP\"  \n\n\n\ndescribe(datos) (del paquete psych).\n\n\n\n         vars     n      mean        sd median   trimmed       mad  min    max\nESTUDIO     1 29201   3411.00      0.00   3411   3411.00      0.00 3411   3411\nREGISTRO    2 29201 206693.59 142972.42 177688 196970.89 155275.66  229 494973\nCUES        3 29201  14601.00   8429.75  14601  14601.00  10822.98    1  29201\nCCAA        4 29201      8.06      4.66      9      7.98      4.45    1     19\nPROV        5 29201     24.67     14.30     26     24.43     17.79    1     52\nMUN         6 29201     37.74     66.98      0     20.88      0.00    0    297\nCAPITAL     7 29201      2.44      0.79      3      2.54      0.00    1      3\nTAMUNI      8 29201      3.78      1.64      4      3.75      1.48    1      7\nENTREV      9 29201      0.00      0.00      0      0.00      0.00    0      0\nTIPO_TEL   10 29201      1.74      0.44      2      1.80      0.00    1      2\n          range  skew kurtosis     se\nESTUDIO       0   NaN      NaN   0.00\nREGISTRO 494744  0.48    -0.89 836.67\nCUES      29200  0.00    -1.20  49.33\nCCAA         18 -0.10    -0.93   0.03\nPROV         51  0.10    -1.17   0.08\nMUN         297  2.30     4.96   0.39\nCAPITAL       2 -0.94    -0.77   0.00\nTAMUNI        6  0.15    -0.76   0.01\nENTREV        0   NaN      NaN   0.00\nTIPO_TEL      1 -1.08    -0.83   0.00\n\n\n\nstr(datos) → metadatos de cada una de las variables (lo que sale si le das al triángulo verde que aparece junto al nombre de la base de datos del environment).\n\n\n\ntibble [29,201 × 5] (S3: tbl_df/tbl/data.frame)\n $ ESTUDIO : dbl+lbl [1:29201] 3411, 3411, 3411, 3411, 3411, 3411, 3411, 3411, 3411...\n   ..@ label        : chr \"Código del estudio\"\n   ..@ format.spss  : chr \"F4.0\"\n   ..@ display_width: int 4\n   ..@ labels       : Named num 3411\n   .. ..- attr(*, \"names\")= chr \"3411\"\n $ REGISTRO: num [1:29201] 492777 70655 46423 103464 112810 ...\n  ..- attr(*, \"label\")= chr \"Número de registro\"\n  ..- attr(*, \"format.spss\")= chr \"F6.0\"\n  ..- attr(*, \"display_width\")= int 6\n $ CUES    : num [1:29201] 29043 5848 3893 8711 9517 ...\n  ..- attr(*, \"label\")= chr \"Cuestionario\"\n  ..- attr(*, \"format.spss\")= chr \"F5.0\"\n  ..- attr(*, \"display_width\")= int 5\n $ CCAA    : dbl+lbl [1:29201] 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\n   ..@ label        : chr \"Comunidad autónoma\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 2\n   ..@ labels       : Named num [1:19] 1 2 3 4 5 6 7 8 9 10 ...\n   .. ..- attr(*, \"names\")= chr [1:19] \"Andalucía\" \"Aragón\" \"Asturias (Principado de)\" \"Balears (Illes)\" ...\n $ PROV    : dbl+lbl [1:29201] 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4...\n   ..@ label        : chr \"Provincia\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 2\n   ..@ labels       : Named num [1:52] 1 2 3 4 33 5 6 7 8 9 ...\n   .. ..- attr(*, \"names\")= chr [1:52] \"Araba/Álava\" \"Albacete\" \"Alicante/Alacant\" \"Almería\" ...\n - attr(*, \"label\")= chr \"fileNameJDS\"\n\n\n\nhead(datos, 10) → muestra las variables, su clase, los 10 primeros valores de cada uno de ellos.\n\n\n\n# A tibble: 10 × 228\n   ESTUDIO     REGISTRO  CUES CCAA       PROV    MUN     CAPITAL TAMUNI  ENTREV \n   &lt;dbl+lbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;  &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt;\n 1 3411 [3411]   492777 29043 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 1 [Men… 0 [Ano…\n 2 3411 [3411]    70655  5848 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 1 [Men… 0 [Ano…\n 3 3411 [3411]    46423  3893 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n 4 3411 [3411]   103464  8711 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n 5 3411 [3411]   112810  9517 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n 6 3411 [3411]   126567 10736 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n 7 3411 [3411]   137692 11573 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n 8 3411 [3411]   182178 14839 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n 9 3411 [3411]   216764 16793 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n10 3411 [3411]   237655 17918 1 [Andalu… 4 [Alm… 0 [Mun… 3 [Otr… 3 [10.… 0 [Ano…\n# ℹ 219 more variables: TIPO_TEL &lt;dbl+lbl&gt;, sexo &lt;dbl+lbl&gt;, edad &lt;dbl+lbl&gt;,\n#   P0A &lt;dbl+lbl&gt;, ECOPER &lt;dbl+lbl&gt;, ECOESP &lt;dbl+lbl&gt;, MEDIO_1 &lt;dbl+lbl&gt;,\n#   MEDIO_2 &lt;dbl+lbl&gt;, LEEPRENSA &lt;dbl+lbl&gt;, VETELE &lt;dbl+lbl&gt;,\n#   OYERADIO &lt;dbl+lbl&gt;, PRENSA &lt;dbl+lbl&gt;, P3AR &lt;dbl+lbl&gt;, TELEVISION &lt;dbl+lbl&gt;,\n#   P3BR &lt;dbl+lbl&gt;, RADIO &lt;dbl+lbl&gt;, P3CR &lt;dbl+lbl&gt;, GESTIONGOB &lt;dbl+lbl&gt;,\n#   GESTIONOPO &lt;dbl+lbl&gt;, PROBVOTO &lt;dbl+lbl&gt;, VOTOCORREO &lt;dbl+lbl&gt;,\n#   PROBPARTIDOS_1 &lt;dbl+lbl&gt;, PROBPARTIDOS_2 &lt;dbl+lbl&gt;, …",
    "crumbs": [
      "Bases de datos y variables",
      "Ficheros de datos (dataframe)"
    ]
  },
  {
    "objectID": "df-var/ficheros-datos.html#modificar-el-fichero",
    "href": "df-var/ficheros-datos.html#modificar-el-fichero",
    "title": "Ficheros de datos (dataframe)",
    "section": "3. Modificar el fichero",
    "text": "3. Modificar el fichero\n\nFilter: seleccionar casos (filas)\nSe usa el comando filter, del paquete dplyr (en tidyverse). Se establecen una serie de condiciones lógicas a partir de las cuales la función retendrá únicamente los casos (filas) que cumplen con dicha condición (condiciones como ==, &gt;, %in%).\nEj.: en una base de datos donde los casos son municipios, seleccionar solo aquellos pertenecientes a Murcia o Almería:\ndatos_2prov &lt;- datos %&gt;% \n  filter(Provincia==\"Almería\" | Provincia==\"Murcia\")\n  \ndatos_2prov &lt;- datos %&gt;% \n  filter(id_provincia %in% c(5,35))\nSi se quieren seleccionar todos los casos menos los que cumplen una determinada excepción, se usa ! antes de la condición. En el siguiente ejemplo, quedarán en la base de datos todos los casos menos los de Cs y Otros:\nfilter(!(datos$recuerdo %in% c(\"Cs\",\"Otros\")))\nAl usar tanto este comando como el select, conviene guardar los cambios dentro de un nuevo objeto y dejar el dataset original sin modificar.\n\n\nSelect: seleccionar variables\nSe usa el comando select, del paquete dplyr. Esta función permite reducir el número de columnas, por lo que resulta de gran utilidad cuando tenemos datasets con muchas variables y solo vamos a trabajar con algunas de ellas.\nSeleccionar una columna: select(datos, nombre_variable).\nEste comando permite seleccionar más de una variable a la vez: select(datos, x1, x2, x3).\nTambién se pueden eliminar una o varias variables que no se quieran en el dataset: select(datos, -variable)\n\n\nOrdenar las variables\nVariable numérica:\n\nOrden ascendente:\n\nOpción 1: datos %&gt;% arrange(variable)\nOpción 2: datos &lt;- datos[order(datos$variable), ]\n\nOrden descendente:\n\nOpción 1: datos %&gt;% arrange(desc(variable))\nOpción 2: datos &lt;- datos[order(-datos$variable), ]\n\nSe pueden ordenar los datos por dos variables simultáneamente:\n\nOpción 1: datos &lt;- datos %&gt;% arrange(var1, var1)\nOpción 2: datos &lt;- datos[order(datos$var1, datos$var2), ]\n\n\nVariable categórica:\n\nSe usan los mismos comandos anteriores para ordenar por orden alfabético ascendente o descendente\nOrden personalizado: mutate(variable = fct_relevel(variable, c(\"categoría1\", \"cat2\", \"catn\"))) Ej.:\n\nmutate(partido = fct_relevel(party, c(\"PP\", \"PSOE\", \"VOX\", \"SUMAR\", \"Otros\")))",
    "crumbs": [
      "Bases de datos y variables",
      "Ficheros de datos (dataframe)"
    ]
  },
  {
    "objectID": "graficos/g-intro.html#gráficos-de-barras",
    "href": "graficos/g-intro.html#gráficos-de-barras",
    "title": "Ejemplos",
    "section": "Gráficos de barras:",
    "text": "Gráficos de barras:",
    "crumbs": [
      "Gráficos",
      "Ejemplos"
    ]
  },
  {
    "objectID": "graficos/g-intro.html#gráficos-de-mancuernas",
    "href": "graficos/g-intro.html#gráficos-de-mancuernas",
    "title": "Ejemplos",
    "section": "Gráficos de mancuernas:",
    "text": "Gráficos de mancuernas:",
    "crumbs": [
      "Gráficos",
      "Ejemplos"
    ]
  },
  {
    "objectID": "graficos/g-intro.html#otros-gráficos",
    "href": "graficos/g-intro.html#otros-gráficos",
    "title": "Ejemplos",
    "section": "Otros gráficos:",
    "text": "Otros gráficos:",
    "crumbs": [
      "Gráficos",
      "Ejemplos"
    ]
  },
  {
    "objectID": "graficos/g-mancuernas.html",
    "href": "graficos/g-mancuernas.html",
    "title": "Gráficos de mancuernas",
    "section": "",
    "text": "GráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(posicion, aes(x = Media, y = Tema, group = Tema))+\n  geom_curve(aes(x = 1.7, y = \"inmigracion\", xend = 2.27, yend = \"lgtb\"),\n    arrow = arrow(length = unit(0.22, \"cm\"), type = \"closed\"),\n    linewidth = 0.7,\n    curvature = -0.4,\n    linetype = 2)+\n  geom_label(\n    label=\"Podemos y PSOE\\n son percibidos\\n en la misma posición \", \n    x=1.5,\n    y=\"inmigracion\",\n    label.size = 0,\n    color = \"black\",\n    size=2.2) +\n  geom_vline(xintercept = seq(0,10, by=1), color = \"lightgrey\", alpha = 0.5)+\n  geom_line(aes(group = Tema), color = \"black\", lwd = 0.5) +\n  geom_point(aes(color = Partido), size = 4, alpha=0.7) + \n  geom_vline(xintercept = 5, linetype = \"dashed\", color = \"black\") +\n  labs(\n    x = \"Media\",\n    y = NULL,\n    caption= \"Medias de ubicación de cada partido según la población.\\nEl 0 indida posiciones más favorables.\",\n    color = \"Partido:\") +\n  theme_classic() +\n  theme(\n    axis.text.y = element_text(size = 9),  \n    axis.text.x = element_text(size = 10),  \n    legend.position = \"bottom\")+\n  scale_x_continuous(limits = c(0,10), breaks = c(0,2,4,6,8,10)) +\n  scale_color_manual(values=colores)+\n  scale_y_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))+\n  geom_text(aes(label = round(Media, 1)), vjust = -1.2, size = 2.5,show.legend = F)\n\n\nggplot(posicion, aes(x = Media, y = Tema, group = Tema))+\n\n## Flecha:\n  geom_curve(aes(x = 1.7, y = \"inmigracion\", xend = 2.27, yend = \"lgtb\"), # Coordenadas de principio y final de la flecha\n    arrow = arrow(length = unit(0.22, \"cm\"), type = \"closed\"), # Tipo de flecha y tamaño\n    linewidth = 0.7, # Ancho de la línea\n    curvature = -0.4,# Flecha con curvatura\n    linetype = 2)+ # Tipo de línea (a rayas)\n\n## El texto de la anotaicón en el gráfico\n  geom_label(\n    label=\"Podemos y PSOE\\n son percibidos\\n en la misma posición \", \n    x=1.5,\n    y=\"inmigracion\",\n    label.size = 0,\n    color = \"black\",\n    size=2.2) +\n\n## Líneas verticales de fondo\n  geom_vline(xintercept = seq(0,10, by=1), color = \"lightgrey\", alpha = 0.5)+ # Las líneas grises para cada valor\n  geom_vline(xintercept = 5, linetype = \"dashed\", color = \"black\") +  # Línea vertical en 5\n\n## Lineas para conectar los puntos en cada tema\n  geom_line(aes(group = Tema), color = \"black\", lwd = 0.5) +\n\n## Puntos para cada partido\n  geom_point(aes(color = Partido), size = 4, alpha=0.7) +\n\n## Otras modificaciones \n  labs(\n    x = \"Media\", # Etiqueta del eje x\n    y = NULL, # Para que no aparezca la etiqueta en el eje y\n    caption= \"Medias de ubicación de cada partido según la población.\\nEl 0 indida posiciones más favorables.\",\n    color = \"Partido:\") + # Texto antes de los valores en el índice\n  theme_classic() + #Tema del gráfico (fondo en blanco)\n  theme(\n    axis.text.y = element_text(size = 9),  #Tamaño del eje y\n    axis.text.x = element_text(size = 10), #Tamaño del eje x\n    legend.position = \"bottom\")+ # Posición de la leyenda\n  scale_x_continuous(limits = c(0,10), breaks = c(0,2,4,6,8,10)) + # Valores del eje x\n  scale_color_manual(values=colores)+ # Colores personalizados para cada partido (se crea un vector antes que indique el color de cada partido)\n\n## Cambiar el texto del eje y\n  scale_y_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))+\n\n## Añadir cifras a los puntos\n  geom_text(aes(label = round(Media, 1)), vjust = -1.2, size = 2.5,show.legend = F)",
    "crumbs": [
      "Gráficos",
      "Gráficos de mancuernas"
    ]
  },
  {
    "objectID": "graficos/g-mancuernas.html#simples-posición",
    "href": "graficos/g-mancuernas.html#simples-posición",
    "title": "Gráficos de mancuernas",
    "section": "",
    "text": "GráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(posicion, aes(x = Media, y = Tema, group = Tema))+\n  geom_curve(aes(x = 1.7, y = \"inmigracion\", xend = 2.27, yend = \"lgtb\"),\n    arrow = arrow(length = unit(0.22, \"cm\"), type = \"closed\"),\n    linewidth = 0.7,\n    curvature = -0.4,\n    linetype = 2)+\n  geom_label(\n    label=\"Podemos y PSOE\\n son percibidos\\n en la misma posición \", \n    x=1.5,\n    y=\"inmigracion\",\n    label.size = 0,\n    color = \"black\",\n    size=2.2) +\n  geom_vline(xintercept = seq(0,10, by=1), color = \"lightgrey\", alpha = 0.5)+\n  geom_line(aes(group = Tema), color = \"black\", lwd = 0.5) +\n  geom_point(aes(color = Partido), size = 4, alpha=0.7) + \n  geom_vline(xintercept = 5, linetype = \"dashed\", color = \"black\") +\n  labs(\n    x = \"Media\",\n    y = NULL,\n    caption= \"Medias de ubicación de cada partido según la población.\\nEl 0 indida posiciones más favorables.\",\n    color = \"Partido:\") +\n  theme_classic() +\n  theme(\n    axis.text.y = element_text(size = 9),  \n    axis.text.x = element_text(size = 10),  \n    legend.position = \"bottom\")+\n  scale_x_continuous(limits = c(0,10), breaks = c(0,2,4,6,8,10)) +\n  scale_color_manual(values=colores)+\n  scale_y_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))+\n  geom_text(aes(label = round(Media, 1)), vjust = -1.2, size = 2.5,show.legend = F)\n\n\nggplot(posicion, aes(x = Media, y = Tema, group = Tema))+\n\n## Flecha:\n  geom_curve(aes(x = 1.7, y = \"inmigracion\", xend = 2.27, yend = \"lgtb\"), # Coordenadas de principio y final de la flecha\n    arrow = arrow(length = unit(0.22, \"cm\"), type = \"closed\"), # Tipo de flecha y tamaño\n    linewidth = 0.7, # Ancho de la línea\n    curvature = -0.4,# Flecha con curvatura\n    linetype = 2)+ # Tipo de línea (a rayas)\n\n## El texto de la anotaicón en el gráfico\n  geom_label(\n    label=\"Podemos y PSOE\\n son percibidos\\n en la misma posición \", \n    x=1.5,\n    y=\"inmigracion\",\n    label.size = 0,\n    color = \"black\",\n    size=2.2) +\n\n## Líneas verticales de fondo\n  geom_vline(xintercept = seq(0,10, by=1), color = \"lightgrey\", alpha = 0.5)+ # Las líneas grises para cada valor\n  geom_vline(xintercept = 5, linetype = \"dashed\", color = \"black\") +  # Línea vertical en 5\n\n## Lineas para conectar los puntos en cada tema\n  geom_line(aes(group = Tema), color = \"black\", lwd = 0.5) +\n\n## Puntos para cada partido\n  geom_point(aes(color = Partido), size = 4, alpha=0.7) +\n\n## Otras modificaciones \n  labs(\n    x = \"Media\", # Etiqueta del eje x\n    y = NULL, # Para que no aparezca la etiqueta en el eje y\n    caption= \"Medias de ubicación de cada partido según la población.\\nEl 0 indida posiciones más favorables.\",\n    color = \"Partido:\") + # Texto antes de los valores en el índice\n  theme_classic() + #Tema del gráfico (fondo en blanco)\n  theme(\n    axis.text.y = element_text(size = 9),  #Tamaño del eje y\n    axis.text.x = element_text(size = 10), #Tamaño del eje x\n    legend.position = \"bottom\")+ # Posición de la leyenda\n  scale_x_continuous(limits = c(0,10), breaks = c(0,2,4,6,8,10)) + # Valores del eje x\n  scale_color_manual(values=colores)+ # Colores personalizados para cada partido (se crea un vector antes que indique el color de cada partido)\n\n## Cambiar el texto del eje y\n  scale_y_discrete(labels=c(\"Inversión contra\\n Cambio Climático\",  \"Servicios Públicos\\n vs. Impuesto Bajos\", \"Inmigración\", \"Derechos LGTBI\\n (adopción)\", \"Descentralización\\n Territorial\"))+\n\n## Añadir cifras a los puntos\n  geom_text(aes(label = round(Media, 1)), vjust = -1.2, size = 2.5,show.legend = F)",
    "crumbs": [
      "Gráficos",
      "Gráficos de mancuernas"
    ]
  },
  {
    "objectID": "graficos/g-mancuernas.html#para-más-de-dos-variables-posición",
    "href": "graficos/g-mancuernas.html#para-más-de-dos-variables-posición",
    "title": "Gráficos de mancuernas",
    "section": "Para más de dos variables (posición)",
    "text": "Para más de dos variables (posición)\n\nGráficoCódigoCódigo anotadoFormato de los datos\n\n\n\n\n\n\n\n\n\nggplot(edad_ideol, aes(x = Media, y = edad, group = edad)) +\n  geom_vline(xintercept = seq(0, 10, by = 1), color = \"lightgrey\", alpha = 0.5) +\n  facet_wrap(~ Tema, ncol = 1, strip.position = \"top\", labeller = labeller(Tema = nombres_temas))+\n    geom_vline(\n    data = posicion,\n    aes(xintercept = Media, color = Partido),\n    linetype = \"dotted\",\n    lwd = 1) +\n  geom_line(aes(group = edad), color = \"black\", lwd = 0.5) +  \n  geom_point(aes(color = ideologia), size = 3, alpha = 0.7) +\n  geom_vline(xintercept = 5, linetype = \"dashed\", color = \"black\") +\n  labs(\n    x = \"Media\",\n    y = NULL,\n    caption = \"Medias de ubicación de la población según su ideología y edad.\\nEl 0 indica posiciones más favorables.\",\n    color = NULL) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_text(size = 9),  \n    axis.text.x = element_text(size = 10),  \n    legend.position = \"bottom\",\n    strip.background = element_blank(),\n    strip.text  = element_text(angle = 0,\n                               size = 12)) +\n  scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) +\n  scale_color_manual(values = colores, \n                     breaks = c(\"PSOE\", \"Izquierda\", \"PP\",\"Centro\", \"UP\",\"Derecha\", \"Vox\"))\n\n\nLa explicación de este código es muy similar al de los puntos simples\nggplot(edad_ideol, aes(x = Media, y = edad, group = edad)) +\n  geom_vline(xintercept = seq(0, 10, by = 1), color = \"lightgrey\", alpha = 0.5) +\n\n## Juntar los 5 gráficos (1 por tema) en uno solo.\n  facet_wrap(~ Tema, ncol = 1, strip.position = \"top\", labeller = labeller(Tema = nombres_temas))+\n\n## Líneas verticales con los valores de cada partido\n  geom_vline(\n    data = posicion,\n    aes(xintercept = Media, color = Partido),\n    linetype = \"dotted\",\n    lwd = 1) +\n\n## Puntos y líneas con las posiciones de los 3 grupos ideológicos\n  geom_line(aes(group = edad), color = \"black\", lwd = 0.5) +  \n  geom_point(aes(color = ideologia), size = 3, alpha = 0.7) +\n\n## Linea vertical en el 5\n  geom_vline(xintercept = 5, linetype = \"dashed\", color = \"black\") +\n\n## Otros ajustes estéticos\n  labs( # Etiquetas\n    x = \"Media\",\n    y = NULL,\n    caption = \"Medias de ubicación de la población según su ideología y edad.\\nEl 0 indica posiciones más favorables.\",\n    color = NULL) +\n  theme_classic() + # Tema de fondo\n  theme( # Ajustes de tamaño y posición de las etiquetas\n    axis.text.y = element_text(size = 9),  \n    axis.text.x = element_text(size = 10),  \n    legend.position = \"bottom\",\n    strip.background = element_blank(), # Para elimirar el recuadro de los títulos de cada uno de los 5 temas\n    strip.text  = element_text(angle = 0,     # Títulos en horizontal\n                               size = 12)) +\n  scale_x_continuous(limits = c(0, 10), breaks = c(0, 2, 4, 6, 8, 10)) + # Valores personalizados en el eje x\n  scale_color_manual(values = colores, #Colores personalizados\n                     breaks = c(\"PSOE\", \"Izquierda\", \"PP\",\"Centro\", \"UP\",\"Derecha\", \"Vox\")) # Orden personalizado de la leyenda\n\n\n\n\n\n\n\n\n\n\n\nedad_ideol\n\n\n\n\n\n\n\nposicion",
    "crumbs": [
      "Gráficos",
      "Gráficos de mancuernas"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Apuntes de R",
    "section": "",
    "text": "Aquí te escribes algo para la intro o cambias la foto o lo que quieras",
    "crumbs": [
      "Introducción a R",
      "Apuntes de R"
    ]
  },
  {
    "objectID": "index.html#comentarios-y-anotaciones",
    "href": "index.html#comentarios-y-anotaciones",
    "title": "Apuntes de R",
    "section": "Comentarios y anotaciones",
    "text": "Comentarios y anotaciones\nEste sitio ofrece dos formas de interactuar con el contenido:\n\nAnotaciones específicas: Usa el botón de Hypothesis (➚) en la esquina superior derecha para subrayar y comentar partes específicas del texto.\nComentarios generales: Usa la sección de comentarios de Giscus al final de cada página para discusiones generales. Necesitarás una cuenta de GitHub para comentar.",
    "crumbs": [
      "Introducción a R",
      "Apuntes de R"
    ]
  },
  {
    "objectID": "intro/flujos-trabajo.html",
    "href": "intro/flujos-trabajo.html",
    "title": "Flujos de trabajo",
    "section": "",
    "text": "El directorio de trabajo es el lugar donde R busca los archivos que le pides que cargue, y donde guardará los archivos que generes.\nPara trabajar dentro de una carpeta del ordenador exiten dos opciones: - Crear un nuevo proyecto y trabajar desde ahí. - Establecer manualmente el directorio:\nsetwd(\"dirección de la carpeta en el ordenador\")\nPara consultar los ficheros que hay dentro de nuestro directorio de trabajo podemos usar la función dir()\ndis()\n\nSource\nExtraer el código a un script de R:\nknitr::purl(\"nombre_archivo.Rmd\")\nEjecutar todo el código de un script sin mostrarlo:\nsource(\"nombre_archivo.R\")\nSe escribe al principio del RMarkdown (o del script) para que ejecute directamente un script sin mostrar todo el código (en el environment) (importa el código sin mostrarlo todo).\nPor ejemplo, puedes tener un script solo con la limpieza de la base de datos, y para que no sea tan largo y lioso el documento, ejecutarlo directamente y en el nuevo RM comenzar directamente con el análisis.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Introducción a R",
      "Flujos de trabajo"
    ]
  },
  {
    "objectID": "intro/operaciones-basicas.html",
    "href": "intro/operaciones-basicas.html",
    "title": "Operaciones básicas",
    "section": "",
    "text": "Suma, resta, multiplicación, división, exponencial…\nCuadrado (sqrt) y logaritmos (log)\nAbsoluto:\n\n\nabs(-1.4)\n\n[1] 1.4\n\n\n\nRedondear:\n\n\nround(1.234, 2) #El segundo número indica el número de decimales al que se redondeará.\n\n[1] 1.23",
    "crumbs": [
      "Introducción a R",
      "Operaciones básicas"
    ]
  },
  {
    "objectID": "intro/operaciones-basicas.html#operaciones-numéricas",
    "href": "intro/operaciones-basicas.html#operaciones-numéricas",
    "title": "Operaciones básicas",
    "section": "",
    "text": "Suma, resta, multiplicación, división, exponencial…\nCuadrado (sqrt) y logaritmos (log)\nAbsoluto:\n\n\nabs(-1.4)\n\n[1] 1.4\n\n\n\nRedondear:\n\n\nround(1.234, 2) #El segundo número indica el número de decimales al que se redondeará.\n\n[1] 1.23",
    "crumbs": [
      "Introducción a R",
      "Operaciones básicas"
    ]
  },
  {
    "objectID": "intro/operaciones-basicas.html#edición-de-caracteres-texto",
    "href": "intro/operaciones-basicas.html#edición-de-caracteres-texto",
    "title": "Operaciones básicas",
    "section": "2. Edición de caracteres (texto)",
    "text": "2. Edición de caracteres (texto)\n\nUnión de caracteres:\n\n\npaste(\"Hola\", \"mundo\", sep = \" \")\n\n[1] \"Hola mundo\"\n\npaste0(\"Hola\", \"mundo\")\n\n[1] \"Holamundo\"\n\n\n\nSeleccionar una parte del texto:\n\n\nsubstring(\"Nombre: Marga\", first = 7, last = 11)\n\n[1] \": Mar\"\n\n\n\nPasar un texto a minúsculas:\n\n\ntolower(\"Hola, soy Marga\")\n\n[1] \"hola, soy marga\"\n\n\n\nPasar un texto mayúsculas:\n\n\ntoupper(\"Hola, soy Marga\")\n\n[1] \"HOLA, SOY MARGA\"\n\n\n\nContar el número de caracteres (también espacios y símbolos, no solo letras):\n\n\nnchar(\"Hola, mundo!\")\n\n[1] 12",
    "crumbs": [
      "Introducción a R",
      "Operaciones básicas"
    ]
  },
  {
    "objectID": "intro/operaciones-basicas.html#operadores-lógicos-y-relacionales",
    "href": "intro/operaciones-basicas.html#operadores-lógicos-y-relacionales",
    "title": "Operaciones básicas",
    "section": "3. Operadores lógicos y relacionales",
    "text": "3. Operadores lógicos y relacionales\nOperadores lógicos:\n\n! NOT (lo opuesto)\n& AND\n| OR\n\nOperadores relacionales:\n\n== igual\n!= distinto\n&gt; mayor que\n&gt;= mayor o igual que\n&lt;=menor o igual que\n&lt; menor que",
    "crumbs": [
      "Introducción a R",
      "Operaciones básicas"
    ]
  },
  {
    "objectID": "intro/operaciones-basicas.html#operaciones-con-vectores",
    "href": "intro/operaciones-basicas.html#operaciones-con-vectores",
    "title": "Operaciones básicas",
    "section": "4. Operaciones con vectores",
    "text": "4. Operaciones con vectores\nUn vector es una secuencia de elementos del mismo tipo (numérico, carácter, lógico, etc.). Se puede asimilar a una variable.\n\nVer de qué tipo es el vector: class()\nComprobar la longitud del vector: length()\nSi los vectores son númericos, se les pueden aplicar las mismas operaciones que a los números (suma, multuplicaicón…), ya sea a un único vector o entre vectores (sumar un vector a otro). Ej.:\n\n\nvector1 &lt;- c(1, 6, 4)\nvector2 &lt;- c(1, 2, 3)\n\nvector1 + 10\n\n[1] 11 16 14\n\nvector1 + vector2\n\n[1] 2 8 7\n\n\n\nComparar dos vectores:\n\n\nvector1 == vector2\n\n[1]  TRUE FALSE FALSE\n\n\n\nConcatenar vectores: mismos comandos que para unir dos caracteres de texto. Ej.:\n\n\npaste(vector1, \":00\", sep=\"\")\n\n[1] \"1:00\" \"6:00\" \"4:00\"\n\npaste(vector1, vector2, sep = \" & \")\n\n[1] \"1 & 1\" \"6 & 2\" \"4 & 3\"\n\n\n\nBuscar si existe un valor concreto dentro de un vector. Ej.:\n\n\npartidos1 &lt;- c(\"PP\", \"PSOE\", \"SUMAR\", \"VOX\")\npartidos2 &lt;- c(\"PP\", \"PSOE\", \"OTROS\")\n\"VOX\" %in% partidos1\n\n[1] TRUE\n\n\"VOX\" %in% partidos2\n\n[1] FALSE\n\n\n\nCombinar vectores:\n\n\nlong_vector &lt;- c(partidos1, partidos2)\nlong_vector\n\n[1] \"PP\"    \"PSOE\"  \"SUMAR\" \"VOX\"   \"PP\"    \"PSOE\"  \"OTROS\"\n\n\n\nConocer un elemento dentro de una posición concreta de un vector:\n\n\nnum_vector &lt;- 5:10\nnum_vector[3] # Elemento en la posición 3\n\n[1] 7\n\nnum_vector[c(2, 4)] # Elementos en las posiciones 2 y 4\n\n[1] 6 8\n\n\n\nCambiar elementos específicos de un vector:\n\n\nnum_vector[c(2, 4)] &lt;- c(13, 50)\nnum_vector\n\n[1]  5 13  7 50  9 10\n\n\n\nExplorar los primeros y últimos valores de un vector:\n\n\nhead(long_vector, 2) # devuelve los dos primeros\n\n[1] \"PP\"   \"PSOE\"\n\ntail(long_vector, 3) # devuelve los tres primeros\n\n[1] \"PP\"    \"PSOE\"  \"OTROS\"",
    "crumbs": [
      "Introducción a R",
      "Operaciones básicas"
    ]
  }
]